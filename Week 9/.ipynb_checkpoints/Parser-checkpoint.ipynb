{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "c3ea0da2-98f2-487e-ad2a-728764b08bb7",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy\n",
    "import stanza\n",
    "import textacy\n",
    "from fastcoref import FCoref\n",
    "from taxonerd import TaxoNERD\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import DependencyMatcher\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_biobert-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md_weak-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_biobert_weak-1.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "e08158a6-a956-4c35-a791-64c7702d01bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-28 16:19:26 INFO: Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "04/28/2025 16:19:26 - INFO - \t Checking for updates to resources.json in case models have been updated.  Note: this behavior can be turned off with download_method=None or download_method=DownloadMethod.REUSE_RESOURCES\n",
      "Downloading https://raw.githubusercontent.com/stanfordnlp/stanza-resources/main/resources_1.10.0.json: 426kB [00:00, 2.56MB/s]                    \n",
      "2025-04-28 16:19:28 INFO: Downloaded file to C:\\Users\\lbeln\\stanza_resources\\resources.json\n",
      "04/28/2025 16:19:28 - INFO - \t Downloaded file to C:\\Users\\lbeln\\stanza_resources\\resources.json\n",
      "2025-04-28 16:19:28 WARNING: Language en package default expects mwt, which has been added\n",
      "04/28/2025 16:19:28 - WARNING - \t Language en package default expects mwt, which has been added\n",
      "2025-04-28 16:19:28 INFO: Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "04/28/2025 16:19:28 - INFO - \t Loading these models for language: en (English):\n",
      "========================\n",
      "| Processor | Package  |\n",
      "------------------------\n",
      "| tokenize  | combined |\n",
      "| mwt       | combined |\n",
      "========================\n",
      "\n",
      "2025-04-28 16:19:28 INFO: Using device: cpu\n",
      "04/28/2025 16:19:28 - INFO - \t Using device: cpu\n",
      "2025-04-28 16:19:28 INFO: Loading: tokenize\n",
      "04/28/2025 16:19:28 - INFO - \t Loading: tokenize\n",
      "2025-04-28 16:19:28 INFO: Loading: mwt\n",
      "04/28/2025 16:19:28 - INFO - \t Loading: mwt\n",
      "2025-04-28 16:19:28 INFO: Done loading processors!\n",
      "04/28/2025 16:19:28 - INFO - \t Done loading processors!\n",
      "04/28/2025 16:20:09 - INFO - \t missing_keys: []\n",
      "04/28/2025 16:20:09 - INFO - \t unexpected_keys: []\n",
      "04/28/2025 16:20:09 - INFO - \t mismatched_keys: []\n",
      "04/28/2025 16:20:09 - INFO - \t error_msgs: []\n",
      "04/28/2025 16:20:09 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    }
   ],
   "source": [
    "sp_nlp = spacy.load(\"en_core_web_sm\")\n",
    "st_nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "tn_nlp = TaxoNERD().load(model=\"en_ner_eco_biobert\")\n",
    "fcoref = FCoref(enable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "31b1427f-2ddb-4132-aad8-f0b4421f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements1.txt\n",
    "# !pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "0ed65dd1-7512-4644-87c4-af7fe379dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no definite names for these patterns as I do not know what\n",
    "# to call them. These patterns are used to extract possessive\n",
    "# relationships from a sentence. I also could not find better names for\n",
    "# the two variables below.\n",
    "OWNER = \"owner\"\n",
    "OWNED = \"owned\"\n",
    "\n",
    "pattern_1 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": OWNED,\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"poss\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_2 = [\n",
    "     {\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": OWNED,\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"adp\",\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"prep\",\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"ADP\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"adp\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"pobj\",\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_3 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"nsubj\",\n",
    "            \"POS\": {\"IN\": [\"PRON\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"dobj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_4 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"nsubj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"adp\",\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"prep\",\n",
    "            \"POS\": {\"IN\": [\"ADP\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"adp\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"pobj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = {\n",
    "    \"Pattern1\": pattern_1,\n",
    "    \"Pattern2\": pattern_2,\n",
    "    \"Pattern3\": pattern_3,\n",
    "    \"Pattern4\": pattern_4,\n",
    "}\n",
    "\n",
    "def dependency_matcher(sp_nlp):\n",
    "    matcher = DependencyMatcher(sp_nlp.vocab)\n",
    "    for pattern_id, pattern in patterns.items():\n",
    "        matcher.add(pattern_id, [pattern])\n",
    "    return matcher\n",
    "\n",
    "def index_to_what(sp_nlp, sp_doc, what_matches):\n",
    "    index_to_what_map = {}\n",
    "    for match_id, token_ids in what_matches:\n",
    "        pattern_id = sp_nlp.vocab.strings[match_id]\n",
    "        # print(pattern_id)\n",
    "        owner = None\n",
    "        owned = None\n",
    "        for i in range(len(token_ids)):\n",
    "            right_id = patterns[pattern_id][i][\"RIGHT_ID\"]\n",
    "            if right_id == OWNER:\n",
    "                owner = sp_doc[token_ids[i]]\n",
    "            if right_id == OWNED:\n",
    "                owned = sp_doc[token_ids[i]]\n",
    "        if owner.i not in index_to_what_map:\n",
    "            index_to_what_map[owner.i] = []\n",
    "        index_to_what_map[owner.i].append(owned)\n",
    "        if owned.i not in index_to_what_map:\n",
    "            index_to_what_map[owned.i] = []\n",
    "        index_to_what_map[owned.i].append(owner)\n",
    "\n",
    "    return index_to_what_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ec57a613-6944-47d8-b840-108707fb4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sp_doc, svo, prev_svo, next_svo):\n",
    "    sub_l_i = 0 if not prev_svo else prev_svo.object[-1].i + 1\n",
    "    sub_r_i = svo.verb[0].i\n",
    "\n",
    "    while sub_l_i < len(sp_doc) and sp_doc[sub_l_i].sent.start != svo.subject[0].sent.start:\n",
    "        sub_l_i += 1\n",
    "        \n",
    "    obj_l_i = svo.verb[-1].i + 1\n",
    "    obj_r_i = len(sp_doc) - 1 if not next_svo else next_svo.subject[0].i\n",
    "\n",
    "    while obj_r_i >= 0 and sp_doc[obj_r_i].sent.start != svo.object[0].sent.start:\n",
    "        obj_r_i -= 1\n",
    "\n",
    "    return sp_doc[sub_l_i:sub_r_i], sp_doc[obj_l_i:obj_r_i+1]\n",
    "\n",
    "\n",
    "def index_to_cluster(fc_predictions):\n",
    "    index_to_cluster_map = {}\n",
    "    for prediction in fc_predictions:\n",
    "        clusters = prediction.get_clusters(as_strings=False)\n",
    "        for cluster in clusters:\n",
    "            for token in cluster:\n",
    "                index = token[0]\n",
    "                index_to_cluster_map[index] = list(filter(lambda t: t[0] != index, cluster))\n",
    "    return index_to_cluster_map\n",
    "\n",
    "def species_indices(tn_doc):\n",
    "    indices = []\n",
    "    for species_span in tn_doc.ents:\n",
    "        for species in species_span:\n",
    "            indices.append(species.idx)\n",
    "    return indices\n",
    "\n",
    "def is_species(tokens, context, species_indices):\n",
    "    for token in [*tokens, *context]:\n",
    "        if token.idx in species_indices:\n",
    "            # print(f\"\\t\\t\\tToken '{token.text}' is a Species\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "\n",
    "def get_holder(tokens, cluster_map, what_map):\n",
    "    holder = []\n",
    "    for token in tokens:\n",
    "        if token.idx in cluster_map:\n",
    "            holder += cluster_map[token.idx]\n",
    "        if token.i in what_map:\n",
    "            holder += what_map[token.i]\n",
    "    return holder\n",
    "\n",
    "def same_reference(a, b, cluster_map, what_map, species_indices):\n",
    "    a_is_species = is_species(a, [], species_indices)\n",
    "    print(f\"A is Species: {a_is_species}\")\n",
    "    if not a_is_species:\n",
    "        a = get_holder(a, cluster_map, what_map)\n",
    "        if len(a) == 0:\n",
    "            return False\n",
    "    print(f\"A: {a}\")\n",
    "    \n",
    "    b_is_species = is_species(b, [], species_indices)\n",
    "    print(f\"B is Species: {b_is_species}\")\n",
    "    if not b_is_species:\n",
    "        b = get_holder(b, cluster_map, what_map)\n",
    "        if len(b) == 0:\n",
    "            return False\n",
    "    print(f\"B is Species: {b}\")\n",
    "\n",
    "    for token_a in a:\n",
    "        for token_b in b:\n",
    "            print(f\"\\tToken A: {token_a}, Token B: {token_b}\")\n",
    "            if token_a.pos_ not in [\"NOUN\", \"PROPN\", \"ADJ\"]:\n",
    "                continue\n",
    "            if token_b.pos_ not in [\"NOUN\", \"PROPN\", \"ADJ\"]:\n",
    "                continue\n",
    "            if token_a.pos_ != token_b.pos_:\n",
    "                continue\n",
    "            print(f\"Comparison: {token_a.lower_ != token_b.lower}\")\n",
    "            if token_a.lower_ != token_b.lower:\n",
    "                return False\n",
    "    return True\n",
    "\n",
    "def get_related_possessions(tokens, what_map):\n",
    "    related = []\n",
    "    for token in tokens:\n",
    "        if token.i in what_map:\n",
    "            related += what_map[token.i]\n",
    "    return related\n",
    "\n",
    "def filter_by_species(tokens, species_indices):\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        if token.idx in species_indices:\n",
    "            filtered.append(token)\n",
    "    return filtered\n",
    "\n",
    "# def same_reference(tokensA, tokensB, cluster_map):\n",
    "#     clustersA = set()\n",
    "#     for token in tokensA:\n",
    "#         if token.idx in cluster_map:\n",
    "#             for cluster_token in cluster_map[token.idx]:\n",
    "#                 clustersA.add(cluster_token)\n",
    "#     clustersB = set()\n",
    "#     for token in tokensB:\n",
    "#         if token.idx in cluster_map:\n",
    "#             for cluster_token in cluster_map[token.idx]:\n",
    "#                 clustersB.add(cluster_token)\n",
    "\n",
    "#     if not set(clustersA).isdisjoint(clustersB):\n",
    "#         return False\n",
    "#     return True\n",
    "    \n",
    "def parse(text, verbose=False):\n",
    "    sp_doc = sp_nlp(text)\n",
    "    tn_doc = tn_nlp(text)\n",
    "    species = species_indices(tn_doc)\n",
    "\n",
    "    matcher = dependency_matcher(sp_nlp)\n",
    "    matches = matcher(sp_doc)\n",
    "    what_map = index_to_what(sp_nlp, sp_doc, matches)\n",
    "\n",
    "    predictions = fcoref.predict(texts=[text])\n",
    "    cluster_map = index_to_cluster(predictions)\n",
    "    print(cluster_map)\n",
    "    # print(what_map)\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    svo_triples = list(textacy.extract.subject_verb_object_triples(sp_doc))\n",
    "    for index, svo_triple in enumerate(svo_triples):\n",
    "        # Data to Mine\n",
    "        data = {\n",
    "            \"source\": \"\",\n",
    "            \"source_trait\": \"\",\n",
    "            \"source_change\": \"\",\n",
    "            \"target\": \"\",\n",
    "            \"target_trait\": \"\",\n",
    "            \"target_change\": \"\"\n",
    "        }\n",
    "        \n",
    "        print(svo_triple)\n",
    "\n",
    "        prev_svo = None if index == 0 else svo_triples[index - 1]\n",
    "        next_svo = None if index >= len(svo_triples) - 1 else svo_triples[index + 1]\n",
    "\n",
    "        sub_context, obj_context = split_sentence(sp_doc, svo_triple, prev_svo, next_svo)\n",
    "        # print(f\"Sub Context: {sub_context}\")\n",
    "        # print(f\"Obj Context: {obj_context}\")\n",
    "\n",
    "        base_verb_docs = [sp_nlp(verb) for verb in [\"exhibited\"]]\n",
    "        verb_docs = [sp_nlp(verb.text) for verb in svo_triple.verb]\n",
    "\n",
    "        same = same_reference(svo_triple.subject, svo_triple.object, cluster_map, what_map, species)\n",
    "        if same:\n",
    "            print(\"!!!\")\n",
    "            sub_is_species = is_species(svo_triple.subject, [], species)\n",
    "            if sub_is_species:\n",
    "                data[\"source\"] = svo_triple.subject\n",
    "                data[\"source_trait\"] = svo_triple.object\n",
    "            else:\n",
    "                data[\"source_trait\"] = svo_triple.subject\n",
    "                data[\"source\"] = svo_triple.object\n",
    "        else:\n",
    "            sub_is_species = is_species(svo_triple.subject, [], species)\n",
    "            if sub_is_species:\n",
    "                data[\"source\"] = svo_triple.subject\n",
    "            if not sub_is_species:\n",
    "                data[\"source_trait\"] = svo_triple.subject\n",
    "                data[\"source\"] = filter_by_species(get_related_possessions(svo_triple.subject, what_map), species)\n",
    "    \n",
    "            obj_is_species = is_species(svo_triple.object, [], species)\n",
    "            if obj_is_species:\n",
    "                data[\"target\"] = svo_triple.object\n",
    "            if not obj_is_species:\n",
    "                data[\"target_trait\"] = svo_triple.object\n",
    "                data[\"target\"] = filter_by_species(get_related_possessions(svo_triple.object, what_map), species)\n",
    "\n",
    "        print(data)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "da13dc42-2e24-4fe4-9265-7e69238ba24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/28/2025 16:20:10 - INFO - \t Tokenize 1 inputs...\n",
      "04/28/2025 16:20:11 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [(108, 112)], 108: [(0, 12)]}\n",
      "SVOTriple(subject=[Grasshoppers], verb=[exhibited], object=[diet, shifts])\n",
      "A is Species: True\n",
      "A: [Grasshoppers]\n",
      "B is Species: False\n",
      "B is Species: [grass]\n",
      "\tToken A: Grasshoppers, Token B: grass\n",
      "Comparison: True\n",
      "{'source': [Grasshoppers], 'source_trait': '', 'source_change': '', 'target': [], 'target_trait': [diet, shifts], 'target_change': ''}\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "text = \"Grasshoppers exhibited significant diet shifts from grass to herbs (Kruskal-Wallis test, P 0.01, df 3) when they were in the presence of the comparatively sedentary species (the smaller Pisaurina and the larger Hogna) compared to controls without spiders (Fig. 2).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b004db1-f2eb-444d-b9c8-53b9447c84a2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 2\n",
    "text = \"Our results show that phototrophs can indirectly decrease the population density of heterotrophic bacteria by modification of the nature of bacterial interactions with predators.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d6cdea8d-4a22-409f-9f0a-e01d1691a67e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 3\n",
    "text = \"All predators inflicted significant mortality on the prey at each prey density compared to the predator-free control for that density\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "33114ff6-7277-4613-b1a8-c51e7dd2652b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 4\n",
    "text = \"Our results show that an increase in sediment organic matter content is associated to a decline in the abundance of Loripes lucinalis (lucinid bivalve) in the Cymodocea nodosa meadows studied, which potentially may weaken the mutualism between the two species.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c27d6d1e-6766-41db-98ee-e749b287b457",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 5\n",
    "text = \"The abundance of lucinids showed a negative correlation with the organic matter content in vegetated sediments (Fig. 3a), but showed no correlation in bare ones (Fig. 3b).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49b69b68-f60b-4b93-bff9-249871141e0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 6\n",
    "text = \"The MANOVA on the cattle tank experiment showed that the presence of Tramea, nonlethal Anax, and large bullfrog tadpoles all had significant effects on both small tadpole species (Table 1).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000f8dec-49ce-4f9c-8493-924b3fb11b3c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 7\n",
    "text = \"Thus the presence of predators, both nonlethal Anax and lethal Tramea, modified the tank environment in a way that facilitated invasion by midges, but only in the absence of large bullfrogs.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a91ee-a37d-4dbb-bf97-d7e417ceac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8\n",
    "text = \"We hypothesized that the presence of Anax would decrease foraging activity of small tadpoles, which in turn would decrease predation by Tramea on the small tadpoles\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e34cb4-3056-4011-a4e2-cdd97bc274be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9\n",
    "text = '''Only a fraction of the individuals in a given prey population are likely to be killed and consumed by predators. In contrast, nearly all individuals experience the chronic effects of predation risk. When threatened by predators, prey adopt defensive tactics whole costs can lead to reduced growth, maturation rates, survivorship, fecundity, or population density. This nonconsumptive impact of predation risk on prey is known as a \"trait-mediated interaction\" (TMI) because it results from changes in prey traits such as behavior or physiology. Ecological theory suggests that the strength of TMI effects will reflect a balance between the conflicting demands of reproduction vs. predator avoidance. Competitor density and resource availability are expected to alter the balance between these conflicting forces. We conducted a meta-analysis of experimental studies that measured TMI effect size while varying competitor and/or resource density. The threat of predation had an overall negative effect on prey performance, but the strength of this effect varied with the level of competition. High competition exacerbated the negative effect of intimidation on prey density but moderated the negative effect of intimidation on prey life history and growth. We discuss these results in light of previously published theoretical expectations. Our results highlight the variable and context-dependent nature of interspecific interactions.'''\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3f503-2740-447a-a9bf-b6fdc6813d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 10\n",
    "text = \"Current theory on trophic interactions in food webs assumes that ecologically similar species can be treated collectively as a single functional unit such as a guild or trophic level. This theory implies that all species within that unit transmit identical direct and indirect effects throughout the community. We evaluated this assumption by conducting experiments to compare the direct and indirect effects of three top-predator species, belonging to the same hunting spider guild, on the same species of grasshopper and on old-field grasses and herbs. Observations under field conditions revealed that each spider species exhibited different hunting behavior (i.e., sit-and-wait, sit-and-pursue, and active hunting) and occupied different locations within the vegetation canopy. These differences resulted in different direct effects on grasshopper prey. Grasshoppers demonstrated significant behavioral (diet) shifts in the presence of sit-and-wait and sit-and-pursue species but not when faced with actively hunting species. Grasshopper density was significantly reduced by spider species that occupied lower parts of the vegetation canopy (sit-and-pursue and actively hunting species), but it was not significantly reduced by the sit-and-wait spider species that occupied the upper parts of the canopy. These direct effects manifested themselves differently in the plant trophic level. The sit-and-wait spider caused indirect effects on plants by changing grasshopper foraging behavior (a trait-mediated effect). The sit-and-pursue spider caused indirect effects by reducing grasshopper density (density-mediated effects); the effects of changes in grasshopper behavior were thus not reflected in the plant trophic level. The actively hunting spiders had strictly density-mediated indirect effects on plants. The study offers mechanistic insight into how predator species within the same guild can have very different trophic effects in food webs. Thus classical modeling approaches that treat all predator species as a single functional unit may not adequately capture biologically relevant details that influence community dynamics.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe9ad1-d62d-44d0-8702-6403d6a2f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 11\n",
    "text = \"Diversity and plasticity are hallmarks of cells of the monocyte-macrophage lineage. In response to IFNs, Toll-like receptor engagement, or IL-4/IL-13 signaling, macrophages undergo M1 (classical) or M2 (alternative) activation, which represent extremes of a continuum in a universe of activation states. Progress has now been made in defining the signaling pathways, transcriptional networks, and epigenetic mechanisms underlying M1-M2 or M2-like polarized activation. Functional skewing of mononuclear phagocytes occurs in vivo under physiological conditions (e.g., ontogenesis and pregnancy) and in pathology (allergic and chronic inflammation, tissue repair, infection, and cancer). However, in selected preclinical and clinical conditions, coexistence of cells in different activation states and unique or mixed phenotypes have been observed, a reflection of dynamic changes and complex tissue-derived signals. The identification of mechanisms and molecules associated with macrophage plasticity and polarized activation provides a basis for macrophage-centered diagnostic and therapeutic strategies.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daaf223-9f81-4b6b-9f76-f966687536e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 12\n",
    "text = \"The stranger hit a bystander, the man hit a stranger\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c03e1-9ede-4f8d-964c-e900b6ea833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
