{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 321,
   "id": "c3ea0da2-98f2-487e-ad2a-728764b08bb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md-1.1.0.tar.gz\n",
      "  Downloading https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md-1.1.0.tar.gz (119.2 MB)\n",
      "     ---------------------------------------- 0.0/119.2 MB ? eta -:--:--\n",
      "     ---------------------------------------- 0.0/119.2 MB 1.4 MB/s eta 0:01:28\n",
      "     -------------------------------------- 0.0/119.2 MB 393.8 kB/s eta 0:05:03\n",
      "     -------------------------------------- 0.1/119.2 MB 573.4 kB/s eta 0:03:28\n",
      "     -------------------------------------- 0.1/119.2 MB 778.5 kB/s eta 0:02:33\n",
      "     ---------------------------------------- 0.3/119.2 MB 1.4 MB/s eta 0:01:28\n",
      "     ---------------------------------------- 0.5/119.2 MB 2.0 MB/s eta 0:01:01\n",
      "     ---------------------------------------- 0.8/119.2 MB 2.7 MB/s eta 0:00:44\n",
      "     ---------------------------------------- 1.2/119.2 MB 3.2 MB/s eta 0:00:37\n",
      "     ---------------------------------------- 1.4/119.2 MB 3.4 MB/s eta 0:00:35\n",
      "      --------------------------------------- 1.7/119.2 MB 3.7 MB/s eta 0:00:32\n",
      "      --------------------------------------- 1.8/119.2 MB 3.9 MB/s eta 0:00:31\n",
      "      --------------------------------------- 2.1/119.2 MB 3.9 MB/s eta 0:00:31\n",
      "      --------------------------------------- 2.4/119.2 MB 4.1 MB/s eta 0:00:29\n",
      "      --------------------------------------- 2.9/119.2 MB 4.5 MB/s eta 0:00:26\n",
      "     - -------------------------------------- 3.3/119.2 MB 4.8 MB/s eta 0:00:24\n",
      "     - -------------------------------------- 3.7/119.2 MB 5.1 MB/s eta 0:00:23\n",
      "     - -------------------------------------- 4.3/119.2 MB 5.5 MB/s eta 0:00:22\n",
      "     - -------------------------------------- 4.7/119.2 MB 5.8 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.2/119.2 MB 5.9 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.2/119.2 MB 5.9 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.2/119.2 MB 5.9 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.2/119.2 MB 5.9 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.2/119.2 MB 5.9 MB/s eta 0:00:20\n",
      "     - -------------------------------------- 5.6/119.2 MB 5.1 MB/s eta 0:00:23\n",
      "     - -------------------------------------- 5.9/119.2 MB 5.1 MB/s eta 0:00:23\n",
      "     -- ------------------------------------- 6.4/119.2 MB 5.3 MB/s eta 0:00:22\n",
      "     -- ------------------------------------- 7.0/119.2 MB 5.6 MB/s eta 0:00:21\n",
      "     -- ------------------------------------- 7.9/119.2 MB 6.1 MB/s eta 0:00:19\n",
      "     -- ------------------------------------- 8.8/119.2 MB 6.5 MB/s eta 0:00:17\n",
      "     --- ------------------------------------ 9.1/119.2 MB 6.6 MB/s eta 0:00:17\n",
      "     --- ------------------------------------ 9.3/119.2 MB 6.5 MB/s eta 0:00:17\n",
      "     --- ----------------------------------- 10.0/119.2 MB 6.7 MB/s eta 0:00:17\n",
      "     --- ----------------------------------- 10.7/119.2 MB 8.1 MB/s eta 0:00:14\n",
      "     --- ----------------------------------- 11.7/119.2 MB 8.8 MB/s eta 0:00:13\n",
      "     --- ----------------------------------- 11.8/119.2 MB 8.8 MB/s eta 0:00:13\n",
      "     ---- ---------------------------------- 12.6/119.2 MB 9.6 MB/s eta 0:00:12\n",
      "     ---- ---------------------------------- 13.2/119.2 MB 9.6 MB/s eta 0:00:12\n",
      "     ---- --------------------------------- 14.2/119.2 MB 10.2 MB/s eta 0:00:11\n",
      "     ---- --------------------------------- 15.1/119.2 MB 10.6 MB/s eta 0:00:10\n",
      "     ---- --------------------------------- 15.5/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 15.5/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 15.5/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 15.5/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ---- --------------------------------- 15.5/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ----- -------------------------------- 16.6/119.2 MB 11.3 MB/s eta 0:00:10\n",
      "     ----- -------------------------------- 17.2/119.2 MB 11.5 MB/s eta 0:00:09\n",
      "     ----- -------------------------------- 18.4/119.2 MB 11.9 MB/s eta 0:00:09\n",
      "     ------ ------------------------------- 19.7/119.2 MB 13.1 MB/s eta 0:00:08\n",
      "     ------ ------------------------------- 21.0/119.2 MB 13.9 MB/s eta 0:00:08\n",
      "     ------- ------------------------------ 22.1/119.2 MB 14.9 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 22.9/119.2 MB 15.2 MB/s eta 0:00:07\n",
      "     ------- ------------------------------ 24.2/119.2 MB 15.6 MB/s eta 0:00:07\n",
      "     -------- ----------------------------- 25.4/119.2 MB 16.0 MB/s eta 0:00:06\n",
      "     -------- ----------------------------- 27.0/119.2 MB 26.2 MB/s eta 0:00:04\n",
      "     --------- ---------------------------- 28.7/119.2 MB 29.8 MB/s eta 0:00:04\n",
      "     --------- ---------------------------- 29.6/119.2 MB 29.7 MB/s eta 0:00:04\n",
      "     --------- ---------------------------- 30.3/119.2 MB 26.2 MB/s eta 0:00:04\n",
      "     ---------- --------------------------- 31.7/119.2 MB 27.3 MB/s eta 0:00:04\n",
      "     ---------- --------------------------- 32.6/119.2 MB 25.2 MB/s eta 0:00:04\n",
      "     ----------- -------------------------- 34.7/119.2 MB 28.4 MB/s eta 0:00:03\n",
      "     ----------- -------------------------- 36.6/119.2 MB 29.7 MB/s eta 0:00:03\n",
      "     ------------ ------------------------- 38.5/119.2 MB 29.7 MB/s eta 0:00:03\n",
      "     ------------ ------------------------- 40.2/119.2 MB 36.4 MB/s eta 0:00:03\n",
      "     ------------- ------------------------ 41.9/119.2 MB 40.9 MB/s eta 0:00:02\n",
      "     -------------- ----------------------- 44.1/119.2 MB 43.5 MB/s eta 0:00:02\n",
      "     -------------- ----------------------- 45.1/119.2 MB 38.6 MB/s eta 0:00:02\n",
      "     -------------- ----------------------- 46.1/119.2 MB 40.9 MB/s eta 0:00:02\n",
      "     -------------- ----------------------- 46.2/119.2 MB 32.7 MB/s eta 0:00:03\n",
      "     -------------- ----------------------- 46.2/119.2 MB 32.7 MB/s eta 0:00:03\n",
      "     -------------- ----------------------- 46.2/119.2 MB 24.2 MB/s eta 0:00:04\n",
      "     -------------- ----------------------- 46.3/119.2 MB 23.4 MB/s eta 0:00:04\n",
      "     --------------- ---------------------- 47.6/119.2 MB 21.1 MB/s eta 0:00:04\n",
      "     --------------- ---------------------- 49.7/119.2 MB 21.1 MB/s eta 0:00:04\n",
      "     ---------------- --------------------- 51.6/119.2 MB 21.1 MB/s eta 0:00:04\n",
      "     ----------------- -------------------- 53.7/119.2 MB 21.1 MB/s eta 0:00:04\n",
      "     ------------------ ------------------- 56.6/119.2 MB 43.7 MB/s eta 0:00:02\n",
      "     ------------------ ------------------- 58.9/119.2 MB 50.4 MB/s eta 0:00:02\n",
      "     ------------------- ------------------ 60.4/119.2 MB 46.7 MB/s eta 0:00:02\n",
      "     ------------------- ------------------ 61.9/119.2 MB 43.5 MB/s eta 0:00:02\n",
      "     -------------------- ----------------- 62.9/119.2 MB 46.9 MB/s eta 0:00:02\n",
      "     -------------------- ----------------- 63.5/119.2 MB 36.3 MB/s eta 0:00:02\n",
      "     -------------------- ----------------- 65.7/119.2 MB 34.6 MB/s eta 0:00:02\n",
      "     --------------------- ---------------- 68.2/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     ---------------------- --------------- 69.2/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     ---------------------- --------------- 69.9/119.2 MB 28.5 MB/s eta 0:00:02\n",
      "     ----------------------- -------------- 72.7/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     ----------------------- -------------- 73.3/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     ------------------------ ------------- 75.9/119.2 MB 36.3 MB/s eta 0:00:02\n",
      "     ------------------------ ------------- 77.3/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     ------------------------ ------------- 78.3/119.2 MB 32.7 MB/s eta 0:00:02\n",
      "     ------------------------- ------------ 80.6/119.2 MB 36.4 MB/s eta 0:00:02\n",
      "     -------------------------- ----------- 82.8/119.2 MB 36.3 MB/s eta 0:00:02\n",
      "     -------------------------- ----------- 83.3/119.2 MB 34.4 MB/s eta 0:00:02\n",
      "     --------------------------- ---------- 86.5/119.2 MB 38.5 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 88.0/119.2 MB 38.5 MB/s eta 0:00:01\n",
      "     ---------------------------- --------- 88.8/119.2 MB 36.3 MB/s eta 0:00:01\n",
      "     ----------------------------- -------- 91.8/119.2 MB 38.5 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 94.2/119.2 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------------ ------- 96.5/119.2 MB 43.7 MB/s eta 0:00:01\n",
      "     ------------------------------- ------ 99.1/119.2 MB 59.5 MB/s eta 0:00:01\n",
      "     ------------------------------- ----- 101.4/119.2 MB 50.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 103.3/119.2 MB 50.4 MB/s eta 0:00:01\n",
      "     -------------------------------- ---- 105.0/119.2 MB 50.4 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 106.4/119.2 MB 50.4 MB/s eta 0:00:01\n",
      "     --------------------------------- --- 108.7/119.2 MB 43.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 110.7/119.2 MB 46.7 MB/s eta 0:00:01\n",
      "     ---------------------------------- -- 112.0/119.2 MB 40.9 MB/s eta 0:00:01\n",
      "     ----------------------------------- - 114.5/119.2 MB 43.5 MB/s eta 0:00:01\n",
      "     ------------------------------------  116.8/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------  119.2/119.2 MB 46.9 MB/s eta 0:00:01\n",
      "     ------------------------------------- 119.2/119.2 MB 16.8 MB/s eta 0:00:00\n",
      "  Preparing metadata (setup.py): started\n",
      "  Preparing metadata (setup.py): finished with status 'done'\n",
      "Requirement already satisfied: spacy<3.8.0,>=3.7.4 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from en_ner_eco_md==1.1.0) (3.7.5)\n",
      "Requirement already satisfied: spacy-legacy<3.1.0,>=3.0.11 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.0.12)\n",
      "Requirement already satisfied: spacy-loggers<2.0.0,>=1.0.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (1.0.4)\n",
      "Requirement already satisfied: murmurhash<1.1.0,>=0.28.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (1.0.12)\n",
      "Requirement already satisfied: cymem<2.1.0,>=2.0.2 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2.0.11)\n",
      "Requirement already satisfied: preshed<3.1.0,>=3.0.2 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.0.6)\n",
      "Requirement already satisfied: thinc<8.3.0,>=8.2.2 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (8.2.5)\n",
      "Requirement already satisfied: wasabi<1.2.0,>=0.9.1 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.9.1)\n",
      "Requirement already satisfied: srsly<3.0.0,>=2.4.3 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2.5.1)\n",
      "Requirement already satisfied: catalogue<2.1.0,>=2.0.6 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2.0.10)\n",
      "Requirement already satisfied: weasel<0.5.0,>=0.1.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.3.4)\n",
      "Requirement already satisfied: typer<1.0.0,>=0.3.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.4.2)\n",
      "Requirement already satisfied: tqdm<5.0.0,>=4.38.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (4.67.1)\n",
      "Requirement already satisfied: requests<3.0.0,>=2.13.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2.32.3)\n",
      "Requirement already satisfied: pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (1.8.2)\n",
      "Requirement already satisfied: jinja2 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.1.6)\n",
      "Requirement already satisfied: setuptools in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (75.8.0)\n",
      "Requirement already satisfied: packaging>=20.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (24.2)\n",
      "Requirement already satisfied: langcodes<4.0.0,>=3.2.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.3.0)\n",
      "Requirement already satisfied: numpy>=1.19.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (1.26.4)\n",
      "Requirement already satisfied: typing-extensions>=3.7.4.3 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from pydantic!=1.8,!=1.8.1,<3.0.0,>=1.7.4->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (4.13.2)\n",
      "Requirement already satisfied: charset-normalizer<4,>=2 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.3.2)\n",
      "Requirement already satisfied: idna<4,>=2.5 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.7)\n",
      "Requirement already satisfied: urllib3<3,>=1.21.1 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2.3.0)\n",
      "Requirement already satisfied: certifi>=2017.4.17 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from requests<3.0.0,>=2.13.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (2025.1.31)\n",
      "Requirement already satisfied: blis<0.8.0,>=0.7.8 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.7.11)\n",
      "Requirement already satisfied: confection<1.0.0,>=0.0.1 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from thinc<8.3.0,>=8.2.2->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.1.4)\n",
      "Requirement already satisfied: colorama in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from tqdm<5.0.0,>=4.38.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.4.6)\n",
      "Requirement already satisfied: click<9.0.0,>=7.1.1 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from typer<1.0.0,>=0.3.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (7.1.2)\n",
      "Requirement already satisfied: cloudpathlib<0.17.0,>=0.7.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (0.16.0)\n",
      "Requirement already satisfied: smart-open<7.0.0,>=5.2.1 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from weasel<0.5.0,>=0.1.0->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (5.2.1)\n",
      "Requirement already satisfied: MarkupSafe>=2.0 in c:\\users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages (from jinja2->spacy<3.8.0,>=3.7.4->en_ner_eco_md==1.1.0) (3.0.2)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "DEPRECATION: textract 1.6.5 has a non-standard dependency specifier extract-msg<=0.29.*. pip 24.1 will enforce this behaviour change. A possible replacement is to upgrade to a newer version of textract or contact the author to suggest that they release a version with a conforming dependency specifiers. Discussion can be found at https://github.com/pypa/pip/issues/12063\n",
      "\n",
      "[notice] A new release of pip is available: 24.0 -> 25.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# import stanza\n",
    "# import textacy\n",
    "# from fastcoref import FCoref\n",
    "# from taxonerd import TaxoNERD\n",
    "# from spacy.matcher import Matcher\n",
    "# from spacy.matcher import DependencyMatcher\n",
    "!pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_biobert-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_md_weak-1.1.0.tar.gz\n",
    "# !pip install https://github.com/nleguillarme/taxonerd/releases/download/v1.5.4/en_ner_eco_biobert_weak-1.1.0.tar.gz"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "id": "e08158a6-a956-4c35-a791-64c7702d01bb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# sp_nlp = spacy.load(\"en_core_web_sm\")\n",
    "# st_nlp = stanza.Pipeline(lang='en', processors='tokenize')\n",
    "tn_nlp = TaxoNERD().load(model=\"en_ner_eco_biobert\")\n",
    "# fcoref = FCoref(enable_progress_bar=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 260,
   "id": "31b1427f-2ddb-4132-aad8-f0b4421f65a4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# !pip freeze > requirements1.txt\n",
    "# !pip install nltk\n",
    "# import nltk\n",
    "# nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 364,
   "id": "0ed65dd1-7512-4644-87c4-af7fe379dd84",
   "metadata": {},
   "outputs": [],
   "source": [
    "# There's no definite names for these patterns as I do not know what\n",
    "# to call them. These patterns are used to extract possessive\n",
    "# relationships from a sentence. I also could not find better names for\n",
    "# the two variables below.\n",
    "OWNER = \"owner\"\n",
    "OWNED = \"owned\"\n",
    "\n",
    "pattern_1 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": OWNED,\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"poss\"\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_2 = [\n",
    "     {\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": OWNED,\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"adp\",\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"prep\",\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"ADP\"]\n",
    "            }\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"adp\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"pobj\",\n",
    "            \"POS\": {\n",
    "                \"IN\": [\"NOUN\"]\n",
    "            }\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_3 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"nsubj\",\n",
    "            \"POS\": {\"IN\": [\"PRON\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"dobj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "pattern_4 = [\n",
    "    {\n",
    "        \"RIGHT_ID\": \"verb\",\n",
    "        \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNED,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"nsubj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"verb\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": \"adp\",\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"prep\",\n",
    "            \"POS\": {\"IN\": [\"ADP\"]}\n",
    "        }\n",
    "    },\n",
    "    {\n",
    "        \"LEFT_ID\": \"adp\",\n",
    "        \"REL_OP\": \">\",\n",
    "        \"RIGHT_ID\": OWNER,\n",
    "        \"RIGHT_ATTRS\": {\n",
    "            \"DEP\": \"pobj\",\n",
    "            \"POS\": {\"IN\": [\"NOUN\"]}\n",
    "        }\n",
    "    }\n",
    "]\n",
    "\n",
    "patterns = {\n",
    "    \"Pattern1\": pattern_1,\n",
    "    \"Pattern2\": pattern_2,\n",
    "    \"Pattern3\": pattern_3,\n",
    "    \"Pattern4\": pattern_4,\n",
    "}\n",
    "\n",
    "def dependency_matcher(sp_nlp):\n",
    "    matcher = DependencyMatcher(sp_nlp.vocab)\n",
    "    for pattern_id, pattern in patterns.items():\n",
    "        matcher.add(pattern_id, [pattern])\n",
    "    return matcher\n",
    "\n",
    "def index_to_what(sp_nlp, sp_doc, what_matches):\n",
    "    index_to_what_map = {}\n",
    "    for match_id, token_ids in what_matches:\n",
    "        pattern_id = sp_nlp.vocab.strings[match_id]\n",
    "        # print(pattern_id)\n",
    "        owner = None\n",
    "        owned = None\n",
    "        for i in range(len(token_ids)):\n",
    "            right_id = patterns[pattern_id][i][\"RIGHT_ID\"]\n",
    "            if right_id == OWNER:\n",
    "                owner = sp_doc[token_ids[i]]\n",
    "            if right_id == OWNED:\n",
    "                owned = sp_doc[token_ids[i]]\n",
    "        if owner.i not in index_to_what_map:\n",
    "            index_to_what_map[owner.i] = []\n",
    "        index_to_what_map[owner.i].append(owned)\n",
    "        if owned.i not in index_to_what_map:\n",
    "            index_to_what_map[owned.i] = []\n",
    "        index_to_what_map[owned.i].append(owner)\n",
    "\n",
    "    return index_to_what_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 404,
   "id": "ec57a613-6944-47d8-b840-108707fb4cdd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def split_sentence(sp_doc, svo, prev_svo, next_svo):\n",
    "    sub_l_i = 0 if not prev_svo else prev_svo.object[-1].i + 1\n",
    "    sub_r_i = svo.verb[0].i\n",
    "\n",
    "    while sub_l_i < len(sp_doc) and sp_doc[sub_l_i].sent.start != svo.subject[0].sent.start:\n",
    "        sub_l_i += 1\n",
    "        \n",
    "    obj_l_i = svo.verb[-1].i + 1\n",
    "    obj_r_i = len(sp_doc) - 1 if not next_svo else next_svo.subject[0].i\n",
    "\n",
    "    while obj_r_i >= 0 and sp_doc[obj_r_i].sent.start != svo.object[0].sent.start:\n",
    "        obj_r_i -= 1\n",
    "\n",
    "    return sp_doc[sub_l_i:sub_r_i], sp_doc[obj_l_i:obj_r_i+1]\n",
    "\n",
    "\n",
    "def index_to_cluster(fc_predictions):\n",
    "    index_to_cluster_map = {}\n",
    "    for prediction in fc_predictions:\n",
    "        clusters = prediction.get_clusters(as_strings=False)\n",
    "        for cluster in clusters:\n",
    "            for token in cluster:\n",
    "                index = token[0]\n",
    "                index_to_cluster_map[index] = cluster\n",
    "    return index_to_cluster_map\n",
    "\n",
    "def species_indices(tn_doc):\n",
    "    indices = []\n",
    "    for species_span in tn_doc.ents:\n",
    "        for species in species_span:\n",
    "            indices.append(species.idx)\n",
    "    return indices\n",
    "\n",
    "def is_species(tokens, context, species_indices):\n",
    "    for token in [*tokens, *context]:\n",
    "        if token.idx in species_indices:\n",
    "            # print(f\"\\t\\t\\tToken '{token.text}' is a Species\")\n",
    "            return True\n",
    "    return False\n",
    "\n",
    "def get_related_possessions(tokens, what_map):\n",
    "    related = []\n",
    "    for token in tokens:\n",
    "        if token.i in what_map:\n",
    "            related += what_map[token.i]\n",
    "    return related\n",
    "\n",
    "def filter_by_species(tokens, species_indices):\n",
    "    filtered = []\n",
    "    for token in tokens:\n",
    "        if token.idx in species_indices:\n",
    "            filtered.append(token)\n",
    "    return filtered\n",
    "\n",
    "def same_reference(tokensA, tokensB, cluster_map):\n",
    "    clustersA = set()\n",
    "    for token in tokensA:\n",
    "        if token.idx in cluster_map:\n",
    "            for cluster_token in cluster_map[token.idx]:\n",
    "                clustersA.add(cluster_token)\n",
    "    clustersB = set()\n",
    "    for token in tokensB:\n",
    "        if token.idx in cluster_map:\n",
    "            for cluster_token in cluster_map[token.idx]:\n",
    "                clustersB.add(cluster_token)\n",
    "\n",
    "    if not set(clustersA).isdisjoint(clustersB):\n",
    "        return False\n",
    "    return True\n",
    "    \n",
    "def parse(text, verbose=False):\n",
    "    sp_doc = sp_nlp(text)\n",
    "    tn_doc = tn_nlp(text)\n",
    "    species = species_indices(tn_doc)\n",
    "\n",
    "    matcher = dependency_matcher(sp_nlp)\n",
    "    matches = matcher(sp_doc)\n",
    "    what_map = index_to_what(sp_nlp, sp_doc, matches)\n",
    "\n",
    "    predictions = fcoref.predict(texts=[text])\n",
    "    cluster_map = index_to_cluster(predictions)\n",
    "    print(cluster_map)\n",
    "    # print(what_map)\n",
    "\n",
    "    data = {}\n",
    "    \n",
    "    svo_triples = list(textacy.extract.subject_verb_object_triples(sp_doc))\n",
    "    for index, svo_triple in enumerate(svo_triples):\n",
    "        # Data to Mine\n",
    "        data = {\n",
    "            \"source\": \"\",\n",
    "            \"source_trait\": \"\",\n",
    "            \"source_change\": \"\",\n",
    "            \"target\": \"\",\n",
    "            \"target_trait\": \"\",\n",
    "            \"target_change\": \"\"\n",
    "        }\n",
    "        \n",
    "        print(svo_triple)\n",
    "\n",
    "        prev_svo = None if index == 0 else svo_triples[index - 1]\n",
    "        next_svo = None if index >= len(svo_triples) - 1 else svo_triples[index + 1]\n",
    "\n",
    "        sub_context, obj_context = split_sentence(sp_doc, svo_triple, prev_svo, next_svo)\n",
    "        # print(f\"Sub Context: {sub_context}\")\n",
    "        # print(f\"Obj Context: {obj_context}\")\n",
    "\n",
    "        base_verb_docs = [sp_nlp(verb) for verb in [\"exhibited\"]]\n",
    "        verb_docs = [sp_nlp(verb.text) for verb in svo_triple.verb]\n",
    "\n",
    "        same_ref = False\n",
    "        for base_verb_doc in base_verb_docs:\n",
    "            for verb_doc in verb_docs:\n",
    "                similarity = base_verb_doc.similarity(verb_doc)\n",
    "                if similarity > 0.7:\n",
    "                    same_ref = True\n",
    "        \n",
    "        if same_ref:\n",
    "            print(\"!!!\")\n",
    "            sub_is_species = is_species(svo_triple.subject, [], species)\n",
    "            if sub_is_species:\n",
    "                data[\"source\"] = svo_triple.subject\n",
    "                data[\"source_trait\"] = svo_triple.object\n",
    "            else:\n",
    "                data[\"source_trait\"] = svo_triple.subject\n",
    "                data[\"source\"] = svo_triple.object\n",
    "        else:\n",
    "            sub_is_species = is_species(svo_triple.subject, [], species)\n",
    "            if sub_is_species:\n",
    "                data[\"source\"] = svo_triple.subject\n",
    "            if not sub_is_species:\n",
    "                data[\"source_trait\"] = svo_triple.subject\n",
    "                data[\"source\"] = filter_by_species(get_related_possessions(svo_triple.subject, what_map), species)\n",
    "    \n",
    "            obj_is_species = is_species(svo_triple.object, [], species)\n",
    "            if obj_is_species:\n",
    "                data[\"target\"] = svo_triple.object\n",
    "            if not obj_is_species:\n",
    "                data[\"target_trait\"] = svo_triple.object\n",
    "                data[\"target\"] = filter_by_species(get_related_possessions(svo_triple.object, what_map), species)\n",
    "\n",
    "        print(data)\n",
    "            \n",
    "        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 401,
   "id": "da13dc42-2e24-4fe4-9265-7e69238ba24b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2025 23:46:27 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 50.37 examples/s]\n",
      "04/26/2025 23:46:27 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{0: [(0, 12), (108, 112)], 108: [(0, 12), (108, 112)]}\n",
      "SVOTriple(subject=[Grasshoppers], verb=[exhibited], object=[diet, shifts])\n",
      "{'source': [Grasshoppers], 'source_trait': [diet, shifts], 'source_change': '', 'target': '', 'target_trait': '', 'target_change': ''}\n"
     ]
    }
   ],
   "source": [
    "# Example 1\n",
    "text = \"Grasshoppers exhibited significant diet shifts from grass to herbs (Kruskal-Wallis test, P 0.01, df 3) when they were in the presence of the comparatively sedentary species (the smaller Pisaurina and the larger Hogna) compared to controls without spiders (Fig. 2).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 402,
   "id": "5b004db1-f2eb-444d-b9c8-53b9447c84a2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2025 23:46:30 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 57.45 examples/s]\n",
      "04/26/2025 23:46:31 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{}\n",
      "SVOTriple(subject=[phototrophs], verb=[can, decrease], object=[population, density])\n",
      "{'source': [], 'source_trait': [phototrophs], 'source_change': '', 'target': [bacteria], 'target_trait': [population, density], 'target_change': ''}\n"
     ]
    }
   ],
   "source": [
    "# Example 2\n",
    "text = \"Our results show that phototrophs can indirectly decrease the population density of heterotrophic bacteria by modification of the nature of bacterial interactions with predators.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 405,
   "id": "d6cdea8d-4a22-409f-9f0a-e01d1691a67e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "04/26/2025 23:49:49 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|████████████████████████████████████████████████████████████████████████| 1/1 [00:00<00:00, 64.41 examples/s]\n",
      "04/26/2025 23:49:49 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{61: [(61, 78), (121, 133)], 121: [(61, 78), (121, 133)]}\n",
      "SVOTriple(subject=[predators], verb=[inflicted], object=[mortality])\n",
      "!!!\n",
      "{'source': [mortality], 'source_trait': [predators], 'source_change': '', 'target': '', 'target_trait': '', 'target_change': ''}\n"
     ]
    }
   ],
   "source": [
    "# Example 3\n",
    "text = \"All predators inflicted significant mortality on the prey at each prey density compared to the predator-free control for that density\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 296,
   "id": "33114ff6-7277-4613-b1a8-c51e7dd2652b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Verb: show, Source: None, Target: None\n",
      "\n",
      "Verb: associated, Source: None, Target: increase\n",
      "\n",
      "Verb: studied, Source: None, Target: None\n",
      "\n",
      "Verb: weaken, Source: which, Target: mutualism\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Example 4\n",
    "text = \"Our results show that an increase in sediment organic matter content is associated to a decline in the abundance of Loripes lucinalis (lucinid bivalve) in the Cymodocea nodosa meadows studied, which potentially may weaken the mutualism between the two species.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "id": "c27d6d1e-6766-41db-98ee-e749b287b457",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{3: [abundance], 1: [lucinids], 12: [correlation, sediments], 7: [content], 15: [content], 28: [correlation], 25: [ones]}\n",
      "SVOTriple(subject=[abundance], verb=[showed], object=[correlation, 3a, 3b])\n",
      "Sub Context: The abundance of lucinids\n",
      "Obj Context: \n",
      "Related Possessions: [lucinids]\n",
      "Related Possessions: [content]\n",
      "SVOTriple(subject=[abundance], verb=[showed], object=[correlation])\n",
      "Sub Context: \n",
      "Obj Context: no correlation in bare ones (Fig. 3b).\n",
      "Related Possessions: [lucinids]\n",
      "Related Possessions: [ones]\n"
     ]
    }
   ],
   "source": [
    "# Example 5\n",
    "text = \"The abundance of lucinids showed a negative correlation with the organic matter content in vegetated sediments (Fig. 3a), but showed no correlation in bare ones (Fig. 3b).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "id": "49b69b68-f60b-4b93-bff9-249871141e0d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[presence, bullfrog, tadpoles], verb=[had], object=[effects])\n",
      "Sub Context: The MANOVA on the cattle tank experiment showed that the presence of Tramea, nonlethal Anax, and large bullfrog tadpoles all\n",
      "Obj Context: significant effects on both small tadpole species (Table 1).\n",
      "\t\t\tToken 'bullfrog' is a Species\n",
      "Subject is Species\n",
      "Object is Trait\n"
     ]
    }
   ],
   "source": [
    "# Example 6\n",
    "text = \"The MANOVA on the cattle tank experiment showed that the presence of Tramea, nonlethal Anax, and large bullfrog tadpoles all had significant effects on both small tadpole species (Table 1).\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 331,
   "id": "000f8dec-49ce-4f9c-8493-924b3fb11b3c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "SVOTriple(subject=[presence], verb=[modified], object=[tank, environment])\n",
      "Sub Context: Thus the presence of predators, both nonlethal Anax and lethal Tramea,\n",
      "Obj Context: the tank environment in a way that\n",
      "Subject is Trait\n",
      "Object is Trait\n",
      "SVOTriple(subject=[that], verb=[facilitated], object=[invasion])\n",
      "Sub Context: in a way that\n",
      "Obj Context: invasion by midges, but only in the absence of large bullfrogs.\n",
      "Subject is Trait\n",
      "Object is Trait\n"
     ]
    }
   ],
   "source": [
    "# Example 7\n",
    "text = \"Thus the presence of predators, both nonlethal Anax and lethal Tramea, modified the tank environment in a way that facilitated invasion by midges, but only in the absence of large bullfrogs.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a5a91ee-a37d-4dbb-bf97-d7e417ceac18",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 8\n",
    "text = \"We hypothesized that the presence of Anax would decrease foraging activity of small tadpoles, which in turn would decrease predation by Tramea on the small tadpoles\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a1e34cb4-3056-4011-a4e2-cdd97bc274be",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 9\n",
    "text = '''Only a fraction of the individuals in a given prey population are likely to be killed and consumed by predators. In contrast, nearly all individuals experience the chronic effects of predation risk. When threatened by predators, prey adopt defensive tactics whole costs can lead to reduced growth, maturation rates, survivorship, fecundity, or population density. This nonconsumptive impact of predation risk on prey is known as a \"trait-mediated interaction\" (TMI) because it results from changes in prey traits such as behavior or physiology. Ecological theory suggests that the strength of TMI effects will reflect a balance between the conflicting demands of reproduction vs. predator avoidance. Competitor density and resource availability are expected to alter the balance between these conflicting forces. We conducted a meta-analysis of experimental studies that measured TMI effect size while varying competitor and/or resource density. The threat of predation had an overall negative effect on prey performance, but the strength of this effect varied with the level of competition. High competition exacerbated the negative effect of intimidation on prey density but moderated the negative effect of intimidation on prey life history and growth. We discuss these results in light of previously published theoretical expectations. Our results highlight the variable and context-dependent nature of interspecific interactions.'''\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44b3f503-2740-447a-a9bf-b6fdc6813d3e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 10\n",
    "text = \"Current theory on trophic interactions in food webs assumes that ecologically similar species can be treated collectively as a single functional unit such as a guild or trophic level. This theory implies that all species within that unit transmit identical direct and indirect effects throughout the community. We evaluated this assumption by conducting experiments to compare the direct and indirect effects of three top-predator species, belonging to the same hunting spider guild, on the same species of grasshopper and on old-field grasses and herbs. Observations under field conditions revealed that each spider species exhibited different hunting behavior (i.e., sit-and-wait, sit-and-pursue, and active hunting) and occupied different locations within the vegetation canopy. These differences resulted in different direct effects on grasshopper prey. Grasshoppers demonstrated significant behavioral (diet) shifts in the presence of sit-and-wait and sit-and-pursue species but not when faced with actively hunting species. Grasshopper density was significantly reduced by spider species that occupied lower parts of the vegetation canopy (sit-and-pursue and actively hunting species), but it was not significantly reduced by the sit-and-wait spider species that occupied the upper parts of the canopy. These direct effects manifested themselves differently in the plant trophic level. The sit-and-wait spider caused indirect effects on plants by changing grasshopper foraging behavior (a trait-mediated effect). The sit-and-pursue spider caused indirect effects by reducing grasshopper density (density-mediated effects); the effects of changes in grasshopper behavior were thus not reflected in the plant trophic level. The actively hunting spiders had strictly density-mediated indirect effects on plants. The study offers mechanistic insight into how predator species within the same guild can have very different trophic effects in food webs. Thus classical modeling approaches that treat all predator species as a single functional unit may not adequately capture biologically relevant details that influence community dynamics.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dabe9ad1-d62d-44d0-8702-6403d6a2f6c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 11\n",
    "text = \"Diversity and plasticity are hallmarks of cells of the monocyte-macrophage lineage. In response to IFNs, Toll-like receptor engagement, or IL-4/IL-13 signaling, macrophages undergo M1 (classical) or M2 (alternative) activation, which represent extremes of a continuum in a universe of activation states. Progress has now been made in defining the signaling pathways, transcriptional networks, and epigenetic mechanisms underlying M1-M2 or M2-like polarized activation. Functional skewing of mononuclear phagocytes occurs in vivo under physiological conditions (e.g., ontogenesis and pregnancy) and in pathology (allergic and chronic inflammation, tissue repair, infection, and cancer). However, in selected preclinical and clinical conditions, coexistence of cells in different activation states and unique or mixed phenotypes have been observed, a reflection of dynamic changes and complex tissue-derived signals. The identification of mechanisms and molecules associated with macrophage plasticity and polarized activation provides a basis for macrophage-centered diagnostic and therapeutic strategies.\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3daaf223-9f81-4b6b-9f76-f966687536e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example 12\n",
    "text = \"The stranger hit a bystander, the man hit a stranger\"\n",
    "parse(text)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d42c03e1-9ede-4f8d-964c-e900b6ea833d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
