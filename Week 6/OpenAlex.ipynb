{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "46d61a79-03c1-41ad-be1a-a9220aa1c334",
   "metadata": {},
   "outputs": [],
   "source": [
    "# OpenAlex: Finding Papers\n",
    "# Let's say we have a set or an array of keywords.\n",
    "# We can use OpenAlex to find a large number of papers\n",
    "# that, in some way, match those keywords. This is an\n",
    "# example of how it could work. Furthermore, Veronica\n",
    "# mentioned how there's other characteristics that you\n",
    "# may be looking for, like how far back you want to go\n",
    "# in searching for papers.\n",
    "from pyalex import Works\n",
    "\n",
    "# Later, I'll use these URLs to try out the PDF to text\n",
    "# tools. If there's any.\n",
    "urls = []\n",
    "number_urls = 0\n",
    "\n",
    "keywords = [\"Machine Learning\"]\n",
    "\n",
    "pager = Works().search_filter(title=keywords[0]).paginate(per_page=200)\n",
    "number_works = 0\n",
    "\n",
    "for page in pager:\n",
    "    for work in page:        \n",
    "        print(f\"Title: {work['title']}\")\n",
    "        # You'll see that some PDFs do include URLs,\n",
    "        # while some do not. Maybe in these cases, we could\n",
    "        # instead use the abstract that OpenAlex provides.\n",
    "        # However, there are still chances that the abstract\n",
    "        # is also unavailable. Also, there was an instance of\n",
    "        # an incorrect abstract, so that's also something to \n",
    "        # consider.\n",
    "        print(f\"Abstract: {work['abstract']}\")\n",
    "        if work[\"primary_location\"]:\n",
    "            url = work[\"primary_location\"][\"pdf_url\"]\n",
    "            if url:\n",
    "                print(url)\n",
    "                urls.append(url)\n",
    "                number_urls += 1 \n",
    "        number_works += 1\n",
    "        print()\n",
    "    if number_urls >= 10 or number_works >= 50:\n",
    "        break\n",
    "\n",
    "print(f\"URLs: {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "88402eeb-79a5-446b-912f-5e5b94c33b34",
   "metadata": {},
   "outputs": [],
   "source": [
    "# URLs\n",
    "# As you may be able to see, the number of URLs provided are not plenty.\n",
    "# I'm not sure if this is important, but what if good papers are missed out on\n",
    "# because they don't have a PDF listed? Also, it seems that OpenAlex offers\n",
    "# everything, so I'm not sure if these are research papers that one would want\n",
    "# to use. Possibly a problem for a later day.\n",
    "# In case I can't find enough URLs, this serves to find any paper with an URL.\n",
    "# This is just for the \"testing\" later on.\n",
    "print(f\"URLs: {urls}\")\n",
    "if len(urls) < 10:\n",
    "    while len(urls) < 10:\n",
    "        work = Works().random()\n",
    "        while not work[\"primary_location\"] or not work[\"primary_location\"][\"pdf_url\"]:\n",
    "            work = Works().random()\n",
    "        urls.append(work[\"primary_location\"][\"pdf_url\"])\n",
    "print(f\"URLs: {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "3d0f2ec1-fab0-4cd4-85a8-48b8758d5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text\n",
    "# It's not logical to physically download a PDF\n",
    "# to reference it in the code. Especially if you're\n",
    "# going through thousands of PDFs. So, we can download\n",
    "# the bytes of an URL that links to said PDF to get the\n",
    "# PDF file. This code contains the simple process of\n",
    "# downloading the bytes of the PDF.\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def pdf_bytes(url):\n",
    "    r = requests.get(url)\n",
    "    f = io.BytesIO(r.content)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "44eb6101-24d9-444a-a7e4-9565f778ffa3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text: PyPDF\n",
    "# This doesn't seem to be useless, but it throws\n",
    "# exceptions easily. It's understandable why an\n",
    "# error would be thrown if the PDF cannot be parsed.\n",
    "# However, I wonder if this would cause problems with\n",
    "# the number of issues a PDF could have for whatever\n",
    "# reason.\n",
    "# This also works, but the text is not impressive.\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def pdf_to_text_pypdf(url):\n",
    "    f = pdf_bytes(url)\n",
    "    reader = PdfReader(f)\n",
    "    contents = reader.get_page(0).extract_text().split('\\n')\n",
    "    print(contents)\n",
    "    print(\" \".join(contents))\n",
    "\n",
    "pdf_to_text_pypdf(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3fccde31-c0b5-4611-af6f-3a27ad16e3b4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text: Tika\n",
    "# This has been running for at least\n",
    "# 13 minutes, possibly more. I can't tell\n",
    "# if it's stuck in an infinite loop, or if the\n",
    "# PDF is that long. It could be that the link \n",
    "# to the PDF is a download. I'm not sure if this \n",
    "# is affecting the parser. I'm going to stop it\n",
    "# and try a different URL. Now that I'm using a\n",
    "# PDF that works, I'm seeing that the server can't\n",
    "# be started. Honestly, with the performance of the\n",
    "# parser below, I don't think I'm going to try to\n",
    "# fix it.\n",
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "def pdf_to_text_tika(url):\n",
    "    f = pdf_bytes(url)\n",
    "    parsed = parser.from_buffer(f)\n",
    "    print(parsed[\"metadata\"])\n",
    "    print(parsed[\"content\"])\n",
    "\n",
    "# pdf_to_text_tika(\"https://nnjournal.net/article/download/75\")\n",
    "pdf_to_text_tika(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42309961-1979-4739-a1e0-a13442760258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text: Textract\n",
    "# I've seen this used by other packages I've installed.\n",
    "# The documentation does not look that helpful.\n",
    "# Also, I don't think they allow for file objects.\n",
    "# Onwards!\n",
    "# I think the prior parser was not working because the URL\n",
    "# was a download link and not the URL of a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "79ab83cc-acea-4a1c-a1c7-05eb17ac836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x000001FB86C3F100>\n",
      "Machine Learning 3: 95-99, 1988\n",
      "Â© 1988 Kluwer Academic Publishers - Manufactured in The Netherlands\n",
      "GUEST EDITORIAL\n",
      "Genetic Algorithms and Machine Learning\n",
      "Metaphors for learning\n",
      "There is no a priori reason why machine learning must borrow from nature.\n",
      "A field could exist, complete with well-defined algorithms, data structures,\n",
      "and theories of learning, without once referring to organisms, cognitive or\n",
      "genetic structures, and psychological or evolutionary theories. Yet at the end\n",
      "of the day, with the position papers written, the computers plugged in, and\n",
      "the programs debugged, a learning edifice devoid of natural metaphor would\n",
      "lack something. It would ignore the fact that all these creations have become\n",
      "possible only after three billion years of evolution on this planet. It would\n",
      "miss the point that the very ideas of adaptation and learning are concepts\n",
      "invented by the most recent representatives of the species Homo sapiens from\n",
      "the careful observation of themselves and life around them. It would miss the\n",
      "point that natural examples of learning and adaptation are treasure troves of\n",
      "robust procedures and structures.\n",
      "Fortunately, the field of machine learning does rely upon nature's bounty\n",
      "for both inspiration and mechanism. Many machine learning systems now\n",
      "borrow heavily from current thinking in cognitive science, and rekindled in-\n",
      "terest in neural networks and connectionism is evidence of serious mechanistic\n",
      "and philosophical currents running through the field. Another area where nat-\n",
      "ural example has been tapped is in work on genetic algorithms (GAs) and\n",
      "genetics-based machine learning. Rooted in the early cybernetics movement\n",
      "(Holland, 1962), progress has been made in both theory (Holland, 1975; Hol-\n",
      "land, Holyoak, Nisbett, & Thagard, 1986) and application (Goldberg, 1989;\n",
      "Grefenstette, 1985, 1987) to the point where genetics-based systems are find-\n",
      "ing their way into everyday commercial use (Davis & Coombs, 1987; Fourman,\n",
      "1985).\n",
      "Genetic algorithms and classifier systems\n",
      "This special double issue of Machine Learning is devoted to papers concern-\n",
      "ing genetic algorithms and genetics-based learning systems. Simply stated,\n",
      "genetic algorithms are probabilistic search procedures designed to work on\n",
      "large spaces involving states that can be represented by strings. These meth-\n",
      "ods are inherently parallel, using a distributed set of samples from the space\n",
      "(a population of strings) to generate a new set of samples. They also ex-\n",
      "hibit a more subtle implicit parallelism. Roughly, in processing a population\n",
      "of m strings, a genetic algorithm implicitly evaluates substantially more than\n",
      "m3 component substrings. It then automatically biases future populations to\n",
      "exploit the above average components as building blocks from which to con-\n",
      "\n",
      "96\n",
      "D. E. GOLDBERG AND J. H. HOLLAND\n",
      "struct structures that will exploit regularities in the environment (problem\n",
      "space). Section 3 of the paper by Fitzpatrick and Grefenstette gives a clear\n",
      "discussion of this property. The theorem that establishes this speedup and its\n",
      "precursors - the schema theorems - illustrate the central role of theory in the\n",
      "development of genetic algorithms. Learning programs designed to exploit this\n",
      "building block property gain a substantial advantage in complex spaces where\n",
      "they must discover both the \"rules of the game\" and the strategies for playing\n",
      "that \"game.\"\n",
      "Although there are a number of different types of genetics-based machine\n",
      "learning systems, in this issue we concentrate on classifier systems and their\n",
      "derivatives. Classifier systems are parallel production systems that have been\n",
      "designed to exploit the implicit parallelism of genetic algorithms. All inter-\n",
      "actions are via standardized messages, so that conditions are simply defined\n",
      "in terms of the messages they accept and actions are defined in terms of the\n",
      "messages they send. The resulting systems are computationally complete, and\n",
      "the simple syntax makes it easy for a genetic algorithm to discover building\n",
      "blocks appropriate for the construction of new candidate rules. Because clas-\n",
      "sifier systems rely on competition to resolve conflicts, they need no algorithms\n",
      "for determining the global consistency of a set of rules. As a consequence, new\n",
      "rules can be inserted in an existing system, as trials or hypotheses, without\n",
      "disturbing established capacities. This gracefulness makes it possible for the\n",
      "system to operate incrementally, testing new structures and hypotheses while\n",
      "steadily improving its performance.\n",
      "Arguments for the evolutionary metaphor\n",
      "These attractive properties of genetics-based systems - explicit parallelism,\n",
      "implicit parallelism, and gracefulness - are explored more fully in the papers\n",
      "that follow. However, before proceeding further we must answer an important\n",
      "question. Of the two natural archetypes of learning available to us - the brain\n",
      "and evolution - why have genetic algorithm researchers knowingly adopted\n",
      "the \"wrong\" metaphor? One reason is expedience. The processes of natural\n",
      "evolution and natural genetics have been illuminated by a century of enormous\n",
      "progress in biology and molecular biology. In contrast, the brain, though\n",
      "yielding some of its secrets, remains largely an opaque gray box; we can only\n",
      "guess at many of the fundamental mechanisms contained therein.\n",
      "Of course, simple expedience is not the best reason for adopting a particular\n",
      "course of action, and at first glance, it is not at all obvious why learning in\n",
      "natural or artificial minds should be anything like the adaptation that has\n",
      "occurred in evolution. Yet there is an appealing symmetry in the notion that\n",
      "the mechanisms of natural learning may resemble the processes that created\n",
      "the species possessing those learning processes. Furthermore, the idea that the\n",
      "mind is subject to the same competitive-cooperative pressures as evolutionary\n",
      "systems has achieved some currency outside of GA circles (Bateson, 1972;\n",
      "Edelman, 1987; Minsky, 1986).\n",
      "Despite these suggestions, genetic algorithms and genetics-based machine\n",
      "learning have often been attacked on the grounds that natural evolution is\n",
      "simply too slow to accomplish anything useful in an artificial learning system;\n",
      "three billion years is longer than most people care to wait for a solution to a\n",
      "problem. However, this slowness argument ignores the obvious differences in\n",
      "\n",
      "GENETIC ALGORITHMS AND MACHINE LEARNING\n",
      "97\n",
      "time scale between natural systems and artificial systems. A more fundamental\n",
      "fault is that this argument ignores the robust complexity that evolution has\n",
      "achieved in its three billion years of operation. The 'genetic programs' of even\n",
      "the simplest living organisms are more complex than the most intricate human\n",
      "designs.\n",
      "Waddington (1967) presents more sophisticated probabilistic arguments that\n",
      "actual evolutionary processes have achieved a complexity in existing species\n",
      "that is incommensurate with an evolutionary process using only selection and\n",
      "mutation. Although such arguments were originally meant to challenge evolu-\n",
      "tionary theory, genetic algorithmists see no such challenge. Instead, the high\n",
      "speed-to-complexity level observed in nature lends support to the notion that\n",
      "reproduction, recombination, and the processing of building blocks result in\n",
      "the rapid development of appropriate complexity. Moreover, this speed is not\n",
      "purchased at the cost of generality. The mechanisms of genetics and genetic\n",
      "algorithms permit relative efficiency across a broad range of problems.\n",
      "Contents of the special issue\n",
      "This robust combination of breadth and efficiency is a recurring theme in\n",
      "work on genetic algorithms, and any collection of papers on the topic is likely\n",
      "to cover a broad range. The current set of papers has been selected to give\n",
      "a representative view of the major lines of research involving genetic algo-\n",
      "rithms. The first paper, by Fitzpatrick and Grefenstette, discusses the theory\n",
      "and application of a genetic algorithm in a difficult, noisy search domain -\n",
      "medical image registration. Next De Jong provides an overview and careful\n",
      "discussion of alternative approaches to machine learning using genetic algo-\n",
      "rithms. The third paper, by Robertson and Riolo, explores the problem of\n",
      "\"scaling up\" when one implements 8000 rule classifier systems on a massively\n",
      "parallel machine. After this, Booker discusses experiments with a simulated\n",
      "roving automaton, bridging the gap between theories of animal learning and\n",
      "machine learning. In the fifth paper, Belew and Forrest compare symbolic and\n",
      "subsymbolic approaches to machine learning, using a classifier-system imple-\n",
      "mentation of KL-ONE as their starting point. The final paper, by Grefenstette,\n",
      "experimentally compares various methods for credit assignment in these highly\n",
      "parallel systems.\n",
      "The abstracts provide an effective annotated table of contents that we will\n",
      "not try to duplicate here. However, it is worth extracting a few comments\n",
      "from the papers concerning the kinds of issues typical of research on genetic\n",
      "algorithms:\n",
      "Genetic algorithms search by allocating effort to regions of the search space\n",
      "based on an estimate of the relative performance of competing regions.\n",
      "[In complex domains] one expects perpetual novelty to be a characteristic\n",
      "feature ... In these cases, traditional search techniques ... are likely to be\n",
      "misled [and] genetic algorithms may be the search technique of choice for\n",
      "machine learning systems ... \n",
      "[Fitzpatrick and Grefenstette]\n",
      "If very little background knowledge is available and the problem environ-\n",
      "ment provides a natural measure for the quality of outcomes, it is appro-\n",
      "priate to view the problem of learning as a search for high-performance\n",
      "structures ... \n",
      "[Grefenstette]\n",
      "\n",
      "98\n",
      "D. E. GOLDBERG AND J. H. HOLLAND\n",
      "... the syntactic and semantic complexity of traditional languages makes it\n",
      "difficult to develop [structure-modifying] operators ... that preserve ... the\n",
      "syntactic integrity ... of the programs being manipulated ... An obvious\n",
      "next step [is to] focus on less traditional languages with simpler syntax and\n",
      "semantics [that can be subjected to] genetic operators. \n",
      "[De Jong]\n",
      "[It is important to provide] low-level learning systems that [support] repre-\n",
      "sentations at the symbolic level [and that allow] integration of programmed\n",
      "and learned knowledge ... \n",
      "[Belew and Forrest]\n",
      "... sequences of coupled classifiers, ... [or] classifier chains, are necessary\n",
      "so that classifiers can be used to implement arbitrary networks and to\n",
      "perform a variety of computations. ... the system must not only be able\n",
      "to discover (create) a set of classifiers to solve the problem, it must also be\n",
      "able to maintain such a set once it has been discovered. \n",
      "[Robertson and\n",
      "Riolo]\n",
      "[An internal] model is used to direct behavior, and learning is triggered\n",
      "whenever the model proves to be an inadequate basis for generating be-\n",
      "havior in a given situation. This means that overt external rewards are\n",
      "not necessarily the only or the most useful source of feedback for inductive\n",
      "change. \n",
      "[Booker]\n",
      "Although the papers in this special issue are representative, they can only\n",
      "suggest the breadth of current activity. The proceedings from two conferences\n",
      "on genetic algorithms (Grefenstette, 1985, 1987), held at Carnegie Mellon Uni-\n",
      "versity in 1985 and at Massachusetts Institute of Technology in 1987, contain\n",
      "papers ranging from VLSI layout compaction to problem-directed generation\n",
      "of LISP code. The diversity and level of this activity are the signposts of a\n",
      "journey that has just begun. Along the way, researchers have already learned\n",
      "that evolutionary processes are not \"slow,\" and that discovery and recombina-\n",
      "tion of building blocks, allied with speedup provided by implicit parallelism,\n",
      "provides a powerful tool for learning in complex domains. As the journey con-\n",
      "tinues, we are confident that an approach based on the abstraction of natural\n",
      "example, combined with careful theoretical and computational investigation,\n",
      "will continue to chart useful territory on the landscape of machine learning.\n",
      "David E. Goldberg\n",
      "University of Alabama, Tuscaloosa\n",
      "DGOLDBER@UA1VM.BITNET\n",
      "John H. Holland\n",
      "University of Michigan, Ann Arbor\n",
      "JHH@UM.CC.UMICH.EDU\n",
      "\n",
      "GENETIC ALGORITHMS AND MACHINE LEARNING\n",
      "99\n",
      "References\n",
      "Bateson, G. (1972). Steps to an ecology of mind. New York: Ballantine.\n",
      "Davis, L., & Coombs, S. (1987). Genetic algorithms and communication link\n",
      "speed design: Theoretical considerations. Genetic Algorithms and Their\n",
      "Applications: Proceedings of the Second International Conference on Ge-\n",
      "netic Algorithms (pp. 252-256). Cambridge, MA: Lawrence Erlbaum.\n",
      "Edelman, G. M. (1987). Neural Darwinism: The theory of neuronal group\n",
      "selection. New York: Basic Books.\n",
      "Fourman, M. P. (1985). Compaction of symbolic layout using genetic algo-\n",
      "rithms. Proceedings of the First International Conference on Genetic Al-\n",
      "gorithms and Their Applications (pp. 141-152). Pittsburgh, PA: Lawrence\n",
      "Erlbaum.\n",
      "Goldberg, D. E. (1989). Genetic algorithms in search, optimization, and ma-\n",
      "chine learning. Reading, MA: Addison-Wesley.\n",
      "Grefenstette, J. J. (Ed.). (1985). Proceedings of the First International Con-\n",
      "ference on Genetic Algorithms and Their Applications. Pittsburgh, PA:\n",
      "Lawrence Erlbaum.\n",
      "Grefenstette, J. J. (Ed.). (1987). \n",
      "Genetic Algorithms and Their Applica-\n",
      "tions: Proceedings of the Second International Conference on Genetic Al-\n",
      "gorithms. Cambridge, MA: Lawrence Erlbaum.\n",
      "Holland, J. H. (1962). Outline for a logical theory of adaptive systems. Journal\n",
      "of the Association for Computing Machinery, 3, 297-314.\n",
      "Holland, J. H. (1975). Adaptation in natural and artificial systems. Ann\n",
      "Arbor, MI: University of Michigan Press.\n",
      "Holland, J. H., Holyoak, K. J., Nisbett, R. E., & Thagard, P. R. (1986).\n",
      "Induction: Processes of inference, learning, and discovery. Cambridge,\n",
      "MA: MIT Press.\n",
      "Minsky, M. (1986). The society of mind. New York: Simon and Schuster.\n",
      "Waddington, C. H. (1967). Summary discussion. In P. S. Moorhead & M. M\n",
      "Kaplan (Eds.), Mathematical challenges to the neo-Darwinian interpreta-\n",
      "tion of evolution. Philadelphia, PA: Wistar Institute Press.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDF to Text: PyMuPDF\n",
    "# This looks like it may be good. The documentation\n",
    "# looks great. I think PyMuPDF will be my saving grace\n",
    "# for this portion of the project. I will be choosing\n",
    "# PyMuPDF.\n",
    "import pymupdf\n",
    "\n",
    "def pdf_to_text_pymupdf(url):\n",
    "    f = pdf_bytes(url)\n",
    "    print(f)\n",
    "    doc = pymupdf.open(stream=f)\n",
    "    # print(doc[0].get_text())\n",
    "    for d in doc:\n",
    "        print(d.get_text())\n",
    "\n",
    "pdf_to_text_pymupdf(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9622ce-b4e3-4db8-b1e5-580120750f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
