{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "46d61a79-03c1-41ad-be1a-a9220aa1c334",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Scikit-learn: Machine Learning in Python\n",
      "Abstract: Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing machine learning to non-specialists using a general-purpose high-level language. Emphasis is put on ease of use, performance, documentation, and API consistency. It has minimal dependencies and is distributed under the simplified BSD license, encouraging its use in both academic and commercial settings. Source code, binaries, and documentation can be downloaded from http://scikit-learn.org.\n",
      "\n",
      "Title: Genetic algorithms in search, optimization, and machine learning\n",
      "Abstract: From the Publisher:\n",
      "This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. \n",
      "\n",
      "Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.\n",
      "\n",
      "Title: C4.5: Programs for Machine Learning\n",
      "Abstract: From the Publisher:\n",
      "Classifier systems play a major role in machine learning and knowledge-based systems, and Ross Quinlan's work on ID3 and C4.5 is widely acknowledged to have made some of the most significant contributions to their development. This book is a complete guide to the C4.5 system as implemented in C for the UNIX environment. It contains a comprehensive guide to the system's use , the source code (about 8,800 lines), and implementation notes. The source code and sample datasets are also available on a 3.5-inch floppy diskette for a Sun workstation.\n",
      "\n",
      "C4.5 starts with large sets of cases belonging to known classes. The cases, described by any mixture of nominal and numeric properties, are scrutinized for patterns that allow the classes to be reliably discriminated. These patterns are then expressed as models, in the form of decision trees or sets of if-then rules, that can be used to classify new cases, with emphasis on making the models understandable as well as accurate. The system has been applied successfully to tasks involving tens of thousands of cases described by hundreds of properties. The book starts from simple core learning methods and shows how they can be elaborated and extended to deal with typical problems such as missing data and over hitting. Advantages and disadvantages of the C4.5 approach are discussed and illustrated with several case studies.\n",
      "\n",
      "This book and software should be of interest to developers of classification-based intelligent systems and to students in machine learning and expert systems courses.\n",
      "\n",
      "Title: UCI Machine Learning Repository\n",
      "Abstract: None\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: The <i>Journal of Electronic Imaging</i> (JEI), copublished bimonthly with the Society for Imaging Science and Technology, publishes peer-reviewed papers that cover research and applications in all areas of electronic imaging science and technology.\n",
      "\n",
      "Title: Data Mining: Practical Machine Learning Tools and Techniques\n",
      "Abstract: None\n",
      "\n",
      "Title: Gaussian Processes for Machine Learning\n",
      "Abstract: A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.\n",
      "\n",
      "Title: Genetic algorithms in search, optimization, and machine learning\n",
      "Abstract: From the Publisher:\n",
      "This book brings together - in an informal and tutorial fashion - the computer techniques, mathematical tools, and research results that will enable both students and practitioners to apply genetic algorithms to problems in many fields. \n",
      "\n",
      "Major concepts are illustrated with running examples, and major algorithms are illustrated by Pascal computer programs. No prior knowledge of GAs or genetics is assumed, and only a minimum of computer programming and mathematics background is required.\n",
      "\n",
      "Title: UCI Repository of machine learning databases\n",
      "Abstract: None\n",
      "\n",
      "Title: Gaussian Processes for Machine Learning\n",
      "Abstract: A comprehensive and self-contained introduction to Gaussian processes, which provide a principled, practical, probabilistic approach to learning in kernel machines. Gaussian processes (GPs) provide a principled, practical, probabilistic approach to learning in kernel machines. GPs have received increased attention in the machine-learning community over the past decade, and this book provides a long-needed systematic and unified treatment of theoretical and practical aspects of GPs in machine learning. The treatment is comprehensive and self-contained, targeted at researchers and students in machine learning and applied statistics. The book deals with the supervised-learning problem for both regression and classification, and includes detailed algorithms. A wide variety of covariance (kernel) functions are presented and their properties discussed. Model selection is discussed both from a Bayesian and a classical perspective. Many connections to other well-known techniques from machine learning and statistics are discussed, including support-vector machines, neural networks, splines, regularization networks, relevance vector machines and others. Theoretical issues including learning curves and the PAC-Bayesian framework are treated, and several approximation methods for learning with large datasets are discussed. The book contains illustrative examples and exercises, and code and datasets are available on the Web. Appendixes provide mathematical background and a discussion of Gaussian Markov processes.\n",
      "\n",
      "Title: Machine Learning : A Probabilistic Perspective\n",
      "Abstract: Today's Web-enabled deluge of electronic data calls for automated methods of data analysis. Machine learning provides these, developing methods that can automatically detect patterns in data and then use the uncovered patterns to predict future data. This textbook offers a comprehensive and self-contained introduction to the field of machine learning, based on a unified, probabilistic approach. The coverage combines breadth and depth, offering necessary background material on such topics as probability, optimization, and linear algebra as well as discussion of recent developments in the field, including conditional random fields, L1 regularization, and deep learning. The book is written in an informal, accessible style, complete with pseudo-code for the most important algorithms. All topics are copiously illustrated with color images and worked examples drawn from such application domains as biology, text processing, computer vision, and robotics. Rather than providing a cookbook of different heuristic methods, the book stresses a principled model-based approach, often using the language of graphical models to specify models in a concise and intuitive way. Almost all the models described have been implemented in a MATLAB software package--PMTK (probabilistic modeling toolkit)--that is freely available online. The book is suitable for upper-level undergraduates with an introductory-level college math background and beginning graduate students.\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Programs for Machine Learning\n",
      "Abstract: Algorithms for constructing decision trees are among the most well known and widely used of all machine learning methods. Among decision tree algorithms, J. Ross Quinlan's ID3 and its successor, C4.5, are probably the most popular in the machine learning community. These algorithms and variations on them have been the subject of numerous research papers since Quinlan introduced ID3. Until recently, most researchers looking for an introduction to decision trees turned to Quinlan's seminal 1986 Machine Learning journal article [Quinlan, 1986]. In his new book, C4.5: Programs for Machine Learning, Quinlan has put together a definitive, much needed description of his complete system, including the latest developments. As such, this book will be a welcome addition to the library of many researchers and students.\n",
      "\n",
      "Title: Ensemble Methods in Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: TensorFlow: A system for large-scale machine learning\n",
      "Abstract: TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. TensorFlow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous \"parameter server\" designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with particularly strong support for training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model in contrast to existing systems, and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.\n",
      "\n",
      "Title: Machine learning in automated text categorization\n",
      "Abstract: The automated categorization (or classification) of texts into predefined categories has witnessed a booming interest in the last 10 years, due to the increased availability of documents in digital form and the ensuing need to organize them. In the research community the dominant approach to this problem is based on machine learning techniques: a general inductive process automatically builds a classifier by learning, from a set of preclassified documents, the characteristics of the categories. The advantages of this approach over the knowledge engineering approach (consisting in the manual definition of a classifier by domain experts) are a very good effectiveness, considerable savings in terms of expert labor power, and straightforward portability to different domains. This survey discusses the main approaches to text categorization that fall within the machine learning paradigm. We will discuss in detail issues pertaining to three different problems, namely, document representation, classifier construction, and classifier evaluation.\n",
      "\n",
      "Title: Machine learning: Trends, perspectives, and prospects\n",
      "Abstract: Machine learning addresses the question of how to build computers that improve automatically through experience. It is one of today’s most rapidly growing technical fields, lying at the intersection of computer science and statistics, and at the core of artificial intelligence and data science. Recent progress in machine learning has been driven both by the development of new learning algorithms and theory and by the ongoing explosion in the availability of online data and low-cost computation. The adoption of data-intensive machine-learning methods can be found throughout science, technology and commerce, leading to more evidence-based decision-making across many walks of life, including health care, manufacturing, education, financial modeling, policing, and marketing.\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning (Information Science and Statistics)\n",
      "Abstract: None\n",
      "\n",
      "Title: Proceedings of the 24th international conference on Machine learning\n",
      "Abstract: This volume contains the papers accepted to the 24th International Conference on Machine Learning (ICML 2007), which was held at Oregon State University in Corvalis, Oregon, from June 20th to 24th, 2007. ICML is the annual conference of the International Machine Learning Society (IMLS), and provides a venue for the presentation and discussion of current research in the field of machine learning. These proceedings can also be found online at: http://www.machinelearning.org. This year there were 522 submissions to ICML. There was a very thorough review process, in which each paper was reviewed by three program committee (PC) members. Authors were able to respond to the initial reviews, and the PC members could then modify their reviews based on online discussions and the content of this author response. For the first time this year there were two discussion periods led by the senior program committee (SPC), one just before and one after the submission of author responses. At the end of the second discussion period, the SPC members gave their recommendations and provided a summary review for each of their papers. Also for the first time, authors were asked to submit a list of changes with their final accepted papers, which was checked by the SPCs to ensure that reviewer comments had been addressed. Apart from the length restrictions on papers and the compressed time frame, the review process for ICML resembles that of many journal publications. In total, 150 papers were accepted to ICML this year, including a very small number of papers which were initially conditionally accepted, yielding an overall acceptance rate of 29%. ICML attracts submissions from machine learning researchers around the globe. The 150 accepted papers this year were geographically distributed as follows: 66 papers had a first author from the US, 32 from Europe, 19 from China or Hong Kong, 11 from Canada, 6 from India, 5 each from Australia and Japan, 3 from Israel, and 1 each from Korea, Russia and Taiwan. In addition to the main program of accepted papers, which includes both a talk and poster presentation for each paper, the ICML program included 3 workshops and 8 tutorials on machine learning topics which are currently of broad interest. We were also extremely pleased to have David Heckerman (Microsoft Research), Joshua Tenenbaum (Massachussetts Institute of Technology), and Bernhard Schölkopf (Max Planck Institute for Biological Cybernetics) as the invited speakers this year. Thanks to sponsorship by the Machine Learning Journal, we were able to award a number of outstanding student paper prizes. We were fortunate this year that ICML was co-located with the International Conference on Inductive Logic Programming (ILP 2007). ICML and ILP held joint sessions on the first day of ICML 2007.\n",
      "\n",
      "Title: TensorFlow: Large-Scale Machine Learning on Heterogeneous Distributed Systems\n",
      "Abstract: TensorFlow is an interface for expressing machine learning algorithms, and an implementation for executing such algorithms. A computation expressed using TensorFlow can be executed with little or no change on a wide variety of heterogeneous systems, ranging from mobile devices such as phones and tablets up to large-scale distributed systems of hundreds of machines and thousands of computational devices such as GPU cards. The system is flexible and can be used to express a wide variety of algorithms, including training and inference algorithms for deep neural network models, and it has been used for conducting research and for deploying machine learning systems into production across more than a dozen areas of computer science and other fields, including speech recognition, computer vision, robotics, information retrieval, natural language processing, geographic information extraction, and computational drug discovery. This paper describes the TensorFlow interface and an implementation of that interface that we have built at Google. The TensorFlow API and a reference implementation were released as an open-source package under the Apache 2.0 license in November, 2015 and are available at www.tensorflow.org.\n",
      "\n",
      "Title: Text categorization with Support Vector Machines: Learning with many relevant features\n",
      "Abstract: None\n",
      "\n",
      "Title: Proceedings of the 25th international conference on Machine learning\n",
      "Abstract: This volume contains the papers accepted to the 25th International Conference on Machine Learning (ICML 2008). ICML is the annual conference of the International Machine Learning Society (IMLS), and provides a venue for the presentation and discussion of current research in the field of machine learning. These proceedings can also be found online at http://www.machinelearning.org.\n",
      "\n",
      "This year, ICML was held July 5..9 at the University of Helsinki, in Helsinki, Finland, and was co-located with COLT-2008, the 21st Annual Conference on Computational Learning Theory, and UAI-2008, the 24th Conference on Uncertainty in Artificial Intelligence. No less than 583 papers were submitted to ICML 2008. There was a very thorough review process, in which each paper was reviewed double-blind by three program committee (PC) members. Authors were able to respond to the initial reviews, and the PC members could then modify their reviews based on online discussions and the content of this author response. There were two discussion periods led by the senior program committee (SPC), one just before and one after the submission of author responses. At the end of the second discussion period, the SPC members gave their recommendations and provided a summary review for each of their papers. Some papers were checked by the SPCs to ensure that reviewer comments had been addressed. Apart from the length restrictions on papers and the compressed time frame, the review process for ICML resembles that of many journal publications. In total, 158 papers were accepted to ICML this year, including a small number of papers which were initially conditionally accepted, yielding an overall acceptance rate of 27%.\n",
      "\n",
      "ICML authors presented their papers both orally and in a poster session, allowing time for detailed discussions with any interested attendees of the conference. Each day of the main conference included one or two invited talks by a prominent researcher. We were very fortunate to be able to host Michael Collins, of the Massachusetts Institute of Technology; Andrew Ng, of Stanford University; and Luc De Raedt, of the Katholieke Universiteit Leuven, and John Winn of Microsoft Research Cambridge. In addition to the technical talks, ICML- 2008 also included nine tutorials held before the main conference, presented by Alex Smola, Arthur Gretton, and Kenji Fukumizu; Bert Kappen and Marc Toussaint; Neil Lawrence; MartinWainwright; Ralf Herbrich and Thore Graepel; Andreas Krause and Carlos Guestrin; Shai Shalev-Shwartz and Yoram Singer; Rob Fergus; and Matthias Seeger. This year our workshops were organized jointly with COLT and UAI as part of a special overlap day, consisting of eleven workshops selected and arranged collaboratively by the respective workshop chairs of the three conferences. This day provided a rich opportunity for interaction among the attendees of the conferences.\n",
      "\n",
      "This year, ICML enlarged its award offerings to match several other well-established conferences. We hope these will help build our community, celebrate our advances, and encourage applications and long-term thinking. In addition to our previously traditional Paper and Student Paper awards, we also gave awards for Application Paper and 10-year Best Paper (for the best paper of ICML 1998, optionally given in conjunction with a co-located conference). We thank the Machine Learning Journal for sponsoring some of our paper awards.\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: (2007). Pattern Recognition and Machine Learning. Technometrics: Vol. 49, No. 3, pp. 366-366.\n",
      "\n",
      "Title: TensorFlow: a system for large-scale machine learning\n",
      "Abstract: TensorFlow is a machine learning system that operates at large scale and in heterogeneous environments. Tensor-Flow uses dataflow graphs to represent computation, shared state, and the operations that mutate that state. It maps the nodes of a dataflow graph across many machines in a cluster, and within a machine across multiple computational devices, including multicore CPUs, general-purpose GPUs, and custom-designed ASICs known as Tensor Processing Units (TPUs). This architecture gives flexibility to the application developer: whereas in previous parameter server designs the management of shared state is built into the system, TensorFlow enables developers to experiment with novel optimizations and training algorithms. TensorFlow supports a variety of applications, with a focus on training and inference on deep neural networks. Several Google services use TensorFlow in production, we have released it as an open-source project, and it has become widely used for machine learning research. In this paper, we describe the TensorFlow dataflow model and demonstrate the compelling performance that TensorFlow achieves for several real-world applications.\n",
      "\n",
      "Title: The use of the area under the ROC curve in the evaluation of machine learning algorithms\n",
      "Abstract: None\n",
      "\n",
      "Title: Gaussian Processes in Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Practical Bayesian Optimization of Machine Learning Algorithms\n",
      "Abstract: Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a \"black art\" that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.\n",
      "\n",
      "Title: Large-Scale Machine Learning with Stochastic Gradient Descent\n",
      "Abstract: During the last decade, the data sizes have grown faster than the speed of processors. In this context, the capabilities of statistical machine learning methods is limited by the computing time rather than the sample size. A more precise analysis uncovers qualitatively different tradeoffs for the case of small-scale and large-scale learning problems. The large-scale case involves the computational complexity of the underlying optimization algorithm in non-trivial ways. Unlikely optimization algorithms such as stochastic gradient descent show amazing performance for large-scale problems. In particular, second order stochastic gradient and averaged stochastic gradient are asymptotically efficient after a single pass on the training set.\n",
      "\n",
      "Title: Encyclopedia of Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Proceedings of the 25th international conference on Machine learning - ICML '08\n",
      "Abstract: None\n",
      "\n",
      "Title: Genetic Algorithms and Machine Learning\n",
      "Abstract: None\n",
      "https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\n",
      "\n",
      "Title: Some Studies in Machine Learning Using the Game of Checkers\n",
      "Abstract: Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.\n",
      "\n",
      "Title: Federated Machine Learning\n",
      "Abstract: Today’s artificial intelligence still faces two major challenges. One is that, in most industries, data exists in the form of isolated islands. The other is the strengthening of data privacy and security. We propose a possible solution to these challenges: secure federated learning. Beyond the federated-learning framework first proposed by Google in 2016, we introduce a comprehensive secure federated-learning framework, which includes horizontal federated learning, vertical federated learning, and federated transfer learning. We provide definitions, architectures, and applications for the federated-learning framework, and provide a comprehensive survey of existing works on this subject. In addition, we propose building data networks among organizations based on federated mechanisms as an effective solution to allowing knowledge to be shared without compromising user privacy.\n",
      "\n",
      "Title: Machine Learning for High-Speed Corner Detection\n",
      "Abstract: None\n",
      "\n",
      "Title: Fashion-MNIST: a Novel Image Dataset for Benchmarking Machine Learning Algorithms\n",
      "Abstract: We present Fashion-MNIST, a new dataset comprising of 28x28 grayscale images of 70,000 fashion products from 10 categories, with 7,000 images per category. The training set has 60,000 images and the test set has 10,000 images. Fashion-MNIST is intended to serve as a direct drop-in replacement for the original MNIST dataset for benchmarking machine learning algorithms, as it shares the same image size, data format and the structure of training and testing splits. The dataset is freely available at https://github.com/zalandoresearch/fashion-mnist\n",
      "\n",
      "Title: Convolutional LSTM Network: A Machine Learning Approach for Precipitation Nowcasting\n",
      "Abstract: The goal of precipitation nowcasting is to predict the future rainfall intensity in a local region over a relatively short period of time. Very few previous studies have examined this crucial and challenging weather forecasting problem from the machine learning perspective. In this paper, we formulate precipitation nowcasting as a spatiotemporal sequence forecasting problem in which both the input and the prediction target are spatiotemporal sequences. By extending the fully connected LSTM (FC-LSTM) to have convolutional structures in both the input-to-state and state-to-state transitions, we propose the convolutional LSTM (ConvLSTM) and use it to build an end-to-end trainable model for the precipitation nowcasting problem. Experiments show that our ConvLSTM network captures spatiotemporal correlations better and consistently outperforms FC-LSTM and the state-of-the-art operational ROVER algorithm for precipitation nowcasting.\n",
      "\n",
      "Title: Correlation-based Feature Selection for Machine Learning\n",
      "Abstract: A central problem in machine learning is identifying a representative set of features from which to construct a classification model for a particular task. This thesis addresses the problem of feature selection for machine learning through a correlation based approach. The central hypothesis is that good feature sets contain features that are highly correlated with the class, yet uncorrelated with each other. A feature evaluation formula, based on ideas from test theory, provides an operational definition of this hypothesis. CFS (Correlation based Feature Selection) is an algorithm that couples this evaluation formula with an appropriate correlation measure and a heuristic search strategy. CFS was evaluated by experiments on artificial and natural datasets. Three machine learning algorithms were used: C4.5 (a decision tree learner), IB1 (an instance based learner), and naive Bayes. Experiments on artificial datasets showed that CFS quickly identifies and screens irrelevant, redundant, and noisy features, and identifies relevant features as long as their relevance does not strongly depend on other features. On natural domains, CFS typically eliminated well over half the features. In most cases, classification accuracy using the reduced feature set equaled or bettered accuracy using the complete feature set. Feature selection degraded machine learning performance in cases where some features were eliminated which were highly predictive of very small areas of the instance space. Further experiments compared CFS with a wrapper—a well known approach to feature selection that employs the target learning algorithm to evaluate feature sets. In many cases CFS gave comparable results to the wrapper, and in general, outperformed the wrapper on small datasets. CFS executes many times faster than the wrapper, which allows it to scale to larger datasets. Two methods of extending CFS to handle feature interaction are presented and experimentally evaluated. The first considers pairs of features and the second incorporates iii feature weights calculated by the RELIEF algorithm. Experiments on artificial domains showed that both methods were able to identify interacting features. On natural domains, the pairwise method gave more reliable results than using weights provided by RELIEF.\n",
      "\n",
      "Title: Supervised Machine Learning: A Review of Classification Techniques\n",
      "Abstract: The goal of supervised learning is to build a concise model of the distribution of class labels in terms of predictor features. The resulting classifier is then used to assign class labels to the testing instances where the values of the predictor features are known, but the value of the class label is unknown. This paper describes various supervised machine learning classification techniques. Of course, a single chapter cannot be a complete review of all supervised machine learning classification algorithms (also known induction classification algorithms), yet we hope that the references cited will cover the major theoretical issues, guiding the researcher in interesting research directions and suggesting possible bias combinations that have yet to be explored.\n",
      "\n",
      "Title: Selection of relevant features and examples in machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Quantum machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Pattern recognition and machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Scikit-learn: Machine Learning in Python\n",
      "Abstract: Scikit-learn is a Python module integrating a wide range of state-of-the-art machine learning algorithms for medium-scale supervised and unsupervised problems. This package focuses on bringing mach...\n",
      "\n",
      "Title: Machine Learning in Medicine\n",
      "Abstract: Spurred by advances in processing power, memory, storage, and an unprecedented wealth of data, computers are being asked to tackle increasingly complex learning tasks, often with astonishing success. Computers have now mastered a popular variant of poker, learned the laws of physics from experimental data, and become experts in video games - tasks that would have been deemed impossible not too long ago. In parallel, the number of companies centered on applying complex data analysis to varying industries has exploded, and it is thus unsurprising that some analytic companies are turning attention to problems in health care. The purpose of this review is to explore what problems in medicine might benefit from such learning approaches and use examples from the literature to introduce basic concepts in machine learning. It is important to note that seemingly large enough medical data sets and adequate learning algorithms have been available for many decades, and yet, although there are thousands of papers applying machine learning algorithms to medical data, very few have contributed meaningfully to clinical care. This lack of impact stands in stark contrast to the enormous relevance of machine learning to many other industries. Thus, part of my effort will be to identify what obstacles there may be to changing the practice of medicine through statistical learning approaches, and discuss how these might be overcome.\n",
      "\n",
      "Title: Dlib-ml: A Machine Learning Toolkit\n",
      "Abstract: There are many excellent toolkits which provide support for developing machine learning software in Python, R, Matlab, and similar environments. Dlib-ml is an open source library, targeted at both engineers and research scientists, which aims to provide a similarly rich environment for developing machine learning software in the C++ language. Towards this end, dlib-ml contains an extensible linear algebra toolkit with built in BLAS support. It also houses implementations of algorithms for performing inference in Bayesian networks and kernel-based methods for classification, regression, clustering, anomaly detection, and feature ranking. To enable easy use of these tools, the entire library has been developed with contract programming, which provides complete and precise documentation as well as powerful debugging tools.\n",
      "\n",
      "Title: Understanding Machine Learning\n",
      "Abstract: Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides a theoretical account of the fundamentals underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics, the book covers a wide array of central topics unaddressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for advanced undergraduates or beginning graduates, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics and engineering.\n",
      "\n",
      "Title: UCI Repository of Machine Learning Databases\n",
      "Abstract: None\n",
      "\n",
      "Title: Understanding Machine Learning: From Theory To Algorithms\n",
      "Abstract: Machine learning is one of the fastest growing areas of computer science, with far-reaching applications. The aim of this textbook is to introduce machine learning, and the algorithmic paradigms it offers, in a principled way. The book provides an extensive theoretical account of the fundamental ideas underlying machine learning and the mathematical derivations that transform these principles into practical algorithms. Following a presentation of the basics of the field, the book covers a wide array of central topics that have not been addressed by previous textbooks. These include a discussion of the computational complexity of learning and the concepts of convexity and stability; important algorithmic paradigms including stochastic gradient descent, neural networks, and structured output learning; and emerging theoretical concepts such as the PAC-Bayes approach and compression-based bounds. Designed for an advanced undergraduate or beginning graduate course, the text makes the fundamentals and algorithms of machine learning accessible to students and non-expert readers in statistics, computer science, mathematics, and engineering.\n",
      "\n",
      "Title: Gaussian Processes for Machine Learning (Adaptive Computation and Machine Learning)\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine learning for molecular and materials science\n",
      "Abstract: None\n",
      "\n",
      "Title: Genetic Algorithms in Search, Optimization & Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: A study of the behavior of several methods for balancing machine learning training data\n",
      "Abstract: There are several aspects that might influence the performance achieved by existing learning systems. It has been reported that one of these aspects is related to class imbalance in which examples in training data belonging to one class heavily outnumber the examples in the other class. In this situation, which is found in real world data describing an infrequent but important event, the learning system may have difficulties to learn the concept related to the minority class. In this work we perform a broad experimental evaluation involving ten methods, three of them proposed by the authors, to deal with the class imbalance problem in thirteen UCI data sets. Our experiments provide evidence that class imbalance does not systematically hinder the performance of learning systems. In fact, the problem seems to be related to learning with too few minority class examples in the presence of other complicating factors, such as class overlapping. Two of our proposed methods deal with these conditions directly, allying a known over-sampling method with data cleaning methods in order to produce better-defined class clusters. Our comparative experiments show that, in general, over-sampling methods provide more accurate results than under-sampling methods considering the area under the ROC curve (AUC). This result seems to contradict results previously published in the literature. Two of our proposed methods, Smote + Tomek and Smote + ENN, presented very good results for data sets with a small number of positive examples. Moreover, Random over-sampling, a very simple over-sampling method, is very competitive to more complex over-sampling methods. Since the over-sampling methods provided very good performance results, we also measured the syntactic complexity of the decision trees induced from over-sampled data. Our results show that these trees are usually more complex then the ones induced from original data. Random over-sampling usually produced the smallest increase in the mean number of induced rules and Smote + ENN the smallest increase in the mean number of conditions per rule, when compared among the investigated over-sampling methods.\n",
      "\n",
      "Title: Machine Learning, Neural and Statistical Classification\n",
      "Abstract: Survey of previous comparisons and theoretical work descriptions of methods dataset descriptions criteria for comparison and methodology (including validation) empirical results machine learning on machine learning.\n",
      "\n",
      "Title: Machine Learning: An Artificial Intelligence Approach\n",
      "Abstract: None\n",
      "\n",
      "Title: SoilGrids250m: Global gridded soil information based on machine learning\n",
      "Abstract: This paper describes the technical development and accuracy assessment of the most recent and improved version of the SoilGrids system at 250m resolution (June 2016 update). SoilGrids provides global predictions for standard numeric soil properties (organic carbon, bulk density, Cation Exchange Capacity (CEC), pH, soil texture fractions and coarse fragments) at seven standard depths (0, 5, 15, 30, 60, 100 and 200 cm), in addition to predictions of depth to bedrock and distribution of soil classes based on the World Reference Base (WRB) and USDA classification systems (ca. 280 raster layers in total). Predictions were based on ca. 150,000 soil profiles used for training and a stack of 158 remote sensing-based soil covariates (primarily derived from MODIS land products, SRTM DEM derivatives, climatic images and global landform and lithology maps), which were used to fit an ensemble of machine learning methods—random forest and gradient boosting and/or multinomial logistic regression—as implemented in the R packages ranger, xgboost, nnet and caret. The results of 10–fold cross-validation show that the ensemble models explain between 56% (coarse fragments) and 83% (pH) of variation with an overall average of 61%. Improvements in the relative accuracy considering the amount of variation explained, in comparison to the previous version of SoilGrids at 1 km spatial resolution, range from 60 to 230%. Improvements can be attributed to: (1) the use of machine learning instead of linear regression, (2) to considerable investments in preparing finer resolution covariate layers and (3) to insertion of additional soil profiles. Further development of SoilGrids could include refinement of methods to incorporate input uncertainties and derivation of posterior probability distributions (per pixel), and further automation of spatial modeling so that soil maps can be generated for potentially hundreds of soil variables. Another area of future research is the development of methods for multiscale merging of SoilGrids predictions with local and/or national gridded soil products (e.g. up to 50 m spatial resolution) so that increasingly more accurate, complete and consistent global soil information can be produced. SoilGrids are available under the Open Data Base License.\n",
      "https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable\n",
      "\n",
      "Title: Machine learning applications in cancer prognosis and prediction\n",
      "Abstract: Cancer has been characterized as a heterogeneous disease consisting of many different subtypes. The early diagnosis and prognosis of a cancer type have become a necessity in cancer research, as it can facilitate the subsequent clinical management of patients. The importance of classifying cancer patients into high or low risk groups has led many research teams, from the biomedical and the bioinformatics field, to study the application of machine learning (ML) methods. Therefore, these techniques have been utilized as an aim to model the progression and treatment of cancerous conditions. In addition, the ability of ML tools to detect key features from complex datasets reveals their importance. A variety of these techniques, including Artificial Neural Networks (ANNs), Bayesian Networks (BNs), Support Vector Machines (SVMs) and Decision Trees (DTs) have been widely applied in cancer research for the development of predictive models, resulting in effective and accurate decision making. Even though it is evident that the use of ML methods can improve our understanding of cancer progression, an appropriate level of validation is needed in order for these methods to be considered in the everyday clinical practice. In this work, we present a review of recent ML approaches employed in the modeling of cancer progression. The predictive models discussed here are based on various supervised ML techniques as well as on different input features and data samples. Given the growing trend on the application of ML methods in cancer research, we present here the most recent publications that employ these techniques as an aim to model cancer risk or patient outcomes.\n",
      "\n",
      "Title: Machine Learning in Medicine\n",
      "Abstract: Interview with Dr. Isaac Kohane on machine learning in medicine. (16:31)Download In this view of the future of medicine, patient–provider interactions are informed and supported by massive amounts of data from interactions with similar patients. These data are collected and curated to provide the latest evidence-based assessment and recommendations.\n",
      "\n",
      "Title: Physics-informed machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Membership Inference Attacks Against Machine Learning Models\n",
      "Abstract: We quantitatively investigate how machine learning models leak information about the individual data records on which they were trained. We focus on the basic membership inference attack: given a data record and black-box access to a model, determine if the record was in the model's training dataset. To perform membership inference against a target model, we make adversarial use of machine learning and train our own inference model to recognize differences in the target model's predictions on the inputs that it trained on versus the inputs that it did not train on. We empirically evaluate our inference techniques on classification models trained by commercial \"machine learning as a service\" providers such as Google and Amazon. Using realistic datasets and classification tasks, including a hospital discharge dataset whose membership is sensitive from the privacy perspective, we show that these models can be vulnerable to membership inference attacks. We then investigate the factors that influence this leakage and evaluate mitigation strategies.\n",
      "\n",
      "Title: Practical Black-Box Attacks against Machine Learning\n",
      "Abstract: Machine learning (ML) models, e.g., deep neural networks (DNNs), are vulnerable to adversarial examples: malicious inputs modified to yield erroneous model outputs, while appearing unmodified to human observers. Potential attacks include having malicious content like malware identified as legitimate or controlling vehicle behavior. Yet, all existing adversarial example attacks require knowledge of either the model internals or its training data. We introduce the first practical demonstration of an attacker controlling a remotely hosted DNN with no such knowledge. Indeed, the only capability of our black-box adversary is to observe labels given by the DNN to chosen inputs. Our attack strategy consists in training a local model to substitute for the target DNN, using inputs synthetically generated by an adversary and labeled by the target DNN. We use the local substitute to craft adversarial examples, and find that they are misclassified by the targeted DNN. To perform a real-world and properly-blinded evaluation, we attack a DNN hosted by MetaMind, an online deep learning API. We find that their DNN misclassifies 84.24% of the adversarial examples crafted with our substitute. We demonstrate the general applicability of our strategy to many ML techniques by conducting the same attack against models hosted by Amazon and Google, using logistic regression substitutes. They yield adversarial examples misclassified by Amazon and Google at rates of 96.19% and 88.94%. We also find that this black-box attack strategy is capable of evading defense strategies previously found to make adversarial example crafting harder.\n",
      "\n",
      "Title: A few useful things to know about machine learning\n",
      "Abstract: Tapping into the \"folk knowledge\" needed to advance machine learning applications.\n",
      "\n",
      "Title: Towards A Rigorous Science of Interpretable Machine Learning\n",
      "Abstract: As machine learning systems become ubiquitous, there has been a surge of interest in interpretable machine learning: systems that provide explanation for their outputs. These explanations are often used to qualitatively assess other criteria such as safety or non-discrimination. However, despite the interest in interpretability, there is very little consensus on what interpretable machine learning is and how it should be measured. In this position paper, we first define interpretability and describe when interpretability is needed (and when it is not). Next, we suggest a taxonomy for rigorous evaluation and expose open questions towards a more rigorous science of interpretable machine learning.\n",
      "\n",
      "Title: UCI Repository of Machine Learning Databases\n",
      "Abstract: None\n",
      "\n",
      "Title: Adversarial Machine Learning at Scale\n",
      "Abstract: Adversarial examples are malicious inputs designed to fool machine learning models. They often transfer from one model to another, allowing attackers to mount black box attacks without knowledge of the target model's parameters. Adversarial training is the process of explicitly training a model on adversarial examples, in order to make it more robust to attack or to reduce its test error on clean inputs. So far, adversarial training has primarily been applied to small problems. In this research, we apply adversarial training to ImageNet. Our contributions include: (1) recommendations for how to succesfully scale adversarial training to large models and datasets, (2) the observation that adversarial training confers robustness to single-step attack methods, (3) the finding that multi-step attack methods are somewhat less transferable than single-step attack methods, so single-step attacks are the best for mounting black-box attacks, and (4) resolution of a \"label leaking\" effect that causes adversarially trained models to perform better on adversarial examples than on clean examples, because the adversarial example construction process uses the true label and the model can learn to exploit regularities in the construction process.\n",
      "\n",
      "Title: Multimodal Machine Learning: A Survey and Taxonomy\n",
      "Abstract: Our experience of the world is multimodal - we see objects, hear sounds, feel texture, smell odors, and taste flavors. Modality refers to the way in which something happens or is experienced and a research problem is characterized as multimodal when it includes multiple such modalities. In order for Artificial Intelligence to make progress in understanding the world around us, it needs to be able to interpret such multimodal signals together. Multimodal machine learning aims to build models that can process and relate information from multiple modalities. It is a vibrant multi-disciplinary field of increasing importance and with extraordinary potential. Instead of focusing on specific multimodal applications, this paper surveys the recent advances in multimodal machine learning itself and presents them in a common taxonomy. We go beyond the typical early and late fusion categorization and identify broader challenges that are faced by multimodal machine learning, namely: representation, translation, alignment, fusion, and co-learning. This new taxonomy will enable researchers to better understand the state of the field and identify directions for future research.\n",
      "\n",
      "Title: International Conference on Machine Learning (ICML)-2005\n",
      "Abstract: None\n",
      "\n",
      "Title: The Boosting Approach to Machine Learning: An Overview\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine learning for neuroimaging with scikit-learn\n",
      "Abstract: Statistical machine learning methods are increasingly used for neuroimaging data analysis. Their main virtue is their ability to model high-dimensional datasets, e.g. multivariate analysis of activation images or resting-state time series. Supervised learning is typically used in decoding or encoding settings to relate brain images to behavioral or clinical observations, while unsupervised learning can uncover hidden structures in sets of images (e.g. resting state functional MRI) or find sub-populations in large cohorts. By considering different functional neuroimaging applications, we illustrate how scikit-learn, a Python machine learning library, can be used to perform some key analysis steps. Scikit-learn contains a very large set of statistical learning algorithms, both supervised and unsupervised, and its application to neuroimaging data provides a versatile tool to study the brain.\n",
      "https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf\n",
      "\n",
      "Title: The MNIST Database of Handwritten Digit Images for Machine Learning Research [Best of the Web]\n",
      "Abstract: In this issue, \"Best of the Web\" presents the modified National Institute of Standards and Technology (MNIST) resources, consisting of a collection of handwritten digit images used extensively in optical character recognition and machine learning research.\n",
      "\n",
      "Title: Predicting the Future — Big Data, Machine Learning, and Clinical Medicine\n",
      "Abstract: The algorithms of machine learning, which can sift through vast numbers of variables looking for combinations that reliably predict outcomes, will improve prognosis, displace much of the work of radiologists and anatomical pathologists, and improve diagnostic accuracy.\n",
      "\n",
      "Title: Stop explaining black box machine learning models for high stakes decisions and use interpretable models instead\n",
      "Abstract: None\n",
      "\n",
      "Title: Proceedings of the 23rd international conference on Machine learning\n",
      "Abstract: This volume, which is also available from http://www.machinelearning.org, the home page of the International Machine Learning Society, contains the technical papers accepted for presentation at ICML-2006, the 23rd International Conference on Machine Learning. ICML is an international forum for presentation and discussion of the latest results in the field of machine learning. This year, ICML was held at Carnegie Mellon University, in Pittsburgh, Pennsylvania, and was co-located with COLT-2006, the 19th Annual Conference on Computational Learning Theory.Coincidentally, Carnegie Mellon University was also the venue for the first ICML---the First Machine Learning Workshop, which was held in 1980. Instead of proceedings, a book was published (Machine Learning: an Artificial Intelligence Approach, ed. Michalski, Carbonell, and Mitchell, Morgan Kaufman, 1983) containing sixteen research papers, and also a comprehensive of the field of machine learning, as it stood in 1983. This bibliography contained 572 entries.In 2006, no less than 548 papers were submitted to ICML---nearly as many as were in the comprehensive published with the papers from the first ICML. These papers were subjected to a thorough review process. In the first round of reviewing, every paper received three reviews by program committee members. Authors were then given an opportunity to view the first-round reviews and respond to them. Led by a Senior Program Committee member, the reviewers then engaged in a discussion of the paper, leading finally to a decision by the Senior Program Committee member in charge of the paper. Papers could be accepted, rejected, or conditionally accepted; the 36 conditionally accepted papers were subject to an additional final round of review by the Senior Program Committee. Of the 548 submissions, 140 were accepted for publication, an acceptance rate of 25.5%.In addition to the technical talks, ICML-2006 also included seven tutorials and eleven workshops, which were held before and after the conference, respectively. Authors presented their papers both orally and in a poster session, allowing time for detailed discussions with any interested attendees of the conference. Each day of the main conference included an invited talk by a prominent researcher. We were very fortunate to be able to host David Haussler, of the University of California at Santa Cruz; Robert Schapire, of Princeton University; and Mandyam V. Srinivasan, of the Australian National University.\n",
      "\n",
      "Title: MoleculeNet: a benchmark for molecular machine learning\n",
      "Abstract: A large scale benchmark for molecular machine learning consisting of multiple public datasets, metrics, featurizations and learning algorithms.\n",
      "https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a\n",
      "\n",
      "Title: Machine-Learning Research\n",
      "Abstract: Machine-learning research has been making great progress in many directions. This article summarizes four of these directions and discusses some current open problems. The four directions are (1) the improvement of classification accuracy by learning ensembles of classifiers, (2) methods for scaling up supervised learning algorithms, (3) reinforcement learning, and (4) the learning of complex stochastic models.\n",
      "\n",
      "Title: Machine Learning in Agriculture: A Review\n",
      "Abstract: Machine learning has emerged with big data technologies and high-performance computing to create new opportunities for data intensive science in the multi-disciplinary agri-technologies domain. In this paper, we present a comprehensive review of research dedicated to applications of machine learning in agricultural production systems. The works analyzed were categorized in (a) crop management, including applications on yield prediction, disease detection, weed detection crop quality, and species recognition; (b) livestock management, including applications on animal welfare and livestock production; (c) water management; and (d) soil management. The filtering and classification of the presented articles demonstrate how agriculture will benefit from machine learning technologies. By applying machine learning to sensor data, farm management systems are evolving into real time artificial intelligence enabled programs that provide rich recommendations and insights for farmer decision support and action.\n",
      "https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979\n",
      "\n",
      "Title: Practical Secure Aggregation for Privacy-Preserving Machine Learning\n",
      "Abstract: We design a novel, communication-efficient, failure-robust protocol for secure aggregation of high-dimensional data. Our protocol allows a server to compute the sum of large, user-held data vectors from mobile devices in a secure manner (i.e. without learning each user's individual contribution), and can be used, for example, in a federated learning setting, to aggregate user-provided model updates for a deep neural network. We prove the security of our protocol in the honest-but-curious and active adversary settings, and show that security is maintained even if an arbitrarily chosen subset of users drop out at any time. We evaluate the efficiency of our protocol and show, by complexity analysis and a concrete implementation, that its runtime and communication overhead remain low even on large data sets and client pools. For 16-bit input values, our protocol offers $1.73 x communication expansion for 210 users and 220-dimensional vectors, and 1.98 x expansion for 214 users and 224-dimensional vectors over sending data in the clear.\n",
      "\n",
      "Title: Automatic differentiation in machine learning: a survey\n",
      "Abstract: Derivatives, mostly in the form of gradients and Hessians, are ubiquitous in machine learning. Automatic (AD), also called algorithmic or simply auto-diff, is a family of techniques similar to but more general than backpropagation for efficiently and accurately evaluating derivatives of numeric functions expressed as computer programs. AD is a small but established field with applications in areas including computational uid dynamics, atmospheric sciences, and engineering design optimization. Until very recently, the fields of machine learning and AD have largely been unaware of each other and, in some cases, have independently discovered each other's results. Despite its relevance, general-purpose AD has been missing from the machine learning toolbox, a situation slowly changing with its ongoing adoption under the names dynamic computational graphs and differentiable programming. We survey the intersection of AD and machine learning, cover applications where AD has direct relevance, and address the main implementation techniques. By precisely defining the main techniques and their interrelationships, we aim to bring clarity to the usage of the terms autodiff, automatic differentiation, and symbolic differentiation as these are encountered more and more in machine learning settings.\n",
      "\n",
      "Title: A Survey on Bias and Fairness in Machine Learning\n",
      "Abstract: With the widespread use of artificial intelligence (AI) systems and applications in our everyday lives, accounting for fairness has gained significant importance in designing and engineering of such systems. AI systems can be used in many sensitive environments to make important and life-changing decisions; thus, it is crucial to ensure that these decisions do not reflect discriminatory behavior toward certain groups or populations. More recently some work has been developed in traditional machine learning and deep learning that address such challenges in different subdomains. With the commercialization of these systems, researchers are becoming more aware of the biases that these applications can contain and are attempting to address them. In this survey, we investigated different real-world applications that have shown biases in various ways, and we listed different sources of biases that can affect AI applications. We then created a taxonomy for fairness definitions that machine learning researchers have defined to avoid the existing bias in AI systems. In addition to that, we examined different domains and subdomains in AI showing what researchers have observed with regard to unfair outcomes in the state-of-the-art methods and ways they have tried to address them. There are still many future directions and solutions that can be taken to mitigate the problem of bias in AI systems. We are hoping that this survey will motivate researchers to tackle these issues in the near future by observing existing work in their respective fields.\n",
      "\n",
      "Title: Optimization Methods for Large-Scale Machine Learning\n",
      "Abstract: This paper provides a review and commentary on the past, present, and future of numerical optimization algorithms in the context of machine learning applications. Through case studies on text classification and the training of deep neural networks, we discuss how optimization problems arise in machine learning and what makes them challenging. A major theme of our study is that large-scale machine learning represents a distinctive setting in which the stochastic gradient (SG) method has traditionally played a central role while conventional gradient-based nonlinear optimization techniques typically falter. Based on this viewpoint, we present a comprehensive theory of a straightforward, yet versatile SG algorithm, discuss its practical behavior, and highlight opportunities for designing algorithms with improved performance. This leads to a discussion about the next generation of optimization methods for large-scale machine learning, including an investigation of two main streams of research on techniques that diminish noise in the stochastic directions and methods that make use of second-order derivative approximations.\n",
      "\n",
      "Title: Machine learning: An artificial intelligence approach\n",
      "Abstract: None\n",
      "\n",
      "Title: Ensemble Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Bayesian Reasoning and Machine Learning\n",
      "Abstract: Machine learning methods extract value from vast data sets quickly and with modest resources. They are established tools in a wide range of industrial applications, including search engines, DNA sequencing, stock market analysis, and robot locomotion, and their use is spreading rapidly. People who know the methods have their choice of rewarding jobs. This hands-on text opens these opportunities to computer science students with modest mathematical backgrounds. It is designed for final-year undergraduates and master's students with limited background in linear algebra and calculus. Comprehensive and coherent, it develops everything from basic reasoning to advanced techniques within the framework of graphical models. Students learn more than a menu of techniques, they develop analytical and problem-solving skills that equip them for the real world. Numerous examples and exercises, both computer based and theoretical, are included in every chapter. Resources for students and instructors, including a MATLAB toolbox, are available online.\n",
      "\n",
      "Title: Kernel methods in machine learning\n",
      "Abstract: We review machine learning methods employing positive definite kernels. These methods formulate learning and estimation problems in a reproducing kernel Hilbert space (RKHS) of functions defined on the data domain, expanded in terms of a kernel. Working in linear spaces of function has the benefit of facilitating the construction and analysis of learning algorithms while at the same time allowing large classes of functions. The latter include nonlinear functions as well as functions defined on nonvectorial data. We cover a wide range of methods, ranging from binary classifiers to sophisticated methods for estimation with structured data.\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Dataset Shift in Machine Learning\n",
      "Abstract: An overview of recent efforts in the machine learning community to deal with dataset and covariate shift, which occurs when test and training inputs and outputs have different distributions. Dataset shift is a common problem in predictive modeling that occurs when the joint distribution of inputs and outputs differs between training and test stages. Covariate shift, a particular case of dataset shift, occurs when only the input distribution changes. Dataset shift is present in most practical applications, for reasons ranging from the bias introduced by experimental design to the irreproducibility of the testing conditions at training time. (An example is -email spam filtering, which may fail to recognize spam that differs in form from the spam the automatic filter has been built on.) Despite this, and despite the attention given to the apparently similar problems of semi-supervised learning and active learning, dataset shift has received relatively little attention in the machine learning community until recently. This volume offers an overview of current efforts to deal with dataset and covariate shift. The chapters offer a mathematical and philosophical introduction to the problem, place dataset shift in relationship to transfer learning, transduction, local learning, active learning, and semi-supervised learning, provide theoretical views of dataset and covariate shift (including decision theoretic and Bayesian perspectives), and present algorithms for covariate shift. Contributors Shai Ben-David, Steffen Bickel, Karsten Borgwardt, Michael Brückner, David Corfield, Amir Globerson, Arthur Gretton, Lars Kai Hansen, Matthias Hein, Jiayuan Huang, Choon Hui Teo, Takafumi Kanamori, Klaus-Robert Müller, Sam Roweis, Neil Rubens, Tobias Scheffer, Marcel Schmittfull, Bernhard Schölkopf Hidetoshi Shimodaira, Alex Smola, Amos Storkey, Masashi Sugiyama\n",
      "\n",
      "Title: Machine learning and the physical sciences\n",
      "Abstract: In October 2018 an APS Physics Next Workshop on Machine Learning was held in Riverhead, NY. This article reviews and summarizes the proceedings of this very broad, emerging field.This needs to be a placard in the left-hand column, with a custom tag.\n",
      "\n",
      "Title: DaDianNao: A Machine-Learning Supercomputer\n",
      "Abstract: Many companies are deploying services, either for consumers or industry, which are largely based on machine-learning algorithms for sophisticated processing of large amounts of data. The state-of-the-art and most popular such machine-learning algorithms are Convolutional and Deep Neural Networks (CNNs and DNNs), which are known to be both computationally and memory intensive. A number of neural network accelerators have been recently proposed which can offer high computational capacity/area ratio, but which remain hampered by memory accesses. However, unlike the memory wall faced by processors on general-purpose workloads, the CNNs and DNNs memory footprint, while large, is not beyond the capability of the on chip storage of a multi-chip system. This property, combined with the CNN/DNN algorithmic characteristics, can lead to high internal bandwidth and low external communications, which can in turn enable high-degree parallelism at a reasonable area cost. In this article, we introduce a custom multi-chip machine-learning architecture along those lines. We show that, on a subset of the largest known neural network layers, it is possible to achieve a speedup of 450.65x over a GPU, and reduce the energy by 150.31x on average for a 64-chip system. We implement the node down to the place and route at 28nm, containing a combination of custom storage and computational units, with industry-grade interconnects.\n",
      "\n",
      "Title: ilastik: interactive machine learning for (bio)image analysis\n",
      "Abstract: None\n",
      "\n",
      "Title: Introduction to Machine Learning\n",
      "Abstract: The goal of machine learning is to program computers to use example data or past experience to solve a given problem. Many successful applications of machine learning exist already, including systems that analyze past sales data to predict customer behavior, optimize robot behavior so that a task can be completed using minimum resources, and extract knowledge from bioinformatics data. Introduction to Machine Learning is a comprehensive textbook on the subject, covering a broad array of topics not usually included in introductory machine learning texts. In order to present a unified treatment of machine learning problems and solutions, it discusses many methods from different fields, including statistics, pattern recognition, neural networks, artificial intelligence, signal processing, control, and data mining. All learning algorithms are explained so that the student can easily move from the equations in the book to a computer program. The text covers such topics as supervised learning, Bayesian decision theory, parametric methods, multivariate methods, multilayer perceptrons, local models, hidden Markov models, assessing and comparing classification algorithms, and reinforcement learning. New to the second edition are chapters on kernel machines, graphical models, and Bayesian estimation; expanded coverage of statistical tests in a chapter on design and analysis of machine learning experiments; case studies available on the Web (with downloadable results for instructors); and many additional exercises. All chapters have been revised and updated. Introduction to Machine Learning can be used by advanced undergraduates and graduate students who have completed courses in computer programming, probability, calculus, and linear algebra. It will also be of interest to engineers in the field who are concerned with the application of machine learning methods. Adaptive Computation and Machine Learning series\n",
      "\n",
      "Title: Probabilistic machine learning and artificial intelligence\n",
      "Abstract: None\n",
      "\n",
      "Title: Fast and Accurate Modeling of Molecular Atomization Energies with Machine Learning\n",
      "Abstract: We introduce a machine learning model to predict atomization energies of a diverse set of organic molecules, based on nuclear charges and atomic positions only. The problem of solving the molecular Schrödinger equation is mapped onto a nonlinear statistical regression problem of reduced complexity. Regression models are trained on and compared to atomization energies computed with hybrid density-functional theory. Cross validation over more than seven thousand organic molecules yields a mean absolute error of ∼10 kcal/mol. Applicability is demonstrated for the prediction of molecular atomization potential energy curves.\n",
      "https://link.aps.org/accepted/10.1103/PhysRevLett.108.058301\n",
      "\n",
      "Title: Machine learning applications in genetics and genomics\n",
      "Abstract: None\n",
      "\n",
      "Title: Introduction to Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine learning classifiers and fMRI: A tutorial overview\n",
      "Abstract: None\n",
      "\n",
      "Title: Introduction to Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Faster and Better: A Machine Learning Approach to Corner Detection\n",
      "Abstract: The repeatability and efficiency of a corner detector determines how likely it is to be useful in a real-world application. The repeatability is important because the same scene viewed from different positions should yield features which correspond to the same real-world 3D locations. The efficiency is important because this determines whether the detector combined with further processing can operate at frame rate. Three advances are described in this paper. First, we present a new heuristic for feature detection and, using machine learning, we derive a feature detector from this which can fully process live PAL video using less than 5 percent of the available processing time. By comparison, most other detectors cannot even operate at frame rate (Harris detector 115 percent, SIFT 195 percent). Second, we generalize the detector, allowing it to be optimized for repeatability, with little loss of efficiency. Third, we carry out a rigorous comparison of corner detectors based on the above repeatability criterion applied to 3D scenes. We show that, despite being principally constructed for speed, on these stringent tests, our heuristic detector significantly outperforms existing feature detectors. Finally, the comparison demonstrates that using machine learning produces significant improvements in repeatability, yielding a detector that is both very fast and of very high quality.\n",
      "\n",
      "Title: Foundations of Machine Learning\n",
      "Abstract: This graduate-level textbook introduces fundamental concepts and methods in machine learning. It describes several important modern algorithms, provides the theoretical underpinnings of these algorithms, and illustrates key aspects for their application. The authors aim to present novel theoretical tools and concepts while giving concise proofs even for relatively advanced topics. Foundations of Machine Learning fills the need for a general textbook that also offers theoretical details and an emphasis on proofs. Certain topics that are often treated with insufficient attention are discussed in more detail here; for example, entire chapters are devoted to regression, multi-class classification, and ranking. The first three chapters lay the theoretical foundation for what follows, but each remaining chapter is mostly self-contained. The appendix offers a concise probability review, a short introduction to convex optimization, tools for concentration bounds, and several basic properties of matrices and norms used in the book. The book is intended for graduate students and researchers in machine learning, statistics, and related areas; it can be used either as a textbook or as a reference text for a research seminar.\n",
      "\n",
      "Title: How the machine ‘thinks’: Understanding opacity in machine learning algorithms\n",
      "Abstract: This article considers the issue of opacity as a problem for socially consequential mechanisms of classification and ranking, such as spam filters, credit card fraud detection, search engines, news trends, market segmentation and advertising, insurance or loan qualification, and credit scoring. These mechanisms of classification all frequently rely on computational algorithms, and in many cases on machine learning algorithms to do this work. In this article, I draw a distinction between three forms of opacity: (1) opacity as intentional corporate or state secrecy, (2) opacity as technical illiteracy, and (3) an opacity that arises from the characteristics of machine learning algorithms and the scale required to apply them usefully. The analysis in this article gets inside the algorithms themselves. I cite existing literatures in computer science, known industry practices (as they are publicly presented), and do some testing and manipulation of code as a form of lightweight code audit. I argue that recognizing the distinct forms of opacity that may be coming into play in a given application is a key to determining which of a variety of technical and non-technical solutions could help to prevent harm.\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512\n",
      "\n",
      "Title: Thumbs up? Sentiment Classification using Machine Learning Techniques\n",
      "Abstract: We consider the problem of classifying documents not by topic, but by overall sentiment, e.g., determining whether a review is positive or negative. Using movie reviews as data, we find that standard machine learning techniques definitively outperform human-produced baselines. However, the three machine learning methods we employed (Naive Bayes, maximum entropy classification, and support vector machines) do not perform as well on sentiment classification as on traditional topic-based categorization. We conclude by examining factors that make the sentiment classification problem more challenging.\n",
      "\n",
      "Title: A Survey of Data Mining and Machine Learning Methods for Cyber Security Intrusion Detection\n",
      "Abstract: This survey paper describes a focused literature survey of machine learning (ML) and data mining (DM) methods for cyber analytics in support of intrusion detection. Short tutorial descriptions of each ML/DM method are provided. Based on the number of citations or the relevance of an emerging method, papers representing each method were identified, read, and summarized. Because data are so important in ML/DM approaches, some well-known cyber data sets used in ML/DM are described. The complexity of ML/DM algorithms is addressed, discussion of challenges for using ML/DM for cyber security is presented, and some recommendations on when to use a given method are provided.\n",
      "\n",
      "Title: Learning Phrase Representations using RNN Encoder–Decoder for Statistical Machine Translation\n",
      "Abstract: Kyunghyun Cho, Bart van Merriënboer, Caglar Gulcehre, Dzmitry Bahdanau, Fethi Bougares, Holger Schwenk, Yoshua Bengio. Proceedings of the 2014 Conference on Empirical Methods in Natural Language Processing (EMNLP). 2014.\n",
      "https://aclanthology.org/D14-1179.pdf\n",
      "\n",
      "Title: Adversarial machine learning\n",
      "Abstract: In this paper (expanded from an invited talk at AISEC 2010), we discuss an emerging field of study: adversarial machine learning---the study of effective machine learning techniques against an adversarial opponent. In this paper, we: give a taxonomy for classifying attacks against online machine learning algorithms; discuss application-specific factors that limit an adversary's capabilities; introduce two models for modeling an adversary's capabilities; explore the limits of an adversary's knowledge about the algorithm, feature space, training, and input data; explore vulnerabilities in machine learning algorithms; discuss countermeasures against attacks; introduce the evasion challenge; and discuss privacy-preserving learning techniques.\n",
      "\n",
      "Title: Proceedings of The 32nd International Conference on Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine Learning: Algorithms, Real-World Applications and Research Directions\n",
      "Abstract: None\n",
      "\n",
      "Title: Applications of machine learning in drug discovery and development\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine Learning for Medical Imaging\n",
      "Abstract: Machine learning is a technique for recognizing patterns that can be applied to medical images. Although it is a powerful tool that can help in rendering medical diagnoses, it can be misapplied. Machine learning typically begins with the machine learning algorithm system computing the image features that are believed to be of importance in making the prediction or diagnosis of interest. The machine learning algorithm system then identifies the best combination of these image features for classifying the image or computing some metric for the given image region. There are several methods that can be used, each with different strengths and weaknesses. There are open-source versions of most of these machine learning methods that make them easy to try and apply to images. Several metrics for measuring the performance of an algorithm exist; however, one must be aware of the possible associated pitfalls that can result in misleading metrics. More recently, deep learning has started to be used; this method has the benefit that it does not require image feature identification and calculation as a first step; rather, features are identified as part of the learning process. Machine learning has been used in medical imaging and will have a greater influence in the future. Those working in medical imaging must be aware of how machine learning works. ©RSNA, 2017\n",
      "\n",
      "Title: Evasion Attacks against Machine Learning at Test Time\n",
      "Abstract: None\n",
      "\n",
      "Title: Making Large-Scale Support Vector Machine Learning Practical\n",
      "Abstract: None\n",
      "\n",
      "Title: Foundations of Machine Learning\n",
      "Abstract: Foundations of Machine LearningSoon we will embark on a theoretical study of AdaBoost in order to understand its properties, particularly its ability as a learning algorithm to generalize, that is, to make accurate predictions on data not seen during training.Before this will be possible, however, it will be necessary to take a step back to outline our approach to the more general problem of machine learning, including some fundamental general-purpose tools that will be invaluable in our analysis of AdaBoost.We study the basic problem of inferring from a set of training examples a classification rule whose predictions are highly accurate on freshly observed test data.On first encounter, it may seem questionable whether this kind of learning should even be possible.After all, why should there be any connection between the training and test examples, and why should it be possible to generalize from a relatively small number of training examples to a potentially vast universe of test examples?Although such objections have indeed often been the subject of philosophical debate, in this chapter we will identify an idealized but realistic model of the inference problem in which this kind of learning can be proved to be entirely feasible when certain conditions are satisfied.In particular, we will see that if we can find a simple rule that fits the training data well, and if the training set is not too small, then this rule will in fact generalize well, providing accurate predictions on previously unseen test examples.This is the basis of the approach presented in this chapter, and we will often use the general analysis on which it is founded to guide us in understanding how, why, and when learning is possible.We also outline in this chapter a mathematical framework for studying machine learning, one in which a precise formulation of the boosting problem can be clearly and naturally expressed.Note that, unlike the rest of the book, this chapter omits nearly all of the proofs of the main results since these have largely all appeared in various texts and articles.\n",
      "https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025421/c000700_9780262301183.pdf\n",
      "\n",
      "Title: The immune system, adaptation, and machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine Learning: An Applied Econometric Approach\n",
      "Abstract: Machines are increasingly doing “intelligent” things. Face recognition algorithms use a large dataset of photos labeled as having a face or not to estimate a function that predicts the presence y of a face from pixels x. This similarity to econometrics raises questions: How do these new empirical tools fit with what we know? As empirical economists, how can we use them? We present a way of thinking about machine learning that gives it its own place in the econometric toolbox. Machine learning not only provides new tools, it solves a different problem. Specifically, machine learning revolves around the problem of prediction, while many economic applications revolve around parameter estimation. So applying machine learning to economics requires finding relevant tasks. Machine learning algorithms are now technically easy to use: you can download convenient packages in R or Python. This also raises the risk that the algorithms are applied naively or their output is misinterpreted. We hope to make them conceptually easier to use by providing a crisper understanding of how these algorithms work, where they excel, and where they can stumble—and thus where they can be most usefully applied.\n",
      "https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87\n",
      "\n",
      "Title: A Review of Relational Machine Learning for Knowledge Graphs\n",
      "Abstract: Relational machine learning studies methods for the statistical analysis of relational, or graph-structured, data. In this paper, we provide a review of how such statistical models can be \"trained\" on large knowledge graphs, and then used to predict new facts about the world (which is equivalent to predicting new edges in the graph). In particular, we discuss two fundamentally different kinds of statistical relational models, both of which can scale to massive datasets. The first is based on latent feature models such as tensor factorization and multiway neural networks. The second is based on mining observable patterns in the graph. We also show how to combine these latent and observable models to get improved modeling power at decreased computational cost. Finally, we discuss how such statistical models of graphs can be combined with text-based information extraction methods for automatically constructing knowledge graphs from the Web. To this end, we also discuss Google's Knowledge Vault project as an example of such combination.\n",
      "\n",
      "Title: Extreme learning machine: Theory and applications\n",
      "Abstract: None\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: \"Pattern Recognition and Machine Learning.\" Journal of the American Statistical Association, 103(482), pp. 886–887\n",
      "\n",
      "Title: Neural Machine Translation by Jointly Learning to Align and Translate\n",
      "Abstract: Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.\n",
      "\n",
      "Title: Machine learning phases of matter\n",
      "Abstract: None\n",
      "\n",
      "Title: MXNet: A Flexible and Efficient Machine Learning Library for Heterogeneous Distributed Systems\n",
      "Abstract: MXNet is a multi-language machine learning (ML) library to ease the development of ML algorithms, especially for deep neural networks. Embedded in the host language, it blends declarative symbolic expression with imperative tensor computation. It offers auto differentiation to derive gradients. MXNet is computation and memory efficient and runs on various heterogeneous systems, ranging from mobile devices to distributed GPU clusters. This paper describes both the API design and the system implementation of MXNet, and explains how embedding of both symbolic expression and tensor operation is handled in a unified fashion. Our preliminary experiments reveal promising results on large scale deep neural network applications using multiple GPU machines.\n",
      "\n",
      "Title: Machine learning and deep learning\n",
      "Abstract: Abstract Today, intelligent systems that offer artificial intelligence capabilities often rely on machine learning. Machine learning describes the capacity of systems to learn from problem-specific training data to automate the process of analytical model building and solve associated tasks. Deep learning is a machine learning concept based on artificial neural networks. For many applications, deep learning models outperform shallow machine learning models and traditional data analysis approaches. In this article, we summarize the fundamentals of machine learning and deep learning to generate a broader understanding of the methodical underpinning of current intelligent systems. In particular, we provide a conceptual distinction between relevant terms and concepts, explain the process of automated analytical model building through machine learning and deep learning, and discuss the challenges that arise when implementing such intelligent systems in the field of electronic markets and networked business. These naturally go beyond technological aspects and highlight issues in human-machine interaction and artificial intelligence servitization.\n",
      "https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf\n",
      "\n",
      "Title: Map-Reduce for Machine Learning on Multicore\n",
      "Abstract: We are at the beginning of the multicore era. Computers will have increasingly many cores (processors), but there is still no good programming framework for these architectures, and thus no simple and unified way for machine learning to take advantage of the potential speed up. In this paper, we develop a broadly applicable parallel programming method, one that is easily applied to many different learning algorithms. Our work is in distinct contrast to the tradition in machine learning of designing (often ingenious) ways to speed up a single algorithm at a time. Specifically, we show that algorithms that fit the Statistical Query model [15] can be written in a certain summation form, which allows them to be easily parallelized on multicore computers. We adapt Google's map-reduce [7] paradigm to demonstrate this parallel speed up technique on a variety of learning algorithms including locally weighted linear regression (LWLR), k-means, logistic regression (LR), naive Bayes (NB), SVM, ICA, PCA, gaussian discriminant analysis (GDA), EM, and backpropagation (NN). Our experimental results show basically linear speedup with an increasing number of processors.\n",
      "\n",
      "Title: Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Correlation-based Feature Selection for Discrete and Numeric Class Machine Learning\n",
      "Abstract: Algorithms for feature selection fall into two broad categories: wrappers that use the learning algorithm itself to evaluate the usefulness of features and filters that evaluate features according to heuristics based on general characteristics of the data. For application to large databases, filters have proven to be more practical than wrappers because they are much faster. However, most existing filter algorithms only work with discrete classification problems. This paper describes a fast, correlation-based filter algorithm that can be applied to continuous and discrete problems. The algorithm often outperforms the well-known ReliefF attribute estimator when used as a preprocessing step for naive Bayes, instance-based learning, decision trees, locally weighted regression, and model trees. It performs more feature selection than ReliefF does—reducing the data dimensionality by fifty percent in most cases. Also, decision and model trees built from the preprocessed data are often significantly smaller.\n",
      "\n",
      "Title: Machine Learning Algorithms - A Review\n",
      "Abstract: Machine learning (ML) is the scientific study of algorithms and statistical models that computer systems use to perform a specific task without being explicitly programmed. Learning algorithms in many applications that's we make use of daily. Every time a web search engine like Google is used to search the internet, one of the reasons that work so well is because a learning algorithm thathas learned how to rank web pages.These algorithms are used for various purposes like data mining, image processing, predictive analytics, etc. to name a few.The main advantage of using machine learning is that, once an algorithm learns what to do with data, it can do its work automatically.In this paper, a brief review and future prospect of the vast applications of machine learning algorithms has been made.\n",
      "\n",
      "Title: GAUSSIAN PROCESSES FOR MACHINE LEARNING\n",
      "Abstract: Gaussian processes (GPs) are natural generalisations of multivariate Gaussian random variables to infinite (countably or continuous) index sets. GPs have been applied in a large number of fields to a diverse range of ends, and very many deep theoretical analyses of various properties are available. This paper gives an introduction to Gaussian processes on a fairly elementary level with special emphasis on characteristics relevant in machine learning. It draws explicit connections to branches such as spline smoothing models and support vector machines in which similar ideas have been investigated. Gaussian process models are routinely used to solve hard machine learning problems. They are attractive because of their flexible non-parametric nature and computational simplicity. Treated within a Bayesian framework, very powerful statistical methods can be implemented which offer valid estimates of uncertainties in our predictions and generic model selection procedures cast as nonlinear optimization problems. Their main drawback of heavy computational scaling has recently been alleviated by the introduction of generic sparse approximations. 13,78,31 The mathematical literature on GPs is large and often uses deep concepts which are not required to fully understand most machine learning applications. In this tutorial paper, we aim to present characteristics of GPs relevant to machine learning and to show up precise connections to other \"kernel machines\" popular in the community. Our focus is on a simple presentation, but references to more detailed sources are provided.\n",
      "\n",
      "Title: Machine learning for medical diagnosis: history, state of the art and perspective\n",
      "Abstract: None\n",
      "\n",
      "Title: Neural Machine Translation by Jointly Learning to Align and Translate\n",
      "Abstract: Neural machine translation is a recently proposed approach to machine translation. Unlike the traditional statistical machine translation, the neural machine translation aims at building a single neural network that can be jointly tuned to maximize the translation performance. The models proposed recently for neural machine translation often belong to a family of encoder-decoders and consists of an encoder that encodes a source sentence into a fixed-length vector from which a decoder generates a translation. In this paper, we conjecture that the use of a fixed-length vector is a bottleneck in improving the performance of this basic encoder-decoder architecture, and propose to extend this by allowing a model to automatically (soft-)search for parts of a source sentence that are relevant to predicting a target word, without having to form these parts as a hard segment explicitly. With this new approach, we achieve a translation performance comparable to the existing state-of-the-art phrase-based system on the task of English-to-French translation. Furthermore, qualitative analysis reveals that the (soft-)alignments found by the model agree well with our intuition.\n",
      "\n",
      "Title: Adaptive Computation and Machine Learning\n",
      "Abstract: None\n",
      "https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025438/c002700_9780262301183.pdf\n",
      "\n",
      "Title: Bioinformatics: The Machine Learning Approach\n",
      "Abstract: In this book Pierre Baldi and Soren Brunak present the key machine learning approaches and apply them to the computational problems encountered in the analysis of biological data. The book is aimed both at biologists and biochemists who need to understand new data-driven algorithms and at those with a primary background in physics, mathematics, statistics, or computer science who need to know more about applications in molecular biology.\n",
      "\n",
      "Title: Machine learning: An artificial intelligence approach\n",
      "Abstract: None\n",
      "\n",
      "Title: Explaining Explanations: An Overview of Interpretability of Machine Learning\n",
      "Abstract: There has recently been a surge of work in explanatory artificial intelligence (XAI). This research area tackles the important problem that complex machines and algorithms often cannot provide insights into their behavior and thought processes. XAI allows users and parts of the internal system to be more transparent, providing explanations of their decisions in some level of detail. These explanations are important to ensure algorithmic fairness, identify potential bias/problems in the training data, and to ensure that the algorithms perform as expected. However, explanations produced by these systems is neither standardized nor systematically assessed. In an effort to create best practices and identify open challenges, we describe foundational concepts of explainability and show how they can be used to classify existing literature. We discuss why current approaches to explanatory methods especially for deep neural networks are insufficient. Finally, based on our survey, we conclude with suggested future research directions for explanatory artificial intelligence.\n",
      "\n",
      "Title: Machine learning: a review of classification and combining techniques\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine Learning: An Algorithmic Perspective\n",
      "Abstract: Written in an easily accessible style, this book provides the ideal blend of theory and practical, applicable knowledge. It covers neural networks, graphical models, reinforcement learning, evolutionary algorithms, dimensionality reduction methods, and the important area of optimization. It treads the fine line between adequate academic rigor and overwhelming students with equations and mathematical concepts. The author includes examples based on widely available datasets and practical and theoretical problems to test understanding and application of the material. The book describes algorithms with code examples backed up by a website that provides working implementations in Python.\n",
      "\n",
      "Title: Federated Optimization: Distributed Machine Learning for On-Device Intelligence\n",
      "Abstract: We introduce a new and increasingly relevant setting for distributed optimization in machine learning, where the data defining the optimization are unevenly distributed over an extremely large number of nodes. The goal is to train a high-quality centralized model. We refer to this setting as Federated Optimization. In this setting, communication efficiency is of the utmost importance and minimizing the number of rounds of communication is the principal goal. A motivating example arises when we keep the training data locally on users' mobile devices instead of logging it to a data center for training. In federated optimziation, the devices are used as compute nodes performing computation on their local data in order to update a global model. We suppose that we have extremely large number of devices in the network --- as many as the number of users of a given service, each of which has only a tiny fraction of the total data available. In particular, we expect the number of data points available locally to be much smaller than the number of devices. Additionally, since different users generate data with different patterns, it is reasonable to assume that no device has a representative sample of the overall distribution. We show that existing algorithms are not suitable for this setting, and propose a new algorithm which shows encouraging experimental results for sparse convex problems. This work also sets a path for future research needed in the context of \\federated optimization.\n",
      "\n",
      "Title: A survey of techniques for internet traffic classification using machine learning\n",
      "Abstract: The research community has begun looking for IP traffic classification techniques that do not rely on `well known' TCP or UDP port numbers, or interpreting the contents of packet payloads. New work is emerging on the use of statistical traffic characteristics to assist in the identification and classification process. This survey paper looks at emerging research into the application of Machine Learning (ML) techniques to IP traffic classification - an inter-disciplinary blend of IP networking and data mining techniques. We provide context and motivation for the application of ML techniques to IP traffic classification, and review 18 significant works that cover the dominant period from 2004 to early 2007. These works are categorized and reviewed according to their choice of ML strategies and primary contributions to the literature. We also discuss a number of key requirements for the employment of ML-based traffic classifiers in operational IP networks, and qualitatively critique the extent to which the reviewed works meet these requirements. Open issues and challenges in the field are also discussed.\n",
      "\n",
      "Title: Trainable Weka Segmentation: a machine learning tool for microscopy pixel classification\n",
      "Abstract: State-of-the-art light and electron microscopes are capable of acquiring large image datasets, but quantitatively evaluating the data often involves manually annotating structures of interest. This process is time-consuming and often a major bottleneck in the evaluation pipeline. To overcome this problem, we have introduced the Trainable Weka Segmentation (TWS), a machine learning tool that leverages a limited number of manual annotations in order to train a classifier and segment the remaining data automatically. In addition, TWS can provide unsupervised segmentation learning schemes (clustering) and can be customized to employ user-designed image features or classifiers.TWS is distributed as open-source software as part of the Fiji image processing distribution of ImageJ at http://imagej.net/Trainable_Weka_Segmentation .ignacio.arganda@ehu.eus.Supplementary data are available at Bioinformatics online.\n",
      "\n",
      "Title: Proceedings of the 29th International Conference on Machine Learning (ICML-12)\n",
      "Abstract: This is an index to the papers that appear in the Proceedings of the 29th International Conference on Machine Learning (ICML-12). The conference was held in Edinburgh, Scotland, June 27th - July 3rd, 2012.\n",
      "\n",
      "Title: Feature selection in machine learning: A new perspective\n",
      "Abstract: None\n",
      "\n",
      "Title: An Introduction to Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Torch7: A Matlab-like Environment for Machine Learning\n",
      "Abstract: Torch7 is a versatile numeric computing framework and machine learning library that extends Lua. Its goal is to provide a flexible environment to design and train learning machines. Flexibility is obtained via Lua, an extremely lightweight scripting language. High performance is obtained via efficient OpenMP/SSE and CUDA implementations of low-level numeric routines. Torch7 can easily be interfaced to third-party software thanks to Lua’s light interface.\n",
      "\n",
      "Title: Diffuse large B-cell lymphoma outcome prediction by gene-expression profiling and supervised machine learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Combining satellite imagery and machine learning to predict poverty\n",
      "Abstract: Measuring consumption and wealth remotely Nighttime lighting is a rough proxy for economic wealth, and nighttime maps of the world show that many developing countries are sparsely illuminated. Jean et al. combined nighttime maps with high-resolution daytime satellite images (see the Perspective by Blumenstock). With a bit of machine-learning wizardry, the combined images can be converted into accurate estimates of household consumption and assets, both of which are hard to measure in poorer countries. Furthermore, the night- and day-time data are publicly available and nonproprietary. Science , this issue p. 790 ; see also p. 753\n",
      "\n",
      "Title: Incremental and Decremental Support Vector Machine Learning\n",
      "Abstract: An on-line recursive algorithm for training support vector machines, one vector at a time, is presented. Adiabatic increments retain the Kuhn-Tucker conditions on all previously seen training data, in a number of steps each computed analytically. The incremental procedure is reversible, and decremental offers an efficient method to exactly evaluate leave-one-out generalization performance. Interpretation of decremental unlearning in feature space sheds light on the relationship between generalization and geometry of the data.\n",
      "\n",
      "Title: Proceedings of the 28th International Conference on Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: On hyperparameter optimization of machine learning algorithms: Theory and practice\n",
      "Abstract: None\n",
      "\n",
      "Title: Perspective: Machine learning potentials for atomistic simulations\n",
      "Abstract: Nowadays, computer simulations have become a standard tool in essentially all fields of chemistry, condensed matter physics, and materials science. In order to keep up with state-of-the-art experiments and the ever growing complexity of the investigated problems, there is a constantly increasing need for simulations of more realistic, i.e., larger, model systems with improved accuracy. In many cases, the availability of sufficiently efficient interatomic potentials providing reliable energies and forces has become a serious bottleneck for performing these simulations. To address this problem, currently a paradigm change is taking place in the development of interatomic potentials. Since the early days of computer simulations simplified potentials have been derived using physical approximations whenever the direct application of electronic structure methods has been too demanding. Recent advances in machine learning (ML) now offer an alternative approach for the representation of potential-energy surfaces by fitting large data sets from electronic structure calculations. In this perspective, the central ideas underlying these ML potentials, solved problems and remaining challenges are reviewed along with a discussion of their current applicability and limitations.\n",
      "https://aip.scitation.org/doi/pdf/10.1063/1.4966192\n",
      "\n",
      "Title: SecureML: A System for Scalable Privacy-Preserving Machine Learning\n",
      "Abstract: Machine learning is widely used in practice to produce predictive models for applications such as image processing, speech and text recognition. These models are more accurate when trained on large amount of data collected from different sources. However, the massive data collection raises privacy concerns. In this paper, we present new and efficient protocols for privacy preserving machine learning for linear regression, logistic regression and neural network training using the stochastic gradient descent method. Our protocols fall in the two-server model where data owners distribute their private data among two non-colluding servers who train various models on the joint data using secure two-party computation (2PC). We develop new techniques to support secure arithmetic operations on shared decimal numbers, and propose MPC-friendly alternatives to non-linear functions such as sigmoid and softmax that are superior to prior work. We implement our system in C++. Our experiments validate that our protocols are several orders of magnitude faster than the state of the art implementations for privacy preserving linear and logistic regressions, and scale to millions of data samples with thousands of features. We also implement the first privacy preserving system for training neural networks.\n",
      "\n",
      "Title: An Introduction to Support Vector Machines and Other Kernel-based Learning Methods\n",
      "Abstract: This is the first comprehensive introduction to Support Vector Machines (SVMs), a generation learning system based on recent advances in statistical learning theory. SVMs deliver state-of-the-art performance in real-world applications such as text categorisation, hand-written character recognition, image classification, biosequences analysis, etc., and are now established as one of the standard tools for machine learning and data mining. Students will find the book both stimulating and accessible, while practitioners will be guided smoothly through the material required for a good grasp of the theory and its applications. The concepts are introduced gradually in accessible and self-contained stages, while the presentation is rigorous and thorough. Pointers to relevant literature and web sites containing software ensure that it forms an ideal starting point for further study. Equally, the book and its associated web site will guide practitioners to updated literature, new applications, and on-line software.\n",
      "\n",
      "Title: Applications of machine learning to machine fault diagnosis: A review and roadmap\n",
      "Abstract: None\n",
      "\n",
      "Title: Optimization for Machine Learning\n",
      "Abstract: An up-to-date account of the interplay between optimization and machine learning, accessible to students and researchers in both communities. The interplay between optimization and machine learning is one of the most important developments in modern computational science. Optimization formulations and methods are proving to be vital in designing algorithms to extract essential knowledge from huge volumes of data. Machine learning, however, is not simply a consumer of optimization technology but a rapidly evolving field that is itself generating new optimization ideas. This book captures the state of the art of the interaction between optimization and machine learning in a way that is accessible to researchers in both fields. Optimization approaches have enjoyed prominence in machine learning because of their wide applicability and attractive theoretical properties. The increasing complexity, size, and variety of today's machine learning models call for the reassessment of existing assumptions. This book starts the process of reassessment. It describes the resurgence in novel contexts of established frameworks such as first-order methods, stochastic approximations, convex relaxations, interior-point methods, and proximal methods. It also devotes attention to newer themes such as regularized optimization, robust optimization, gradient and subgradient methods, splitting techniques, and second-order methods. Many of these techniques draw inspiration from other fields, including operations research, theoretical computer science, and subfields of optimization. The book will enrich the ongoing cross-fertilization between the machine learning community and these other fields, and within the broader optimization community.\n",
      "\n",
      "Title: Tensor Decomposition for Signal Processing and Machine Learning\n",
      "Abstract: Tensors or {\\em multi-way arrays} are functions of three or more indices $(i,j,k,\\cdots)$ -- similar to matrices (two-way arrays), which are functions of two indices $(r,c)$ for (row,column). Tensors have a rich history, stretching over almost a century, and touching upon numerous disciplines; but they have only recently become ubiquitous in signal and data analytics at the confluence of signal processing, statistics, data mining and machine learning. This overview article aims to provide a good starting point for researchers and practitioners interested in learning about and working with tensors. As such, it focuses on fundamentals and motivation (using various application examples), aiming to strike an appropriate balance of breadth {\\em and depth} that will enable someone having taken first graduate courses in matrix algebra and probability to get started doing research and/or developing tensor algorithms and software. Some background in applied optimization is useful but not strictly required. The material covered includes tensor rank and rank decomposition; basic tensor factorization models and their relationships and properties (including fairly good coverage of identifiability); broad coverage of algorithms ranging from alternating optimization to stochastic gradient; statistical performance analysis; and applications ranging from source separation to collaborative filtering, mixture and topic modeling, classification, and multilinear subspace learning.\n",
      "\n",
      "Title: Efficient and robust automated machine learning\n",
      "Abstract: The success of machine learning in a broad range of applications has led to an ever-growing demand for machine learning systems that can be used off the shelf by non-experts. To be effective in practice, such systems need to automatically choose a good algorithm and feature preprocessing steps for a new dataset at hand, and also set their respective hyperparameters. Recent work has started to tackle this automated machine learning (AutoML) problem with the help of efficient Bayesian optimization methods. Building on this, we introduce a robust new AutoML system based on scikit-learn (using 15 classifiers, 14 feature preprocessing methods, and 4 data preprocessing methods, giving rise to a structured hypothesis space with 110 hyperparameters). This system, which we dub AUTO-SKLEARN, improves on existing AutoML methods by automatically taking into account past performance on similar datasets, and by constructing ensembles from the models evaluated during the optimization. Our system won the first phase of the ongoing ChaLearn AutoML challenge, and our comprehensive analysis on over 100 diverse datasets shows that it substantially outperforms the previous state of the art in AutoML. We also demonstrate the performance gains due to each of our contributions and derive insights into the effectiveness of the individual components of AUTO-SKLEARN.\n",
      "\n",
      "Title: Definitions, methods, and applications in interpretable machine learning\n",
      "Abstract: Machine-learning models have demonstrated great success in learning complex patterns that enable them to make predictions about unobserved data. In addition to using models for prediction, the ability to interpret what a model has learned is receiving an increasing amount of attention. However, this increased focus has led to considerable confusion about the notion of interpretability. In particular, it is unclear how the wide array of proposed interpretation methods are related and what common concepts can be used to evaluate them. We aim to address these concerns by defining interpretability in the context of machine learning and introducing the predictive, descriptive, relevant (PDR) framework for discussing interpretations. The PDR framework provides 3 overarching desiderata for evaluation: predictive accuracy, descriptive accuracy, and relevancy, with relevancy judged relative to a human audience. Moreover, to help manage the deluge of interpretation methods, we introduce a categorization of existing techniques into model-based and post hoc categories, with subgroups including sparsity, modularity, and simulatability. To demonstrate how practitioners can use the PDR framework to evaluate and understand interpretations, we provide numerous real-world examples. These examples highlight the often underappreciated role played by human audiences in discussions of interpretability. Finally, based on our framework, we discuss limitations of existing methods and directions for future work. We hope that this work will provide a common vocabulary that will make it easier for both practitioners and researchers to discuss and choose from the full range of interpretation methods.\n",
      "\n",
      "Title: Machine learning methods for solar radiation forecasting: A review\n",
      "Abstract: None\n",
      "\n",
      "Title: WEKA: a machine learning workbench\n",
      "Abstract: WEKA is a workbench for machine learning that is intended to aid in the application of machine learning techniques to a variety of real-world problems, in particular, those arising from agricultural and horticultural domains. Unlike other machine learning projects, the emphasis is on providing a working environment for the domain specialist rather than the machine learning expert. Lessons learned include the necessity of providing a wealth of interactive tools for data manipulation, result visualization, database linkage, and cross-validation and comparison of rule sets, to complement the basic machine learning tools.< <ETX xmlns:mml=\"http://www.w3.org/1998/Math/MathML\" xmlns:xlink=\"http://www.w3.org/1999/xlink\">&gt;</ETX>\n",
      "\n",
      "Title: Foundations of Machine Learning\n",
      "Abstract: The emphasis of machine learning is on automatic methods. In other words, the goal is to devise learning algorithms that do the learning automatically without human intervention or assistance. The machine learning paradigm can be viewed as \"programming by example.\" Often we have a specific task in mind, such as spam filtering. But rather than program the computer to solve the task directly, in machine learning, we seek methods by which the computer will come up with its own program based on examples that i provide.Before getting to our first learning model, i will need some definitions. An example (sometimes also called an instance) is the object that is being classified. For instance, in spam filtering, the email messages are the examples.Usually, an example is described by a set of attributes, also known as features or variables. For instance, in medical diagnosis, a patient might be described by attributes such as gender, age, weight, blood pressure, body temperature, etc.The label is the category that we are trying to predict. For instance, in spam filtering, the possible labels are \"spam\" and \"not spam\". During training, the learning algorithm is supplied with labeled examples, while during testing, only unlabeled examples are provided.\n",
      "\n",
      "Title: Machine learning in bioinformatics\n",
      "Abstract: This article reviews machine learning methods for bioinformatics. It presents modelling methods, such as supervised classification, clustering and probabilistic graphical models for knowledge discovery, as well as deterministic and stochastic heuristics for optimization. Applications in genomics, proteomics, systems biology, evolution and text mining are also shown.\n",
      "https://academic.oup.com/bib/article-pdf/7/1/86/23992771/bbk007.pdf\n",
      "\n",
      "Title: Machine-learning-assisted materials discovery using failed experiments\n",
      "Abstract: None\n",
      "\n",
      "Title: Big Data and Machine Learning in Health Care\n",
      "Abstract: Our website uses cookies to enhance your experience. By continuing to use our site, or clicking \"Continue,\" you are agreeing to our Cookie Policy | Continue JAMA HomeNew OnlineCurrent IssueFor Authors Publications JAMA JAMA Network Open JAMA Cardiology JAMA Dermatology JAMA Health Forum JAMA Internal Medicine JAMA Neurology JAMA Oncology JAMA Ophthalmology JAMA Otolaryngology–Head & Neck Surgery JAMA Pediatrics JAMA Psychiatry JAMA Surgery Archives of Neurology & Psychiatry (1919-1959) Podcasts Clinical Reviews Editors' Summary Medical News Author Interviews More JN Learning / CMESubscribeJobsInstitutions / LibrariansReprints & Permissions Terms of Use | Privacy Policy | Accessibility Statement 2023 American Medical Association. All Rights Reserved Search All JAMA JAMA Network Open JAMA Cardiology JAMA Dermatology JAMA Forum Archive JAMA Health Forum JAMA Internal Medicine JAMA Neurology JAMA Oncology JAMA Ophthalmology JAMA Otolaryngology–Head & Neck Surgery JAMA Pediatrics JAMA Psychiatry JAMA Surgery Archives of Neurology & Psychiatry Input Search Term Sign In Individual Sign In Sign inCreate an Account Access through your institution Sign In Purchase Options: Buy this article Rent this article Subscribe to the JAMA journal\n",
      "\n",
      "Title: Machine learning in materials informatics: recent applications and prospects\n",
      "Abstract: Abstract Propelled partly by the Materials Genome Initiative, and partly by the algorithmic developments and the resounding successes of data-driven efforts in other domains, informatics strategies are beginning to take shape within materials science. These approaches lead to surrogate machine learning models that enable rapid predictions based purely on past data rather than by direct experimentation or by computations/simulations in which fundamental equations are explicitly solved. Data-centric informatics methods are becoming useful to determine material properties that are hard to measure or compute using traditional methods—due to the cost, time or effort involved—but for which reliable data either already exists or can be generated for at least a subset of the critical cases. Predictions are typically interpolative, involving fingerprinting a material numerically first, and then following a mapping (established via a learning algorithm) between the fingerprint and the property of interest. Fingerprints, also referred to as “descriptors”, may be of many types and scales, as dictated by the application domain and needs. Predictions may also be extrapolative—extending into new materials spaces—provided prediction uncertainties are properly taken into account. This article attempts to provide an overview of some of the recent successful data-driven “materials informatics” strategies undertaken in the last decade, with particular emphasis on the fingerprint or descriptor choices. The review also identifies some challenges the community is facing and those that should be overcome in the near future.\n",
      "https://www.nature.com/articles/s41524-017-0056-5.pdf\n",
      "\n",
      "Title: The security of machine learning\n",
      "Abstract: Machine learning’s ability to rapidly evolve to changing and complex situations has helped it become a fundamental tool for computer security. That adaptability is also a vulnerability: attackers can exploit machine learning systems. We present a taxonomy identifying and analyzing attacks against machine learning systems. We show how these classes influence the costs for the attacker and defender, and we give a formal structure defining their interaction. We use our framework to survey and analyze the literature of attacks against machine learning systems. We also illustrate our taxonomy by showing how it can guide attacks against SpamBayes, a popular statistical spam filter. Finally, we discuss how our taxonomy suggests new lines of defenses.\n",
      "https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf\n",
      "\n",
      "Title: Choosing Prediction Over Explanation in Psychology: Lessons From Machine Learning\n",
      "Abstract: Psychology has historically been concerned, first and foremost, with explaining the causal mechanisms that give rise to behavior. Randomized, tightly controlled experiments are enshrined as the gold standard of psychological research, and there are endless investigations of the various mediating and moderating variables that govern various behaviors. We argue that psychology's near-total focus on explaining the causes of behavior has led much of the field to be populated by research programs that provide intricate theories of psychological mechanism but that have little (or unknown) ability to predict future behaviors with any appreciable accuracy. We propose that principles and techniques from the field of machine learning can help psychology become a more predictive science. We review some of the fundamental concepts and tools of machine learning and point out examples where these concepts have been used to conduct interesting and important psychological research that focuses on predictive research questions. We suggest that an increased focus on prediction, rather than explanation, can ultimately lead us to greater understanding of behavior.\n",
      "\n",
      "Title: Statistics versus machine learning\n",
      "Abstract: None\n",
      "https://www.nature.com/articles/nmeth.4642.pdf\n",
      "\n",
      "Title: Induction of decision trees. Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Support vector machine learning for interdependent and structured output spaces\n",
      "Abstract: Learning general functional dependencies is one of the main goals in machine learning. Recent progress in kernel-based methods has focused on designing flexible and powerful input representations. This paper addresses the complementary issue of problems involving complex outputs such as multiple dependent output variables and structured output spaces. We propose to generalize multiclass Support Vector Machine learning in a formulation that involves features extracted jointly from inputs and outputs. The resulting optimization problem is solved efficiently by a cutting plane algorithm that exploits the sparseness and structural decomposition of the problem. We demonstrate the versatility and effectiveness of our method on problems ranging from supervised grammar learning and named-entity recognition, to taxonomic text classification and sequence alignment.\n",
      "\n",
      "Title: Explainable AI: A Review of Machine Learning Interpretability Methods\n",
      "Abstract: Recent advances in artificial intelligence (AI) have led to its widespread industrial adoption, with machine learning systems demonstrating superhuman performance in a significant number of tasks. However, this surge in performance, has often been achieved through increased model complexity, turning such systems into “black box” approaches and causing uncertainty regarding the way they operate and, ultimately, the way that they come to decisions. This ambiguity has made it problematic for machine learning systems to be adopted in sensitive yet critical domains, where their value could be immense, such as healthcare. As a result, scientific interest in the field of Explainable Artificial Intelligence (XAI), a field that is concerned with the development of new methods that explain and interpret machine learning models, has been tremendously reignited over recent years. This study focuses on machine learning interpretability methods; more specifically, a literature review and taxonomy of these methods are presented, as well as links to their programming implementations, in the hope that this survey would serve as a reference point for both theorists and practitioners.\n",
      "https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444\n",
      "\n",
      "Title: Outside the Closed World: On Using Machine Learning for Network Intrusion Detection\n",
      "Abstract: In network intrusion detection research, one popular strategy for finding attacks is monitoring a network's activity for anomalies: deviations from profiles of normality previously learned from benign traffic, typically identified using tools borrowed from the machine learning community. However, despite extensive academic research one finds a striking gap in terms of actual deployments of such systems: compared with other intrusion detection approaches, machine learning is rarely employed in operational \"real world\" settings. We examine the differences between the network intrusion detection problem and other areas where machine learning regularly finds much more success. Our main claim is that the task of finding attacks is fundamentally different from these other applications, making it significantly harder for the intrusion detection community to employ machine learning effectively. We support this claim by identifying challenges particular to network intrusion detection, and provide a set of guidelines meant to strengthen future research on anomaly detection.\n",
      "\n",
      "Title: Machine Learning Identifies Stemness Features Associated with Oncogenic Dedifferentiation\n",
      "Abstract: Cancer progression involves the gradual loss of a differentiated phenotype and acquisition of progenitor and stem-cell-like features. Here, we provide novel stemness indices for assessing the degree of oncogenic dedifferentiation. We used an innovative one-class logistic regression (OCLR) machine-learning algorithm to extract transcriptomic and epigenetic feature sets derived from non-transformed pluripotent stem cells and their differentiated progeny. Using OCLR, we were able to identify previously undiscovered biological mechanisms associated with the dedifferentiated oncogenic state. Analyses of the tumor microenvironment revealed unanticipated correlation of cancer stemness with immune checkpoint expression and infiltrating immune cells. We found that the dedifferentiated oncogenic phenotype was generally most prominent in metastatic tumors. Application of our stemness indices to single-cell data revealed patterns of intra-tumor molecular heterogeneity. Finally, the indices allowed for the identification of novel targets and possible targeted therapies aimed at tumor differentiation.\n",
      "\n",
      "Title: UCI Repository of Machine Learning Database\n",
      "Abstract: None\n",
      "\n",
      "Title: Majorization-Minimization Algorithms in Signal Processing, Communications, and Machine Learning\n",
      "Abstract: This paper gives an overview of the majorization-minimization (MM) algorithmic framework, which can provide guidance in deriving problem-driven algorithms with low computational cost. A general introduction of MM is presented, including a description of the basic principle and its convergence results. The extensions, acceleration schemes, and connection to other algorithmic frameworks are also covered. To bridge the gap between theory and practice, upperbounds for a large number of basic functions, derived based on the Taylor expansion, convexity, and special inequalities, are provided as ingredients for constructing surrogate functions. With the pre-requisites established, the way of applying MM to solving specific problems is elaborated by a wide range of applications in signal processing, communications, and machine learning.\n",
      "\n",
      "Title: Double/debiased machine learning for treatment and structural parameters\n",
      "Abstract: We revisit the classic semi‐parametric problem of inference on a low‐dimensional parameter θ0 in the presence of high‐dimensional nuisance parameters η0. We depart from the classical setting by allowing for η0 to be so high‐dimensional that the traditional assumptions (e.g. Donsker properties) that limit complexity of the parameter space for this object break down. To estimate η0, we consider the use of statistical or machine learning (ML) methods, which are particularly well suited to estimation in modern, very high‐dimensional cases. ML methods perform well by employing regularization to reduce variance and trading off regularization bias with overfitting in practice. However, both regularization bias and overfitting in estimating η0 cause a heavy bias in estimators of θ0 that are obtained by naively plugging ML estimators of η0 into estimating equations for θ0. This bias results in the naive estimator failing to be N−1/2 consistent, where N is the sample size. We show that the impact of regularization bias and overfitting on estimation of the parameter of interest θ0 can be removed by using two simple, yet critical, ingredients: (1) using Neyman‐orthogonal moments/scores that have reduced sensitivity with respect to nuisance parameters to estimate θ0; (2) making use of cross‐fitting, which provides an efficient form of data‐splitting. We call the resulting set of methods double or debiased ML (DML). We verify that DML delivers point estimators that concentrate in an N−1/2‐neighbourhood of the true parameter values and are approximately unbiased and normally distributed, which allows construction of valid confidence statements. The generic statistical theory of DML is elementary and simultaneously relies on only weak theoretical requirements, which will admit the use of a broad array of modern ML methods for estimating the nuisance parameters, such as random forests, lasso, ridge, deep neural nets, boosted trees, and various hybrids and ensembles of these methods. We illustrate the general theory by applying it to provide theoretical properties of the following: DML applied to learn the main regression parameter in a partially linear regression model; DML applied to learn the coefficient on an endogenous variable in a partially linear instrumental variables model; DML applied to learn the average treatment effect and the average treatment effect on the treated under unconfoundedness; DML applied to learn the local average treatment effect in an instrumental variables setting. In addition to these theoretical applications, we also illustrate the use of DML in three empirical examples.\n",
      "https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf\n",
      "\n",
      "Title: Scaling distributed machine learning with the parameter server\n",
      "Abstract: We propose a parameter server framework for distributed machine learning problems. Both data and workloads are distributed over worker nodes, while the server nodes maintain globally shared parameters, represented as dense or sparse vectors and matrices. The framework manages asynchronous data communication between nodes, and supports flexible consistency models, elastic scalability, and continuous fault tolerance.To demonstrate the scalability of the proposed framework, we show experimental results on petabytes of real data with billions of examples and parameters on problems ranging from Sparse Logistic Regression to Latent Dirichlet Allocation and Distributed Sketching.\n",
      "\n",
      "Title: MLlib: Machine Learning in Apache Spark\n",
      "Abstract: Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.\n",
      "\n",
      "Title: Practical Bayesian Optimization of Machine Learning Algorithms\n",
      "Abstract: Machine learning algorithms frequently require careful tuning of model hyperparameters, regularization terms, and optimization parameters. Unfortunately, this tuning is often a black art that requires expert experience, unwritten rules of thumb, or sometimes brute-force search. Much more appealing is the idea of developing automatic approaches which can optimize the performance of a given learning algorithm to the task at hand. In this work, we consider the automatic tuning problem within the framework of Bayesian optimization, in which a learning algorithm's generalization performance is modeled as a sample from a Gaussian process (GP). The tractable posterior distribution induced by the GP leads to efficient use of the information gathered by previous experiments, enabling optimal choices about what parameters to try next. Here we show how the effects of the Gaussian process prior and the associated inference procedure can have a large impact on the success or failure of Bayesian optimization. We show that thoughtful choices can lead to results that exceed expert-level performance in tuning machine learning algorithms. We also describe new algorithms that take into account the variable cost (duration) of learning experiments and that can leverage the presence of multiple cores for parallel experimentation. We show that these proposed algorithms improve on previous automatic procedures and can reach or surpass human expert-level optimization on a diverse set of contemporary algorithms including latent Dirichlet allocation, structured SVMs and convolutional neural networks.\n",
      "\n",
      "Title: Optimization, and Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Automated Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Recent advances and applications of machine learning in solid-state materials science\n",
      "Abstract: Abstract One of the most exciting tools that have entered the material science toolbox in recent years is machine learning. This collection of statistical methods has already proved to be capable of considerably speeding up both fundamental and applied research. At present, we are witnessing an explosion of works that develop and apply machine learning to solid-state systems. We provide a comprehensive overview and analysis of the most recent research in this topic. As a starting point, we introduce machine learning principles, algorithms, descriptors, and databases in materials science. We continue with the description of different machine learning approaches for the discovery of stable materials and the prediction of their crystal structure. Then we discuss research in numerous quantitative structure–property relationships and various approaches for the replacement of first-principle methods by machine learning. We review how active learning and surrogate-based optimization can be applied to improve the rational design process and related examples of applications. Two major questions are always the interpretability of and the physical understanding gained from machine learning models. We consider therefore the different facets of interpretability and their importance in materials science. Finally, we propose solutions and future research paths for various challenges in computational materials science.\n",
      "https://www.nature.com/articles/s41524-019-0221-0.pdf\n",
      "\n",
      "Title: Challenges in Representation Learning: A Report on Three Machine Learning Contests\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine learning in manufacturing: advantages, challenges, and applications\n",
      "Abstract: The nature of manufacturing systems faces ever more complex, dynamic and at times even chaotic behaviors. In order to being able to satisfy the demand for high-quality products in an efficient manner, it is essential to utilize all means available. One area, which saw fast pace developments in terms of not only promising results but also usability, is machine learning. Promising an answer to many of the old and new challenges of manufacturing, machine learning is widely discussed by researchers and practitioners alike. However, the field is very broad and even confusing which presents a challenge and a barrier hindering wide application. Here, this paper contributes in presenting an overview of available machine learning techniques and structuring this rather complicated area. A special focus is laid on the potential benefit, and examples of successful applications in a manufacturing environment.\n",
      "https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true\n",
      "\n",
      "Title: Correlation-based Feature Subset Selection for Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Some studies in machine learning using the game of checkers\n",
      "Abstract: Two machine-learning procedures have been investigated in some detail using the game of checkers. Enough work has been done to verify the fact that a computer can be programmed so that it will learn to play a better game of checkers than can be played by the person who wrote the program. Furthermore, it can learn to do this in a remarkably short period of time (8 or 10 hours of machine-playing time) when given only the rules of the game, a sense of direction, and a redundant and incomplete list of parameters which are thought to have something to do with the game, but whose correct signs and relative weights are unknown and unspecified. The principles of machine learning verified by these experiments are, of course, applicable to many other situations.\n",
      "\n",
      "Title: Intrusion detection by machine learning: A review\n",
      "Abstract: None\n",
      "\n",
      "Title: Pattern Recognition and Machine Learning\n",
      "Abstract: None\n",
      "\n",
      "Title: Can machine learning be secure?\n",
      "Abstract: Machine learning systems offer unparalled flexibility in dealing with evolving input in a variety of applications, such as intrusion detection systems and spam e-mail filtering. However, machine learning algorithms themselves can be a target of attack by a malicious adversary. This paper provides a framework for answering the question, \"Can machine learning be secure?\" Novel contributions of this paper include a taxonomy of different types of attacks on machine learning techniques and systems, a variety of defenses against those attacks, a discussion of ideas that are important to security for machine learning, an analytical model giving a lower bound on attacker's work function, and a list of open problems.\n",
      "\n",
      "Title: Structural Health Monitoring: A Machine Learning Perspective\n",
      "Abstract: This book focuses on structural health monitoring in the context of machine learning. The authors review the technical literature and include case studies. Chapters include: operational evaluation, sensing and data acquisition, introduction to probability and statistics, machine learning and statistical pattern recognition, and data prognosis.\n",
      "\n",
      "Title: A Machine Learning Approach to Coreference Resolution of Noun Phrases\n",
      "Abstract: In this paper, we present a learning approach to coreference resolution of noun phrases in unrestricted text. The approach learns from a small, annotated corpus and the task includes resolving not just a certain type of noun phrase (e.g., pronouns) but rather general noun phrases. It also does not restrict the entity types of the noun phrases; that is, coreference is assigned whether they are of “organization,” “person,” or other types. We evaluate our approach on common data sets (namely, the MUC-6 and MUC-7 coreference corpora) and obtain encouraging results, indicating that on the general noun phrase coreference task, the learning approach holds promise and achieves accuracy comparable to that of nonlearning approaches. Our system is the first learning-based system that offers performance comparable to that of state-of-the-art nonlearning systems on these data sets.\n",
      "https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf\n",
      "\n",
      "Title: MLlib: Machine Learning in Apache Spark\n",
      "Abstract: Apache Spark is a popular open-source platform for large-scale data processing that is well-suited for iterative machine learning tasks. In this paper we present MLlib, Spark's open-source distributed machine learning library. MLlib provides efficient functionality for a wide range of learning settings and includes several underlying statistical, optimization, and linear algebra primitives. Shipped with Spark, MLlib supports several languages and provides a high-level API that leverages Spark's rich ecosystem to simplify the development of end-to-end machine learning pipelines. MLlib has experienced a rapid growth due to its vibrant open-source community of over 140 contributors, and includes extensive documentation to support further growth and to let users quickly get up to speed.\n",
      "\n",
      "Title: Machine Learning\n",
      "Abstract: As one of the most comprehensive machine learning texts around, this book does justice to the field's incredible richness, but without losing sight of the unifying principles. Peter Flach's clear, example-based approach begins by discussing how a spam filter works, which gives an immediate introduction to machine learning in action, with a minimum of technical fuss. Flach provides case studies of increasing complexity and variety with well-chosen examples and illustrations throughout. He covers a wide range of logical, geometric and statistical models and state-of-the-art topics such as matrix factorisation and ROC analysis. Particular attention is paid to the central role played by features. The use of established terminology is balanced with the introduction of new and useful concepts, and summaries of relevant background material are provided with pointers for revision if necessary. These features ensure Machine Learning will set a new standard as an introductory textbook.\n",
      "\n",
      "Title: Machine learning in geosciences and remote sensing\n",
      "Abstract: Learning incorporates a broad range of complex procedures. Machine learning (ML) is a subdivision of artificial intelligence based on the biological learning process. The ML approach deals with the design of algorithms to learn from machine readable data. ML covers main domains such as data mining, difficult-to-program applications, and software applications. It is a collection of a variety of algorithms (e.g. neural networks, support vector machines, self-organizing map, decision trees, random forests, case-based reasoning, genetic programming, etc.) that can provide multivariate, nonlinear, nonparametric regression or classification. The modeling capabilities of the ML-based methods have resulted in their extensive applications in science and engineering. Herein, the role of ML as an effective approach for solving problems in geosciences and remote sensing will be highlighted. The unique features of some of the ML techniques will be outlined with a specific attention to genetic programming paradigm. Furthermore, nonparametric regression and classification illustrative examples are presented to demonstrate the efficiency of ML for tackling the geosciences and remote sensing problems.\n",
      "\n",
      "Title: All-optical machine learning using diffractive deep neural networks\n",
      "Abstract: We introduce an all-optical Diffractive Deep Neural Network (D2NN) architecture that can learn to implement various functions after deep learning-based design of passive diffractive layers that work collectively. We experimentally demonstrated the success of this framework by creating 3D-printed D2NNs that learned to implement handwritten digit classification and the function of an imaging lens at terahertz spectrum. With the existing plethora of 3D-printing and other lithographic fabrication methods as well as spatial-light-modulators, this all-optical deep learning framework can perform, at the speed of light, various complex functions that computer-based neural networks can implement, and will find applications in all-optical image analysis, feature detection and object classification, also enabling new camera designs and optical components that can learn to perform unique tasks using D2NNs.\n",
      "https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf\n",
      "\n",
      "Title: Applications of Machine Learning in Cancer Prediction and Prognosis\n",
      "Abstract: Machine learning is a branch of artificial intelligence that employs a variety of statistical, probabilistic and optimization techniques that allows computers to “learn” from past examples and to detect hard-to-discern patterns from large, noisy or complex data sets. This capability is particularly well-suited to medical applications, especially those that depend on complex proteomic and genomic measurements. As a result, machine learning is frequently used in cancer diagnosis and detection. More recently machine learning has been applied to cancer prognosis and prediction. This latter approach is particularly interesting as it is part of a growing trend towards personalized, predictive medicine. In assembling this review we conducted a broad survey of the different types of machine learning methods being used, the types of data being integrated and the performance of these methods in cancer prediction and prognosis. A number of trends are noted, including a growing dependence on protein biomarkers and microarray data, a strong bias towards applications in prostate and breast cancer, and a heavy reliance on “older” technologies such artificial neural networks (ANNs) instead of more recently developed or more easily interpretable machine learning methods. A number of published studies also appear to lack an appropriate level of validation or testing. Among the better designed and validated studies it is clear that machine learning methods can be used to substantially (15–25%) improve the accuracy of predicting cancer susceptibility, recurrence and mortality. At a more fundamental level, it is also evident that machine learning is also helping to improve our basic understanding of cancer development and progression.\n",
      "https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030\n",
      "\n",
      "Title: Machine learning and data mining\n",
      "Abstract: article Free Access Share on Machine learning and data mining Author: Tom M. Mitchell Carnegie-Mellon Univ., Pittsburgh, PA Carnegie-Mellon Univ., Pittsburgh, PAView Profile Authors Info & Claims Communications of the ACMVolume 42Issue 11Nov. 1999pp 30–36https://doi.org/10.1145/319382.319388Published:01 November 1999Publication History 349citation16,604DownloadsMetricsTotal Citations349Total Downloads16,604Last 12 Months3,016Last 6 weeks639 Get Citation AlertsNew Citation Alert added!This alert has been successfully added and will be sent to:You will be notified whenever a record that you have chosen has been cited.To manage your alert preferences, click on the button below.Manage my AlertsNew Citation Alert!Please log in to your account Save to BinderSave to BinderCreate a New BinderNameCancelCreateExport CitationPublisher SiteView all FormatsPDF\n",
      "https://dl.acm.org/doi/pdf/10.1145/319382.319388\n",
      "\n",
      "Title: Overfitting and undercomputing in machine learning\n",
      "Abstract: No abstract available.\n",
      "https://dl.acm.org/doi/pdf/10.1145/212094.212114\n",
      "\n",
      "Title: Machine Learning Interpretability: A Survey on Methods and Metrics\n",
      "Abstract: Machine learning systems are becoming increasingly ubiquitous. These systems’s adoption has been expanding, accelerating the shift towards a more algorithmic society, meaning that algorithmically informed decisions have greater potential for significant social impact. However, most of these accurate decision support systems remain complex black boxes, meaning their internal logic and inner workings are hidden to the user and even experts cannot fully understand the rationale behind their predictions. Moreover, new regulations and highly regulated domains have made the audit and verifiability of decisions mandatory, increasing the demand for the ability to question, understand, and trust machine learning systems, for which interpretability is indispensable. The research community has recognized this interpretability problem and focused on developing both interpretable models and explanation methods over the past few years. However, the emergence of these methods shows there is no consensus on how to assess the explanation quality. Which are the most suitable metrics to assess the quality of an explanation? The aim of this article is to provide a review of the current state of the research field on machine learning interpretability while focusing on the societal impact and on the developed methods and metrics. Furthermore, a complete literature review is presented in order to identify future directions of work on this field.\n",
      "https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847\n",
      "\n",
      "Title: Machine Learning Paradigms for Next-Generation Wireless Networks\n",
      "Abstract: Next-generation wireless networks are expected to support extremely high data rates and radically new applications, which require a new wireless radio technology paradigm. The challenge is that of assisting the radio in intelligent adaptive learning and decision making, so that the diverse requirements of next-generation wireless networks can be satisfied. Machine learning is one of the most promising artificial intelligence tools, conceived to support smart radio terminals. Future smart 5G mobile terminals are expected to autonomously access the most meritorious spectral bands with the aid of sophisticated spectral efficiency learning and inference, in order to control the transmission power, while relying on energy efficiency learning/inference and simultaneously adjusting the transmission protocols with the aid of quality of service learning/inference. Hence we briefly review the rudimentary concepts of machine learning and propose their employment in the compelling applications of 5G networks, including cognitive radios, massive MIMOs, femto/small cells, heterogeneous networks, smart grid, energy harvesting, device-todevice communications, and so on. Our goal is to assist the readers in refining the motivation, problem formulation, and methodology of powerful machine learning algorithms in the context of future networks in order to tap into hitherto unexplored applications and services.\n",
      "\n",
      "Title: Implementation of machine-learning classification in remote sensing: an applied review\n",
      "Abstract: Machine learning offers the potential for effective and efficient classification of remotely sensed imagery. The strengths of machine learning include the capacity to handle data of high dimensionality and to map classes with very complex characteristics. Nevertheless, implementing a machine-learning classification is not straightforward, and the literature provides conflicting advice regarding many key issues. This article therefore provides an overview of machine learning from an applied perspective. We focus on the relatively mature methods of support vector machines, single decision trees (DTs), Random Forests, boosted DTs, artificial neural networks, and k-nearest neighbours (k-NN). Issues considered include the choice of algorithm, training data requirements, user-defined parameter selection and optimization, feature space impacts and reduction, and computational costs. We illustrate these issues through applying machine-learning classification to two publically available remotely sensed data sets.\n",
      "https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true\n",
      "\n",
      "Title: Techniques for interpretable machine learning\n",
      "Abstract: Uncovering the mysterious ways machine learning models make decisions.\n",
      "\n",
      "Title: API design for machine learning software: experiences from the scikit-learn project\n",
      "Abstract: Scikit-learn is an increasingly popular machine learning li- brary. Written in Python, it is designed to be simple and efficient, accessible to non-experts, and reusable in various contexts. In this paper, we present and discuss our design choices for the application programming interface (API) of the project. In particular, we describe the simple and elegant interface shared by all learning and processing units in the library and then discuss its advantages in terms of composition and reusability. The paper also comments on implementation details specific to the Python ecosystem and analyzes obstacles faced by users and developers of the library.\n",
      "https://inria.hal.science/hal-00856511/document\n",
      "\n",
      "Title: A guide to machine learning for biologists\n",
      "Abstract: None\n",
      "\n",
      "Title: Explainable machine-learning predictions for the prevention of hypoxaemia during surgery\n",
      "Abstract: None\n",
      "\n",
      "Title: Machine Learning and Data Mining Methods in Diabetes Research\n",
      "Abstract: The remarkable advances in biotechnology and health sciences have led to a significant production of data, such as high throughput genetic data and clinical information, generated from large Electronic Health Records (EHRs). To this end, application of machine learning and data mining methods in biosciences is presently, more than ever before, vital and indispensable in efforts to transform intelligently all available information into valuable knowledge. Diabetes mellitus (DM) is defined as a group of metabolic disorders exerting significant pressure on human health worldwide. Extensive research in all aspects of diabetes (diagnosis, etiopathophysiology, therapy, etc.) has led to the generation of huge amounts of data. The aim of the present study is to conduct a systematic review of the applications of machine learning, data mining techniques and tools in the field of diabetes research with respect to a) Prediction and Diagnosis, b) Diabetic Complications, c) Genetic Background and Environment, and e) Health Care and Management with the first category appearing to be the most popular. A wide range of machine learning algorithms were employed. In general, 85% of those used were characterized by supervised learning approaches and 15% by unsupervised ones, and more specifically, association rules. Support vector machines (SVM) arise as the most successful and widely used algorithm. Concerning the type of data, clinical datasets were mainly used. The title applications in the selected articles project the usefulness of extracting valuable knowledge leading to new hypotheses targeting deeper understanding and further investigation in DM.\n",
      "\n",
      "Title: Gaussian Processes for Machine Learning (GPML) Toolbox\n",
      "Abstract: The GPML toolbox provides a wide range of functionality for Gaussian process (GP) inference and prediction. GPs are specified by mean and covariance functions; we offer a library of simple mean and covariance functions and mechanisms to compose more complex ones. Several likelihood functions are supported including Gaussian and heavy-tailed for regression as well as others suitable for classification. Finally, a range of inference methods is provided, including exact and variational inference, Expectation Propagation, and Laplace's method dealing with non-Gaussian likelihoods and FITC for dealing with large regression tasks.\n",
      "\n",
      "URLs: ['https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf', 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable', 'https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf', 'https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a', 'https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979', 'https://link.aps.org/accepted/10.1103/PhysRevLett.108.058301', 'https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512', 'https://aclanthology.org/D14-1179.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025421/c000700_9780262301183.pdf', 'https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87', 'https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025438/c002700_9780262301183.pdf', 'https://aip.scitation.org/doi/pdf/10.1063/1.4966192', 'https://academic.oup.com/bib/article-pdf/7/1/86/23992771/bbk007.pdf', 'https://www.nature.com/articles/s41524-017-0056-5.pdf', 'https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf', 'https://www.nature.com/articles/nmeth.4642.pdf', 'https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444', 'https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf', 'https://www.nature.com/articles/s41524-019-0221-0.pdf', 'https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true', 'https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf', 'https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf', 'https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030', 'https://dl.acm.org/doi/pdf/10.1145/319382.319388', 'https://dl.acm.org/doi/pdf/10.1145/212094.212114', 'https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847', 'https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true', 'https://inria.hal.science/hal-00856511/document']\n"
     ]
    }
   ],
   "source": [
    "# OpenAlex: Finding Papers\n",
    "# Let's say we have a set or an array of keywords.\n",
    "# We can use OpenAlex to find a large number of papers\n",
    "# that, in some way, match those keywords. This is an\n",
    "# example of how it could work. Furthermore, Veronica\n",
    "# mentioned how there's other characteristics that you\n",
    "# may be looking for, like how far back you want to go\n",
    "# in searching for papers.\n",
    "from pyalex import Works\n",
    "\n",
    "# Later, I'll use these URLs to try out the PDF to text\n",
    "# tools. If there's any.\n",
    "urls = []\n",
    "number_urls = 0\n",
    "\n",
    "keywords = [\"Machine Learning\"]\n",
    "\n",
    "pager = Works().search_filter(title=keywords[0]).paginate(per_page=200)\n",
    "number_works = 0\n",
    "\n",
    "for page in pager:\n",
    "    for work in page:        \n",
    "        print(f\"Title: {work['title']}\")\n",
    "        # You'll see that some PDFs do include URLs,\n",
    "        # while some do not. Maybe in these cases, we could\n",
    "        # instead use the abstract that OpenAlex provides.\n",
    "        # However, there are still chances that the abstract\n",
    "        # is also unavailable. Also, there was an instance of\n",
    "        # an incorrect abstract, so that's also something to \n",
    "        # consider.\n",
    "        print(f\"Abstract: {work['abstract']}\")\n",
    "        if work[\"primary_location\"]:\n",
    "            url = work[\"primary_location\"][\"pdf_url\"]\n",
    "            if url:\n",
    "                print(url)\n",
    "                urls.append(url)\n",
    "                number_urls += 1 \n",
    "        number_works += 1\n",
    "        print()\n",
    "    if number_urls >= 10 or number_works >= 50:\n",
    "        break\n",
    "\n",
    "print(f\"URLs: {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "88402eeb-79a5-446b-912f-5e5b94c33b34",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "URLs: ['https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf', 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable', 'https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf', 'https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a', 'https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979', 'https://link.aps.org/accepted/10.1103/PhysRevLett.108.058301', 'https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512', 'https://aclanthology.org/D14-1179.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025421/c000700_9780262301183.pdf', 'https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87', 'https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025438/c002700_9780262301183.pdf', 'https://aip.scitation.org/doi/pdf/10.1063/1.4966192', 'https://academic.oup.com/bib/article-pdf/7/1/86/23992771/bbk007.pdf', 'https://www.nature.com/articles/s41524-017-0056-5.pdf', 'https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf', 'https://www.nature.com/articles/nmeth.4642.pdf', 'https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444', 'https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf', 'https://www.nature.com/articles/s41524-019-0221-0.pdf', 'https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true', 'https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf', 'https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf', 'https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030', 'https://dl.acm.org/doi/pdf/10.1145/319382.319388', 'https://dl.acm.org/doi/pdf/10.1145/212094.212114', 'https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847', 'https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true', 'https://inria.hal.science/hal-00856511/document']\n",
      "URLs: ['https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf', 'https://journals.plos.org/plosone/article/file?id=10.1371/journal.pone.0169748&type=printable', 'https://www.frontiersin.org/articles/10.3389/fninf.2014.00014/pdf', 'https://pubs.rsc.org/en/content/articlepdf/2018/sc/c7sc02664a', 'https://www.mdpi.com/1424-8220/18/8/2674/pdf?version=1534247979', 'https://link.aps.org/accepted/10.1103/PhysRevLett.108.058301', 'https://journals.sagepub.com/doi/pdf/10.1177/2053951715622512', 'https://aclanthology.org/D14-1179.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025421/c000700_9780262301183.pdf', 'https://www.aeaweb.org/articles/pdf/doi/10.1257/jep.31.2.87', 'https://link.springer.com/content/pdf/10.1007/s12525-021-00475-2.pdf', 'https://direct.mit.edu/books/oa-monograph/chapter-pdf/2025438/c002700_9780262301183.pdf', 'https://aip.scitation.org/doi/pdf/10.1063/1.4966192', 'https://academic.oup.com/bib/article-pdf/7/1/86/23992771/bbk007.pdf', 'https://www.nature.com/articles/s41524-017-0056-5.pdf', 'https://link.springer.com/content/pdf/10.1007/s10994-010-5188-5.pdf', 'https://www.nature.com/articles/nmeth.4642.pdf', 'https://www.mdpi.com/1099-4300/23/1/18/pdf?version=1609160444', 'https://academic.oup.com/ectj/article-pdf/21/1/C1/27684918/ectj00c1.pdf', 'https://www.nature.com/articles/s41524-019-0221-0.pdf', 'https://www.tandfonline.com/doi/pdf/10.1080/21693277.2016.1192517?needAccess=true', 'https://direct.mit.edu/coli/article-pdf/27/4/521/1797672/089120101753342653.pdf', 'https://www.science.org/cms/asset/e0345a34-e2a8-46ff-81d8-e68e47e223c6/pap.pdf', 'https://journals.sagepub.com/doi/pdf/10.1177/117693510600200030', 'https://dl.acm.org/doi/pdf/10.1145/319382.319388', 'https://dl.acm.org/doi/pdf/10.1145/212094.212114', 'https://www.mdpi.com/2079-9292/8/8/832/pdf?version=1564134847', 'https://www.tandfonline.com/doi/pdf/10.1080/01431161.2018.1433343?needAccess=true', 'https://inria.hal.science/hal-00856511/document']\n"
     ]
    }
   ],
   "source": [
    "# URLs\n",
    "# As you may be able to see, the number of URLs provided are not plenty.\n",
    "# I'm not sure if this is important, but what if good papers are missed out on\n",
    "# because they don't have a PDF listed? Also, it seems that OpenAlex offers\n",
    "# everything, so I'm not sure if these are research papers that one would want\n",
    "# to use. Possibly a problem for a later day.\n",
    "# In case I can't find enough URLs, this serves to find any paper with an URL.\n",
    "# This is just for the \"testing\" later on.\n",
    "print(f\"URLs: {urls}\")\n",
    "if len(urls) < 10:\n",
    "    while len(urls) < 10:\n",
    "        work = Works().random()\n",
    "        while not work[\"primary_location\"] or not work[\"primary_location\"][\"pdf_url\"]:\n",
    "            work = Works().random()\n",
    "        urls.append(work[\"primary_location\"][\"pdf_url\"])\n",
    "print(f\"URLs: {urls}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "3d0f2ec1-fab0-4cd4-85a8-48b8758d5922",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text\n",
    "# It's not logical to physically download a PDF\n",
    "# to reference it in the code. Especially if you're\n",
    "# going through thousands of PDFs. So, we can download\n",
    "# the bytes of an URL that links to said PDF to get the\n",
    "# PDF file. This code contains the simple process of\n",
    "# downloading the bytes of the PDF.\n",
    "import io\n",
    "import requests\n",
    "\n",
    "def pdf_bytes(url):\n",
    "    r = requests.get(url)\n",
    "    f = io.BytesIO(r.content)\n",
    "    return f"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "44eb6101-24d9-444a-a7e4-9565f778ffa3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Machine Learnin g 3: 95-99, 1988', '© 1988 Kluwe r Academi c Publisher s - Manufacture d in The Netherland s', 'GUEST EDITORIA L', 'Genetic Algorithm s and Machin e Learnin g', 'Metaphors for learnin g', 'There i s no a  priori reason wh y machine learnin g must borro w fro m nature .', 'A fiel d coul d exist , complet e wit h well-define d algorithms , dat a structures ,', 'and theorie s o f learning , withou t onc e referrin g t o organisms , cognitiv e o r', 'genetic structures , an d psychologica l or evolutionar y theories . Ye t at th e en d', 'of th e day , wit h th e positio n paper s written , th e computer s plugge d in , an d', 'the program s debugged , a  learnin g edific e devoi d of natura l metapho r woul d', 'lack something . I t woul d ignore th e fac t tha t al l these creations hav e become', 'possible onl y afte r thre e billio n years o f evolutio n o n thi s planet . I t woul d', 'miss th e poin t tha t th e ver y idea s o f adaptatio n an d learnin g ar e concepts', 'invented b y the mos t recen t representative s o f the species Homo  sapiens  fro m', 'the carefu l observatio n o f themselves an d lif e aroun d them . I t woul d miss th e', 'point tha t natura l example s of learning and  adaptatio n are treasur e trove s of', 'robust procedure s an d structures .', \"Fortunately , th e fiel d o f machine learnin g doe s rel y upo n nature' s bount y\", 'for bot h inspiratio n an d mechanism . Man y machin e learnin g system s no w', 'borrow heavil y fro m curren t thinkin g i n cognitiv e science, an d rekindle d in -', 'terest i n neural network s and connectionis m is evidence of serious mechanisti c', 'and philosophical current s runnin g through th e field. Anothe r area where nat -', 'ural exampl e ha s bee n tappe d i s i n wor k o n genetic  algorithms  (GAs ) an d', 'genetics-based machin e learning . Roote d i n th e earl y cybernetic s movemen t', '(Holland , 1962), progress ha s bee n mad e i n bot h theor y (Holland , 1975; Hol-', 'land, Holyoak , Nisbett , &  Thagard , 1986) an d applicatio n (Goldberg , 1989;', 'Grefenstette , 1985, 1987) t o th e poin t wher e genetics-based system s ar e find-', 'ing thei r way into everyday commercial use (Davis & Coombs, 1987; Fourman ,', '1985).', 'Genetic algorithms and classifier systems', 'This special double issue of Machine Learning  is devoted to paper s concern -', 'ing geneti c algorithm s an d genetics-base d learnin g systems . Simpl y stated ,', 'genetic algorithm s ar e probabilisti c searc h procedure s designe d t o wor k o n', 'large spaces involvin g states tha t ca n be represente d b y strings. Thes e meth -', 'ods ar e inherentl y parallel , usin g a  distribute d se t of samples fro m th e space', '(a populatio n o f strings ) t o generat e a  ne w se t o f samples. The y als o ex -', 'hibit a  mor e subtl e implicit  parallelism.  Roughly , i n processing a  populatio n', 'of m strings , a  geneti c algorith m implicitl y evaluates substantiall y mor e tha n', 'm3 componen t substrings . I t the n automaticall y biase s futur e population s t o', 'exploit th e abov e average component s a s building  blocks  fro m whic h t o con -', '']\n",
      "Machine Learnin g 3: 95-99, 1988 © 1988 Kluwe r Academi c Publisher s - Manufacture d in The Netherland s GUEST EDITORIA L Genetic Algorithm s and Machin e Learnin g Metaphors for learnin g There i s no a  priori reason wh y machine learnin g must borro w fro m nature . A fiel d coul d exist , complet e wit h well-define d algorithms , dat a structures , and theorie s o f learning , withou t onc e referrin g t o organisms , cognitiv e o r genetic structures , an d psychologica l or evolutionar y theories . Ye t at th e en d of th e day , wit h th e positio n paper s written , th e computer s plugge d in , an d the program s debugged , a  learnin g edific e devoi d of natura l metapho r woul d lack something . I t woul d ignore th e fac t tha t al l these creations hav e become possible onl y afte r thre e billio n years o f evolutio n o n thi s planet . I t woul d miss th e poin t tha t th e ver y idea s o f adaptatio n an d learnin g ar e concepts invented b y the mos t recen t representative s o f the species Homo  sapiens  fro m the carefu l observatio n o f themselves an d lif e aroun d them . I t woul d miss th e point tha t natura l example s of learning and  adaptatio n are treasur e trove s of robust procedure s an d structures . Fortunately , th e fiel d o f machine learnin g doe s rel y upo n nature' s bount y for bot h inspiratio n an d mechanism . Man y machin e learnin g system s no w borrow heavil y fro m curren t thinkin g i n cognitiv e science, an d rekindle d in - terest i n neural network s and connectionis m is evidence of serious mechanisti c and philosophical current s runnin g through th e field. Anothe r area where nat - ural exampl e ha s bee n tappe d i s i n wor k o n genetic  algorithms  (GAs ) an d genetics-based machin e learning . Roote d i n th e earl y cybernetic s movemen t (Holland , 1962), progress ha s bee n mad e i n bot h theor y (Holland , 1975; Hol- land, Holyoak , Nisbett , &  Thagard , 1986) an d applicatio n (Goldberg , 1989; Grefenstette , 1985, 1987) t o th e poin t wher e genetics-based system s ar e find- ing thei r way into everyday commercial use (Davis & Coombs, 1987; Fourman , 1985). Genetic algorithms and classifier systems This special double issue of Machine Learning  is devoted to paper s concern - ing geneti c algorithm s an d genetics-base d learnin g systems . Simpl y stated , genetic algorithm s ar e probabilisti c searc h procedure s designe d t o wor k o n large spaces involvin g states tha t ca n be represente d b y strings. Thes e meth - ods ar e inherentl y parallel , usin g a  distribute d se t of samples fro m th e space (a populatio n o f strings ) t o generat e a  ne w se t o f samples. The y als o ex - hibit a  mor e subtl e implicit  parallelism.  Roughly , i n processing a  populatio n of m strings , a  geneti c algorith m implicitl y evaluates substantiall y mor e tha n m3 componen t substrings . I t the n automaticall y biase s futur e population s t o exploit th e abov e average component s a s building  blocks  fro m whic h t o con - \n"
     ]
    }
   ],
   "source": [
    "# PDF to Text: PyPDF\n",
    "# This doesn't seem to be useless, but it throws\n",
    "# exceptions easily. It's understandable why an\n",
    "# error would be thrown if the PDF cannot be parsed.\n",
    "# However, I wonder if this would cause problems with\n",
    "# the number of issues a PDF could have for whatever\n",
    "# reason.\n",
    "# This also works, but the text is not impressive.\n",
    "from pypdf import PdfReader\n",
    "\n",
    "def pdf_to_text_pypdf(url):\n",
    "    f = pdf_bytes(url)\n",
    "    reader = PdfReader(f)\n",
    "    contents = reader.get_page(0).extract_text().split('\\n')\n",
    "    print(contents)\n",
    "    print(\" \".join(contents))\n",
    "\n",
    "pdf_to_text_pypdf(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "3fccde31-c0b5-4611-af6f-3a27ad16e3b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-02 06:25:19,731 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "WARNING:tika.tika:Failed to see startup log message; retrying...\n",
      "2025-04-02 06:25:24,743 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "WARNING:tika.tika:Failed to see startup log message; retrying...\n",
      "2025-04-02 06:25:29,751 [MainThread  ] [WARNI]  Failed to see startup log message; retrying...\n",
      "WARNING:tika.tika:Failed to see startup log message; retrying...\n",
      "2025-04-02 06:25:34,755 [MainThread  ] [ERROR]  Tika startup log message not received after 3 tries.\n",
      "ERROR:tika.tika:Tika startup log message not received after 3 tries.\n",
      "2025-04-02 06:25:34,761 [MainThread  ] [ERROR]  Failed to receive startup confirmation from startServer.\n",
      "ERROR:tika.tika:Failed to receive startup confirmation from startServer.\n"
     ]
    },
    {
     "ename": "RuntimeError",
     "evalue": "Unable to start Tika server.",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[21], line 22\u001b[0m\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     21\u001b[0m \u001b[38;5;66;03m# pdf_to_text_tika(\"https://nnjournal.net/article/download/75\")\u001b[39;00m\n\u001b[1;32m---> 22\u001b[0m \u001b[43mpdf_to_text_tika\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mhttps://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\n",
      "Cell \u001b[1;32mIn[21], line 17\u001b[0m, in \u001b[0;36mpdf_to_text_tika\u001b[1;34m(url)\u001b[0m\n\u001b[0;32m     15\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mpdf_to_text_tika\u001b[39m(url):\n\u001b[0;32m     16\u001b[0m     f \u001b[38;5;241m=\u001b[39m pdf_bytes(url)\n\u001b[1;32m---> 17\u001b[0m     parsed \u001b[38;5;241m=\u001b[39m \u001b[43mparser\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfrom_buffer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mf\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     18\u001b[0m     \u001b[38;5;28mprint\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmetadata\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n\u001b[0;32m     19\u001b[0m     \u001b[38;5;28mprint\u001b[39m(parsed[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mcontent\u001b[39m\u001b[38;5;124m\"\u001b[39m])\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\3.10\\lib\\site-packages\\tika\\parser.py:65\u001b[0m, in \u001b[0;36mfrom_buffer\u001b[1;34m(string, serverEndpoint, xmlContent, headers, config_path, requestOptions, raw_response)\u001b[0m\n\u001b[0;32m     62\u001b[0m headers\u001b[38;5;241m.\u001b[39mupdate({\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mAccept\u001b[39m\u001b[38;5;124m'\u001b[39m: \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mapplication/json\u001b[39m\u001b[38;5;124m'\u001b[39m})\n\u001b[0;32m     64\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m xmlContent:\n\u001b[1;32m---> 65\u001b[0m     status, response \u001b[38;5;241m=\u001b[39m \u001b[43mcallServer\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mput\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverEndpoint\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43m/rmeta/text\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstring\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mheaders\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mFalse\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mconfig_path\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mrequestOptions\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mrequestOptions\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m     66\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m     67\u001b[0m     status, response \u001b[38;5;241m=\u001b[39m callServer(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mput\u001b[39m\u001b[38;5;124m'\u001b[39m, serverEndpoint, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124m/rmeta/xml\u001b[39m\u001b[38;5;124m'\u001b[39m, string, headers, \u001b[38;5;28;01mFalse\u001b[39;00m, config_path\u001b[38;5;241m=\u001b[39mconfig_path, requestOptions\u001b[38;5;241m=\u001b[39mrequestOptions)\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\3.10\\lib\\site-packages\\tika\\tika.py:532\u001b[0m, in \u001b[0;36mcallServer\u001b[1;34m(verb, serverEndpoint, service, data, headers, verbose, tikaServerJar, httpVerbs, classpath, rawResponse, config_path, requestOptions)\u001b[0m\n\u001b[0;32m    530\u001b[0m \u001b[38;5;28;01mglobal\u001b[39;00m TikaClientOnly\n\u001b[0;32m    531\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m TikaClientOnly:\n\u001b[1;32m--> 532\u001b[0m     serverEndpoint \u001b[38;5;241m=\u001b[39m \u001b[43mcheckTikaServer\u001b[49m\u001b[43m(\u001b[49m\u001b[43mscheme\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mserverHost\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mport\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtikaServerJar\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasspath\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig_path\u001b[49m\u001b[43m)\u001b[49m\n\u001b[0;32m    534\u001b[0m serviceUrl  \u001b[38;5;241m=\u001b[39m serverEndpoint \u001b[38;5;241m+\u001b[39m service\n\u001b[0;32m    535\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m verb \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m httpVerbs:\n",
      "File \u001b[1;32m~\\anaconda3\\envs\\3.10\\lib\\site-packages\\tika\\tika.py:602\u001b[0m, in \u001b[0;36mcheckTikaServer\u001b[1;34m(scheme, serverHost, port, tikaServerJar, classpath, config_path)\u001b[0m\n\u001b[0;32m    600\u001b[0m         \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m status:\n\u001b[0;32m    601\u001b[0m             log\u001b[38;5;241m.\u001b[39merror(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mFailed to receive startup confirmation from startServer.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m--> 602\u001b[0m             \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mRuntimeError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mUnable to start Tika server.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[0;32m    603\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m serverEndpoint\n",
      "\u001b[1;31mRuntimeError\u001b[0m: Unable to start Tika server."
     ]
    }
   ],
   "source": [
    "# PDF to Text: Tika\n",
    "# This has been running for at least\n",
    "# 13 minutes, possibly more. I can't tell\n",
    "# if it's stuck in an infinite loop, or if the\n",
    "# PDF is that long. It could be that the link \n",
    "# to the PDF is a download. I'm not sure if this \n",
    "# is affecting the parser. I'm going to stop it\n",
    "# and try a different URL. Now that I'm using a\n",
    "# PDF that works, I'm seeing that the server can't\n",
    "# be started. Honestly, with the performance of the\n",
    "# parser below, I don't think I'm going to try to\n",
    "# fix it.\n",
    "import tika\n",
    "from tika import parser\n",
    "\n",
    "def pdf_to_text_tika(url):\n",
    "    f = pdf_bytes(url)\n",
    "    parsed = parser.from_buffer(f)\n",
    "    print(parsed[\"metadata\"])\n",
    "    print(parsed[\"content\"])\n",
    "\n",
    "# pdf_to_text_tika(\"https://nnjournal.net/article/download/75\")\n",
    "pdf_to_text_tika(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "42309961-1979-4739-a1e0-a13442760258",
   "metadata": {},
   "outputs": [],
   "source": [
    "# PDF to Text: Textract\n",
    "# I've seen this used by other packages I've installed.\n",
    "# The documentation does not look that helpful.\n",
    "# Also, I don't think they allow for file objects.\n",
    "# Onwards!\n",
    "# I think the prior parser was not working because the URL\n",
    "# was a download link and not the URL of a PDF."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "79ab83cc-acea-4a1c-a1c7-05eb17ac836b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<_io.BytesIO object at 0x00000251999FC900>\n",
      "Machine Learning 3: 95-99, 1988\n",
      "© 1988 Kluwer Academic Publishers - Manufactured in The Netherlands\n",
      "GUEST EDITORIAL\n",
      "Genetic Algorithms and Machine Learning\n",
      "Metaphors for learning\n",
      "There is no a priori reason why machine learning must borrow from nature.\n",
      "A field could exist, complete with well-defined algorithms, data structures,\n",
      "and theories of learning, without once referring to organisms, cognitive or\n",
      "genetic structures, and psychological or evolutionary theories. Yet at the end\n",
      "of the day, with the position papers written, the computers plugged in, and\n",
      "the programs debugged, a learning edifice devoid of natural metaphor would\n",
      "lack something. It would ignore the fact that all these creations have become\n",
      "possible only after three billion years of evolution on this planet. It would\n",
      "miss the point that the very ideas of adaptation and learning are concepts\n",
      "invented by the most recent representatives of the species Homo sapiens from\n",
      "the careful observation of themselves and life around them. It would miss the\n",
      "point that natural examples of learning and adaptation are treasure troves of\n",
      "robust procedures and structures.\n",
      "Fortunately, the field of machine learning does rely upon nature's bounty\n",
      "for both inspiration and mechanism. Many machine learning systems now\n",
      "borrow heavily from current thinking in cognitive science, and rekindled in-\n",
      "terest in neural networks and connectionism is evidence of serious mechanistic\n",
      "and philosophical currents running through the field. Another area where nat-\n",
      "ural example has been tapped is in work on genetic algorithms (GAs) and\n",
      "genetics-based machine learning. Rooted in the early cybernetics movement\n",
      "(Holland, 1962), progress has been made in both theory (Holland, 1975; Hol-\n",
      "land, Holyoak, Nisbett, & Thagard, 1986) and application (Goldberg, 1989;\n",
      "Grefenstette, 1985, 1987) to the point where genetics-based systems are find-\n",
      "ing their way into everyday commercial use (Davis & Coombs, 1987; Fourman,\n",
      "1985).\n",
      "Genetic algorithms and classifier systems\n",
      "This special double issue of Machine Learning is devoted to papers concern-\n",
      "ing genetic algorithms and genetics-based learning systems. Simply stated,\n",
      "genetic algorithms are probabilistic search procedures designed to work on\n",
      "large spaces involving states that can be represented by strings. These meth-\n",
      "ods are inherently parallel, using a distributed set of samples from the space\n",
      "(a population of strings) to generate a new set of samples. They also ex-\n",
      "hibit a more subtle implicit parallelism. Roughly, in processing a population\n",
      "of m strings, a genetic algorithm implicitly evaluates substantially more than\n",
      "m3 component substrings. It then automatically biases future populations to\n",
      "exploit the above average components as building blocks from which to con-\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# PDF to Text: PyMuPDF\n",
    "# This looks like it may be good. The documentation\n",
    "# looks great. I think PyMuPDF will be my saving grace\n",
    "# for this portion of the project. I will be choosing\n",
    "# PyMuPDF.\n",
    "import pymupdf\n",
    "\n",
    "def pdf_to_text_pymupdf(url):\n",
    "    f = pdf_bytes(url)\n",
    "    print(f)\n",
    "    doc = pymupdf.open(stream=f)\n",
    "    print(doc[0].get_text())\n",
    "\n",
    "pdf_to_text_pymupdf(\"https://link.springer.com/content/pdf/10.1023/A:1022602019183.pdf\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "dc9622ce-b4e3-4db8-b1e5-580120750f5b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
