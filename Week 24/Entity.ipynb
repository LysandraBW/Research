{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f05c4b1-2271-4c10-bb03-4c9b7310cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    # Labels\n",
    "    LIST = 1\n",
    "    ITEM = 2\n",
    "    QUOTE = 3\n",
    "    BREAK = 4\n",
    "    END = 5\n",
    "    AND_OR_END = 6\n",
    "    COLON = 7\n",
    "    COLON_BREAK = 8\n",
    "    I_CLAUSE = 9\n",
    "    D_CLAUSE = 10\n",
    "    P_PHRASE = 11\n",
    "    BRACKETS = 12\n",
    "    FRAGMENT = 13\n",
    "    CONJ = 14\n",
    "\n",
    "    def __init__(self, doc, label=None, l=None, r=None, children=None):\n",
    "        self.doc = doc\n",
    "        self.label = [] if not label else [label] if not isinstance(label, list) else label\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "        self.children = children or []\n",
    "\n",
    "    def label_(self):\n",
    "        labels = []\n",
    "        if Entity.LIST in self.label:\n",
    "            labels.append(\"List\")\n",
    "        if Entity.ITEM in self.label:\n",
    "            labels.append(\"Item\")\n",
    "        if Entity.QUOTE in self.label:\n",
    "            labels.append(\"Quote\")\n",
    "        if Entity.BREAK in self.label:\n",
    "            labels.append(\"Break\")\n",
    "        if Entity.END in self.label:\n",
    "            labels.append(\"End\")\n",
    "        if Entity.AND_OR_END in self.label:\n",
    "            labels.append(\"And or End\")\n",
    "        if Entity.COLON in self.label:\n",
    "            labels.append(\"Colon\")\n",
    "        if Entity.COLON_BREAK in self.label:\n",
    "            labels.append(\"Colon Break\")\n",
    "        if Entity.I_CLAUSE in self.label:\n",
    "            labels.append(\"Independent Clause\")\n",
    "        if Entity.D_CLAUSE in self.label:\n",
    "            labels.append(\"Dependent Clause\")\n",
    "        if Entity.P_PHRASE in self.label:\n",
    "            labels.append(\"Prepositional Phrase\")\n",
    "        if Entity.BRACKETS in self.label:\n",
    "            labels.append(\"Brackets\")\n",
    "        if Entity.FRAGMENT in self.label:\n",
    "            labels.append(\"Fragment\")\n",
    "        if Entity.CONJ in self.label:\n",
    "            labels.append(\"Conjunction\")\n",
    "        return \", \".join(labels) or \"None\"\n",
    "        \n",
    "    def size(self):\n",
    "        return self.r - self.l + 1\n",
    "\n",
    "    def span(self):\n",
    "        return self.doc[self.l:self.r+1]\n",
    "\n",
    "    def lower(self):\n",
    "        return self.doc[self.l:self.r+1].text.lower()\n",
    "\n",
    "    def start(self):\n",
    "        return self.doc[self.l]\n",
    "\n",
    "    def end(self):\n",
    "        return self.doc[self.r]\n",
    "\n",
    "    def label_has(self, labels):\n",
    "        return set(self.label).intersection(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens(*, ent=None, ents=None):\n",
    "        if ents:\n",
    "            tokens = flatten([list(ent.span()) for ent in ents])\n",
    "            tokens = sorted(tokens, key=lambda token: token.i)\n",
    "            return tokens\n",
    "        if ent:\n",
    "            tokens = list(ent.span())\n",
    "            return tokens\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def is_conjunction(token):\n",
    "        return token.lower_ in [\"and\", \"or\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def same_speech(speech_1, speech_2):\n",
    "        nouns = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "        if speech_1 in nouns and speech_2 in nouns:\n",
    "            return True\n",
    "        return speech_1 == speech_2\n",
    "\n",
    "    @staticmethod\n",
    "    def same_speech_list(speech_1, speech_2_list):\n",
    "        for speech_2 in speech_2_list:\n",
    "            if Entity.same_speech(speech_1, speech_2):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.span().text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04897364-b98a-4271-9ee0-f200c7b02c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quotes:\n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = entities\n",
    "\n",
    "    def is_quote(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower() == \"\\\"\"\n",
    "    \n",
    "    def identify(self):\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            if not self.is_quote(i):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            self.entities[i].label.append(Entity.QUOTE)\n",
    "            \n",
    "            while not self.is_quote(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            if self.is_quote(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30f332f-9503-4c2a-a17c-593e2ecc0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brackets:\n",
    "    MATCHES = {\n",
    "        \"[\": \"]\", \n",
    "        \"(\": \")\",\n",
    "        \"—\": \"—\",\n",
    "    }\n",
    "\n",
    "    OPENING = MATCHES.keys()\n",
    "    CLOSING = MATCHES.values()\n",
    "\n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.stack = []\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def is_opening(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower()[0] in Brackets.OPENING\n",
    "\n",
    "    def is_closing(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower()[0] in Brackets.CLOSING\n",
    "\n",
    "    def closes(self, i):\n",
    "        opener = self.entities[self.stack[-1]].lower()[0]\n",
    "        closer = self.entities[i].lower()[0]\n",
    "        return Brackets.MATCHES[opener] == closer\n",
    "    \n",
    "    def identify(self):\n",
    "        self.stack = []\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(self.entities):\n",
    "            # Closing\n",
    "            if self.is_closing(i) and self.stack:\n",
    "                j = None if not self.closes(i) else self.stack.pop()\n",
    "                \n",
    "                if not self.stack and j != None:\n",
    "                    self.entities[j].r = self.entities[i].r\n",
    "                    self.entities.pop(i)\n",
    "                    continue\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "            # Opening\n",
    "            elif self.is_opening(i):\n",
    "                if not self.stack:\n",
    "                    self.entities[i].label.append(Entity.BRACKETS)\n",
    "                self.stack.append(i)\n",
    "                i += 1\n",
    "\n",
    "            # Consuming\n",
    "            elif self.stack:\n",
    "                # If you're at the end of the possible entities,\n",
    "                # and the list is unclosed, we must stop.\n",
    "                if i + 1 >= len(self.entities):\n",
    "                    break\n",
    "                self.entities[self.stack[0]].r = self.entities[i+1].r\n",
    "                self.entities.pop(i)\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1224ba1-75fe-4fc5-a1f9-e021b214a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separators:\n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def is_break(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return False\n",
    "        \n",
    "        if self.entities[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "\n",
    "        # Breaks cannot have a following conjunction.\n",
    "        # Else, it would be an end and not a break.\n",
    "        return not bool(\n",
    "            i + 1 < len(self.entities) and \n",
    "            self.entities[i+1].size() == 1 and \n",
    "            self.entities[i+1].span()[0].pos_ in [\"CCONJ\"]\n",
    "        )\n",
    "\n",
    "    def is_end(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return False\n",
    "        \n",
    "        if self.entities[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "        \n",
    "        return not self.is_break(i)\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.entities):\n",
    "            # Break\n",
    "            if self.is_break(i):\n",
    "                self.entities[i].label.append(Entity.BREAK)\n",
    "                i += 1\n",
    "\n",
    "            # End\n",
    "            elif self.is_end(i):\n",
    "                conj = self.entities[i+1].start().lower_\n",
    "\n",
    "                if conj in [\"and\", \"or\"]:\n",
    "                    self.entities[i].label.append(Entity.AND_OR_END)\n",
    "                else:\n",
    "                    self.entities[i].label.append(Entity.END)\n",
    "                \n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            elif self.entities[i].start().pos_ == \"CCONJ\":\n",
    "                self.entities[i].label.append(Entity.CONJ)\n",
    "                i += 1\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851a2216-ed77-4486-ae0b-06e2b55ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colons:\n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.entities):\n",
    "            if self.entities[i].lower()[-1] != \":\":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if not self.entities[i].label:\n",
    "                self.entities[i].label.append(Entity.COLON_BREAK)\n",
    "\n",
    "            if i + 1 < len(self.entities):\n",
    "                self.entities[i+1].label.append(Entity.COLON)\n",
    "                self.entities[i+1].r = self.entities[-1].r\n",
    "                self.entities = self.entities[:i+2]\n",
    "            \n",
    "            break\n",
    "\n",
    "        return self.entities        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41e0a309-2be6-48be-8726-f8bfbece633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Independent_Clauses:\n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = [*entities]\n",
    "        self.allowed = []\n",
    "\n",
    "    def end(self, i):    \n",
    "        if i >= len(self.entities):\n",
    "            return True\n",
    "\n",
    "        if self.entities[i].label_has(self.allowed):\n",
    "            return True\n",
    "        \n",
    "        # Here, we check if the entity after\n",
    "        # the supposed end is a clause. If it\n",
    "        # is, then we can end at the current entity.\n",
    "        return bool(\n",
    "            i + 1 < len(self.entities) and \n",
    "            self.entities[i+1].label_has([\n",
    "                Entity.COLON,\n",
    "                Entity.COLON_BREAK,\n",
    "                Entity.I_CLAUSE,\n",
    "                Entity.D_CLAUSE,\n",
    "                Entity.P_PHRASE\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def identify(self, allowed):\n",
    "        self.allowed = allowed\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            if not self.entities[i].label_has(self.allowed):\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Skip Clause\n",
    "            if self.entities[i].label_has([\n",
    "                Entity.I_CLAUSE, \n",
    "                Entity.D_CLAUSE, \n",
    "                Entity.P_PHRASE\n",
    "            ]):\n",
    "                i = entities[i].r + 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.entities[i].label.append(Entity.I_CLAUSE)\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.entities[i+1].label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                    self.entities[i].children.append(self.entities[i+1])\n",
    "                    \n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9e6dce7b-963a-475c-9c40-d97f9bd15b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependent_Clauses:\n",
    "    RELATIVE_NOUNS = [\n",
    "        \"who\",\n",
    "        \"whom\",\n",
    "        \"which\",\n",
    "        \"what\",\n",
    "        \"that\",\n",
    "        \"whose\",\n",
    "        \"whomever\",\n",
    "        \"whoever\",\n",
    "        \"whichever\",\n",
    "        \"whatever\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = entities\n",
    "        self.separator = None\n",
    "\n",
    "    def end(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return True\n",
    "\n",
    "        # Here, we check if the entity after\n",
    "        # is a clause. As we don't combine two\n",
    "        # clauses, we must end here if that is\n",
    "        # the case.\n",
    "        if bool(\n",
    "            i + 1 < len(self.entities) and \n",
    "            self.entities[i+1].label_has([\n",
    "                Entity.COLON, \n",
    "                Entity.COLON_BREAK,\n",
    "                Entity.I_CLAUSE,\n",
    "                Entity.D_CLAUSE,\n",
    "                Entity.P_PHRASE\n",
    "            ])\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return bool(\n",
    "            self.entities[i].lower()[0] == self.separator or\n",
    "            self.entities[i].lower() in Dependent_Clauses.RELATIVE_NOUNS or\n",
    "            self.entities[i].start().pos_ in [\"SCONJ\"]\n",
    "        )\n",
    "\n",
    "    def identify(self, separator):\n",
    "        self.separator = separator\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            # Skip\n",
    "            if self.entities[i].label_has([\n",
    "                Entity.COLON,\n",
    "                Entity.COLON_BREAK,\n",
    "                Entity.I_CLAUSE, \n",
    "                Entity.D_CLAUSE, \n",
    "                Entity.P_PHRASE\n",
    "            ]):\n",
    "                i = self.entities[i].r + 1\n",
    "                continue\n",
    "\n",
    "            # Indicators of Dependent Clause\n",
    "            rel = self.entities[i].lower() in Dependent_Clauses.RELATIVE_NOUNS\n",
    "            sub = self.entities[i].start().pos_ == \"SCONJ\"\n",
    "            \n",
    "            if not sub and not rel:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.entities[i].label.append(Entity.D_CLAUSE)\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.entities[i+1].label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                    self.entities[i].children.append(self.entities[i+1])\n",
    "                \n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "48b069be-4406-49fd-bcda-f03cb0944042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepositional_Phrases:\n",
    "    \n",
    "    def __init__(self, main, entities):\n",
    "        self.main = main\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    # A prepositional phrase is typically ended by a noun.\n",
    "    # Therefore, when we run into a noun, we end the phrase.\n",
    "    # We must also check that it is the last of the first noun(s)\n",
    "    # we encounter.\n",
    "    def last_noun(self, i):\n",
    "        if bool(\n",
    "            # 1. End\n",
    "            i >= len(self.entities) or \n",
    "            \n",
    "            # 2. Noun\n",
    "            self.entities[i].start().pos_ not in [\n",
    "                \"NOUN\", \n",
    "                \"PROPN\", \n",
    "                \"PRON\"\n",
    "            ]\n",
    "        ):\n",
    "            return False\n",
    "        \n",
    "        return bool(\n",
    "            i + 1 > len(self.entities) - 1 or \n",
    "            (\n",
    "                self.entities[i+1].size() == 1 and \n",
    "                self.entities[i+1].start().pos_ not in [\n",
    "                    \"NOUN\", \n",
    "                    \"PROPN\", \n",
    "                    \"PRON\", \n",
    "                    \"PART\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def end(self, i):\n",
    "        return bool(\n",
    "            # 1. End of List\n",
    "            i + 1 >= len(self.entities) or\n",
    "            \n",
    "            # 2. Clause\n",
    "            self.entities[i+1].label_has([\n",
    "                Entity.COLON,\n",
    "                Entity.COLON_BREAK,\n",
    "                Entity.I_CLAUSE,\n",
    "                Entity.D_CLAUSE,\n",
    "                Entity.P_PHRASE\n",
    "            ]) or\n",
    "            \n",
    "            # 3. Noun\n",
    "            self.last_noun(i)\n",
    "        )\n",
    "\n",
    "    def identify(self):    \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            # Skip\n",
    "            if bool(\n",
    "                self.entities[i].size() != 1 or\n",
    "                self.entities[i].start().pos_ != \"ADP\"\n",
    "            ):\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.entities[i].label.append(Entity.P_PHRASE)\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.entities[i+1].label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                    self.entities[i].children.append(self.entities[i+1])\n",
    "                \n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            if self.last_noun(i+1):\n",
    "                self.entities[i].r = self.entities[i+1].r\n",
    "                self.entities.pop(i+1)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return self.entities   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65c4bbbe-94e6-49bd-a969-3323f0e891dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lists:\n",
    "    NOUNS = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "    \n",
    "    def __init__(self, main, entities, enclosures):\n",
    "        self.main = main\n",
    "        self.entities = [*entities]\n",
    "        self.separator = None\n",
    "        self.enclosures = enclosures\n",
    "\n",
    "    def is_stop(self, entity):\n",
    "        is_break = Entity.BREAK in entity.label and entity.lower()[0] == self.separator\n",
    "        is_clause = entity.label_has([\n",
    "            Entity.I_CLAUSE, \n",
    "            Entity.D_CLAUSE, \n",
    "            Entity.P_PHRASE,\n",
    "            Entity.COLON,\n",
    "            Entity.COLON_BREAK\n",
    "        ])\n",
    "        return is_break or is_clause\n",
    "\n",
    "    def find_lists(self, sep):\n",
    "        self.separator = sep\n",
    "        \n",
    "        lists = [\n",
    "            [\n",
    "                [None, None]\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(self.entities):\n",
    "            entity = self.entities[i]\n",
    "\n",
    "            opened = lists[-1][0] != [None, None]\n",
    "            remove_list = entity.label_has([Entity.COLON, Entity.COLON_BREAK])\n",
    "            close_list = entity.label_has([Entity.AND_OR_END]) and entity.lower()[0] == sep\n",
    "            close_item = entity.label_has([Entity.BREAK]) and entity.lower() == sep\n",
    "        \n",
    "            # Close List\n",
    "            if opened and close_list:\n",
    "                # Invalid List, Remove\n",
    "                if len(lists[-1]) < 2:\n",
    "                    lists[-1] = [[None, None]]\n",
    "                    i += 1\n",
    "                    continue\n",
    "                    \n",
    "                # Find the L Index of Last Item\n",
    "                last_item_l = i + 1\n",
    "\n",
    "                # Find the R Index of Last Item\n",
    "                last_item_r = last_item_l\n",
    "                \n",
    "                length = find_index(self.entities[last_item_l:], lambda e: self.is_stop(e))\n",
    "                if length > 0:\n",
    "                    last_item_r += length - 1\n",
    "                elif length == -1:\n",
    "                    last_item_r = len(self.entities) - 1\n",
    "\n",
    "                # Add Last Item\n",
    "                lists[-1].append([last_item_l, last_item_r])\n",
    "                lists.append([[None, None]])\n",
    "                i += 1\n",
    "\n",
    "            # Close Item\n",
    "            elif opened and close_item:\n",
    "                lists[-1].append([i + 1, i])\n",
    "                i += 1\n",
    "                \n",
    "            # Remove List\n",
    "            elif opened and remove_list:\n",
    "                lists[-1] = [[None, None]]\n",
    "                i += 1\n",
    "            \n",
    "            # Continue Item\n",
    "            else:\n",
    "                if not opened:\n",
    "                    lists[-1][0] = [i, i]\n",
    "                else:\n",
    "                    lists[-1][-1][1] += 1\n",
    "                i += 1\n",
    "        \n",
    "        # If we reach the end of the list and the last\n",
    "        # list is invalid (< 3 items), we remove it.\n",
    "        if bool(\n",
    "            lists and len(lists[-1]) < 3 or \n",
    "            (\n",
    "                lists and\n",
    "                not find(self.entities[lists[-1][0][0]:], lambda e: e.label_has([Entity.AND_OR_END]) and e.lower()[0] == sep)\n",
    "            )\n",
    "        ):\n",
    "            lists.pop()\n",
    "        \n",
    "        # In each item, we look for pairs (e.g. X and Y).\n",
    "        # We only handle one conjunction.\n",
    "        num_lists = len(lists)\n",
    "        for i, lst in enumerate(lists):\n",
    "            if i >= num_lists:\n",
    "                break\n",
    "            \n",
    "            for l, r in lst:\n",
    "                tokens = Entity.tokens(ents=self.entities[l:r+1])\n",
    "                conj = find_all(tokens, lambda t: Entity.is_conjunction(t))\n",
    "                if len(conj) == 1:\n",
    "                    lists.append([[l, r]])\n",
    "        \n",
    "        # If there's no lists at all, we can take advantage\n",
    "        # of lax rules.\n",
    "        if not lists:\n",
    "            lst = [[None, None]]\n",
    "            i = 0\n",
    "            while i < len(self.entities):\n",
    "                if self.entities[i].label_has([Entity.BREAK, Entity.AND_OR_END, Entity.END]):\n",
    "                    if lst != [[None, None]]:\n",
    "                        lists.append(lst)\n",
    "                    lst = [[None, None]]\n",
    "                else:\n",
    "                    if lst == [[None, None]]:\n",
    "                        lst = [[i, i]]\n",
    "                    else:\n",
    "                        lst[-1][1] = i\n",
    "                \n",
    "                i += 1\n",
    "            \n",
    "            if lst != [[None, None]]:\n",
    "                lists.append(lst)\n",
    "        \n",
    "        # Here we remove duplicates, I'm not sure if duplicates still\n",
    "        # occur, I observed them once, but this is here in case.\n",
    "        # Note: I could do a cheeky list(set(...)), at least I think.\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            if lists[i] in lists[i+1:]:\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Remove Invalid Lists\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            # The list contains one item and that item only contains one\n",
    "            # token, or the list has two items.\n",
    "            if bool(\n",
    "                (\n",
    "                    len(lists[i]) == 1 and \n",
    "                    lists[i][0][0] == lists[i][0][1]\n",
    "                ) or\n",
    "                len(lists[i]) == 2\n",
    "            ):\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        return lists\n",
    "\n",
    "    def clean_lists(self, lists):\n",
    "        overlaps = []\n",
    "\n",
    "        i = 0\n",
    "        while i + 1 < len(lists):\n",
    "            a = lists[i]\n",
    "            b = lists[i+1]\n",
    "                  \n",
    "            if a[-1] != b[0]:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if len(a) <= 1 or len(b) <= 1:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # No Way to Split\n",
    "            if a[-1][1] - a[-1][0] <= 1:\n",
    "                overlaps.extend([i, i + 1])\n",
    "                i += 2\n",
    "            else:\n",
    "                a[-1][1] = a[-1][0]\n",
    "                b[0][0] = b[0][1]\n",
    "                i += 2\n",
    "        \n",
    "        lists = [l for i, l in enumerate(lists) if i not in overlaps]\n",
    "        return lists\n",
    "\n",
    "    def expand_noun(self, tokens, start, direction):\n",
    "        for group in [*self.main.sp_doc.noun_chunks, *self.main.sp_doc.ents]:\n",
    "            tokens_i = [t.i for t in group]\n",
    "            if tokens[start].i in tokens_i:\n",
    "                while start >= 0 and start < len(tokens) and tokens[start].i in tokens_i:\n",
    "                    start += 1 * direction\n",
    "                start += 1 * direction * -1\n",
    "                break\n",
    "        \n",
    "        return start\n",
    "        \n",
    "    def char_bound_list(self, lst):\n",
    "        # We bound each item according to characters or a speech.\n",
    "        # We find these bounds from the \"base item\", the second to last item.\n",
    "        base_tokens = Entity.tokens(ents=self.entities[lst[-2][0]:lst[-2][1]+1])\n",
    "        \n",
    "        # As we're bounding by characters, primarily, the left bound is just\n",
    "        # the characters of the first token\n",
    "        l_bound = base_tokens[0].lower_\n",
    "\n",
    "        # The right bound is the first tag, of the below set of tags, that we\n",
    "        # encounter in the base tokens. If there's not such a token, we cannot\n",
    "        # bound the items.\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\", \"NUM\"]\n",
    "        r_bound = None\n",
    "        for i in range(len(base_tokens) - 1, -1, -1):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                r_bound = base_tokens[i]\n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # The inner items are already bounded on the left and right sides.\n",
    "        # All we need to check is whether the start matches with the left bound.\n",
    "        inner_items = lst[1:-2]\n",
    "\n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            tokens = Entity.tokens(ents=self.entities[l:r+1])\n",
    "\n",
    "            # If it doesn't match, we check if the next set of items can be\n",
    "            # bounded. If not, we cannot bound the list.\n",
    "            if tokens[0].lower_ != l_bound:\n",
    "                if len(inner_items) - i - 1 >= 2:\n",
    "                    return self.bound_list(lst[i+2:])\n",
    "                return None\n",
    "            \n",
    "        # Check for L Bound in Starting Item\n",
    "        start_tokens = Entity.tokens(ents=self.entities[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        while start_l >= 0 and start_tokens[start_l].lower_ != l_bound:\n",
    "            start_l -= 1\n",
    "\n",
    "        # L Bound Not Found\n",
    "        if start_l < 0:\n",
    "            # If the list is greater than 4 items, we can\n",
    "            # cut off the starting item, and try again.\n",
    "            if len(inner_items) >= 2:\n",
    "                return self.bound_list(lst[1:])\n",
    "            return None\n",
    "\n",
    "        # If the first of the start tokens is a noun, there may be more\n",
    "        # to include.\n",
    "        if start_tokens[start_l].pos_ in Lists.NOUNS:\n",
    "            start_l = self.expand_noun(start_tokens, start_l, -1)\n",
    "                    \n",
    "        # Check for R Bound in Ending Item\n",
    "        end_tokens = Entity.tokens(ents=self.entities[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "        while end_r < num_end_tokens and end_tokens[end_r].pos_ not in speech:\n",
    "            end_r += 1\n",
    "\n",
    "        if end_r >= num_end_tokens:\n",
    "            return None\n",
    "\n",
    "        # If the last of the end tokens is a noun, there may be more\n",
    "        # to include.\n",
    "        if end_tokens[end_r].pos_ in Lists.NOUNS:\n",
    "            end_r = self.expand_noun(end_tokens, end_r, 1)\n",
    "        \n",
    "        # Create List\n",
    "        entity_start_item = Entity(self.main.sp_doc, label=Entity.ITEM, l=start_tokens[start_l].i, r=start_tokens[-1].i)\n",
    "        entity_end_item = Entity(self.main.sp_doc, label=Entity.ITEM, l=end_tokens[0].i, r=end_tokens[end_r].i)\n",
    "        \n",
    "        entity_list = Entity(self.main.sp_doc, label=Entity.LIST, l=start_tokens[start_l].i, r=end_tokens[end_r].i)\n",
    "        entity_list.children.extend([entity_start_item, entity_end_item])\n",
    "        \n",
    "        for item in lst[1:-1]:\n",
    "            tokens = Entity.tokens(ents=self.entities[item[0]:item[1]+1])\n",
    "            entity_item = Entity(self.main.sp_doc, label=Entity.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            entity_list.children.append(entity_item)\n",
    "\n",
    "        return entity_list\n",
    "\n",
    "    def char_bound_pair(self, pair):\n",
    "        tokens = Entity.tokens(ents=self.entities[pair[0][0]:pair[0][1]+1])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        m = find_index(tokens, lambda t: Entity.is_conjunction(t))\n",
    "\n",
    "        l = m - 1\n",
    "        r = m + 1\n",
    "\n",
    "        # Bound L by R Token Characters\n",
    "        i = m - 1\n",
    "        while i >= 0 and tokens[i].lower_ != tokens[m + 1].lower_:\n",
    "            i -= 1\n",
    "\n",
    "        if i < 0:\n",
    "            return None\n",
    "\n",
    "        # Bound R by L Token Speech\n",
    "        j =  m + 1\n",
    "        while j < num_tokens and not Entity.same_speech(tokens[m-1].pos_, tokens[j].pos_):\n",
    "            j += 1\n",
    "\n",
    "        if j >= num_tokens:\n",
    "            return None\n",
    "        \n",
    "        e_item_l = Entity(self.main.sp_doc, label=Entity.ITEM, l=tokens[i].i, r=tokens[m-1].i)\n",
    "        e_item_r = Entity(self.main.sp_doc, label=Entity.ITEM, l=tokens[m+1].i, r=tokens[j].i)\n",
    "        e_list = Entity(self.main.sp_doc, label=Entity.LIST, l=tokens[i].i, r=tokens[j].i, children=[e_item_l, e_item_r])\n",
    "        return e_list\n",
    "    \n",
    "    def bound_list(self, lst):\n",
    "        # Base Item (2nd to Last Item) Tokens\n",
    "        # This item is already bounded by the\n",
    "        # left and right sides, which is useful.\n",
    "        base_tokens = Entity.tokens(ents=self.entities[lst[-2][0]:lst[-2][1]+1])\n",
    "        num_base_tokens = len(base_tokens)\n",
    "        \n",
    "        # Speech Bounds\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\"]\n",
    "        adjectives = [\"ADJ\", \"ADV\", \"NUM\"]\n",
    "        \n",
    "        # Find L Bound\n",
    "        l_bound = []\n",
    "        for i in range(0, num_base_tokens):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                l_bound = [base_tokens[i].pos_]\n",
    "                break\n",
    "            elif base_tokens[i].pos_ in adjectives:\n",
    "                l_bound = [base_tokens[i].pos_]\n",
    "\n",
    "                j = i + 1\n",
    "                while j < num_base_tokens:\n",
    "                    if base_tokens[j].pos_ in speech:\n",
    "                        l_bound.append(base_tokens[j].pos_)\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if not l_bound:\n",
    "            return None\n",
    "        \n",
    "        # Find R Bound\n",
    "        r_bound = []\n",
    "        for i in range(num_base_tokens - 1, -1, -1):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                r_bound = [base_tokens[i].pos_]\n",
    "                break\n",
    "            elif base_tokens[i].pos_ in adjectives:\n",
    "                r_bound = [base_tokens[i].pos_]\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0:\n",
    "                    if base_tokens[j].pos_ in speech:\n",
    "                        r_bound.append(base_tokens[j].pos_)\n",
    "                        break\n",
    "                    j -= 1\n",
    "                \n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "        \n",
    "        # Check Inner Items\n",
    "        # The inner items must have the left bound,\n",
    "        # the right bound isn't as important.\n",
    "        inner_items = lst[1:-1]\n",
    "\n",
    "        verb_seen = False\n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            item_tokens = Entity.tokens(ents=self.entities[l:r+1])\n",
    "            item_speech = [token.pos_ for token in item_tokens]\n",
    "\n",
    "            # Must be Homogeneous\n",
    "            if \"VERB\" not in item_speech and verb_seen:\n",
    "                if len(inner_items) >= 2:\n",
    "                    return self.bound_list(lst[1:])  \n",
    "                else:\n",
    "                    return None\n",
    "            elif \"VERB\" in item_speech:\n",
    "                verb_seen = True\n",
    "\n",
    "            # Not Found\n",
    "            if not set(l_bound).intersection(item_speech):\n",
    "                # We check if the list starting at the next\n",
    "                # item has a chance. If it does, that becomes\n",
    "                # the list.\n",
    "                if len(inner_items) - i + 1 >= 2:\n",
    "                    return self.bound_list(lst[i+2:])\n",
    "                return None\n",
    "        \n",
    "        # Check Starting Item\n",
    "        start_tokens = Entity.tokens(ents=self.entities[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        \n",
    "        while start_l >= 0 and not Entity.same_speech_list(start_tokens[start_l].pos_, l_bound):\n",
    "            start_l -= 1\n",
    "\n",
    "        if start_l < 0:\n",
    "            if len(inner_items) >= 2:\n",
    "                return self.bound_list(lst[1:])\n",
    "            return None\n",
    "\n",
    "        # Adjust Starting Item\n",
    "        if set(l_bound).intersection(Lists.NOUNS):\n",
    "            start_l = self.expand_noun(start_tokens, start_l, -1)\n",
    "        \n",
    "        # Check Ending Item\n",
    "        end_tokens = Entity.tokens(ents=self.entities[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "\n",
    "        while end_r < num_end_tokens and not Entity.same_speech_list(end_tokens[end_r].pos_, r_bound):\n",
    "            end_r += 1\n",
    "\n",
    "        if end_r >= num_end_tokens:\n",
    "            return None\n",
    "\n",
    "        # Adjust Ending Item\n",
    "        if set(r_bound).intersection(Lists.NOUNS):\n",
    "            end_r = self.expand_noun(end_tokens, end_r, 1)\n",
    "\n",
    "        # Create List\n",
    "        \n",
    "        # Adjusting Bounds for Start and End Entities\n",
    "        l_i = start_tokens[start_l].i\n",
    "        l_label = [Entity.ITEM]\n",
    "        \n",
    "        r_i = end_tokens[end_r].i\n",
    "        r_label = [Entity.ITEM]\n",
    "        \n",
    "        for ent in self.enclosures:\n",
    "            if not ent.label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                continue\n",
    "            \n",
    "            l_overlap = ent.l <= start_tokens[start_l].i <= ent.r\n",
    "            r_overlap = ent.l <= end_tokens[end_r].i <= ent.r\n",
    "\n",
    "            # Left Item\n",
    "            if l_overlap and not r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Entity.BRACKETS, Entity.QUOTE])))\n",
    "                l_i = min(ent.l, l_i)\n",
    "\n",
    "            # Right Item\n",
    "            if not l_overlap and r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Entity.BRACKETS, Entity.QUOTE])))\n",
    "                r_i = max(ent.r, r_i)\n",
    "      \n",
    "        entity_list = Entity(self.main.sp_doc, label=Entity.LIST, l=l_i, r=r_i)\n",
    "\n",
    "        entity_start_item = Entity(self.main.sp_doc, label=l_label, l=l_i, r=start_tokens[-1].i)\n",
    "        entity_end_item = Entity(self.main.sp_doc, label=r_label, l=end_tokens[0].i, r=r_i)\n",
    "        entity_list.children.extend([entity_start_item, entity_end_item])\n",
    "\n",
    "        for item in lst[1:-1]:\n",
    "            tokens = Entity.tokens(ents=self.entities[item[0]:item[1]+1])\n",
    "            entity_item = Entity(self.main.sp_doc, label=Entity.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            entity_list.children.append(entity_item)\n",
    "\n",
    "        return entity_list\n",
    "    \n",
    "    def bound_pair(self, pair):\n",
    "        # print(pair)\n",
    "        tokens = Entity.tokens(ents=self.entities[pair[0][0]:pair[0][1]+1])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        # Verb Partitions\n",
    "        m = find_index(tokens, lambda t: Entity.is_conjunction(t))\n",
    "        m_i = tokens[m].i\n",
    "\n",
    "        # Speech for Bounding\n",
    "        # We handle lists of the types below.\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\"]\n",
    "        adjectives = [\"ADJ\", \"ADV\", \"NUM\"]\n",
    "\n",
    "        # Find L Bound\n",
    "        l_bound = []\n",
    "        l_bound_i = None\n",
    "        \n",
    "        for i in range(m + 1, num_tokens):\n",
    "            if tokens[i].pos_ in speech:\n",
    "                l_bound = [tokens[i].pos_]\n",
    "                l_bound_i = tokens[i].i\n",
    "                break\n",
    "            # With adjectives, we can also add the following token\n",
    "            # as a bound. This allows a list like \"X and [ADJ] Y\"\n",
    "            # to be recognized.\n",
    "            elif tokens[i].pos_ in adjectives:\n",
    "                l_bound = [tokens[i].pos_]\n",
    "\n",
    "                j = i + 1\n",
    "                while j < num_tokens:\n",
    "                    if tokens[j].pos_ in speech:\n",
    "                        l_bound.append(tokens[j].pos_)\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                break\n",
    "\n",
    "        if not l_bound:\n",
    "            # print(6)\n",
    "            return None\n",
    "        \n",
    "        # Find R Bound\n",
    "        r_bound = []\n",
    "        r_bound_i = None\n",
    "\n",
    "        # print(tokens)\n",
    "        # print(m)\n",
    "        \n",
    "        for i in range(m - 1, -1, -1):\n",
    "            # print(tokens[i], tokens[i].pos_)\n",
    "            if tokens[i].pos_ in speech:\n",
    "                r_bound = [tokens[i].pos_]\n",
    "                r_bound_i = tokens[i].i\n",
    "                break\n",
    "            # With adjectives, we can also list the following token\n",
    "            # as a bound. This allows a list like \"X and [ADJ] Y\"\n",
    "            # to be recognized.\n",
    "            elif tokens[i].pos_ in adjectives:\n",
    "                r_bound = [tokens[i].pos_]\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0:\n",
    "                    if tokens[j].pos_ in speech:\n",
    "                        r_bound.append(tokens[j].pos_)\n",
    "                        break\n",
    "                    j -= 1\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if not r_bound:\n",
    "            # print(7)\n",
    "            return None\n",
    "\n",
    "        # Bound L Item\n",
    "        l = m - 1\n",
    "        while l >= 0 and not Entity.same_speech_list(tokens[l].pos_, l_bound):\n",
    "            l -= 1\n",
    "\n",
    "        if l < 0:\n",
    "            # print(8)\n",
    "            return None\n",
    "\n",
    "        # Adjust L if Noun\n",
    "        if l_bound in Lists.NOUNS:\n",
    "            l = self.expand_noun(tokens, l, -1)\n",
    "        \n",
    "        # Bound R Item\n",
    "        r = m + 1\n",
    "        while r < num_tokens and not Entity.same_speech_list(tokens[r].pos_, r_bound):\n",
    "            r += 1\n",
    "        \n",
    "        if r >= num_tokens:\n",
    "            # print(9)\n",
    "            return None\n",
    "\n",
    "        # Adjust R if Noun\n",
    "        if r_bound in Lists.NOUNS:\n",
    "            r = self.expand_noun(tokens, r, 1)\n",
    "\n",
    "        # Further Adjusting Bounds for Entities\n",
    "        l_i = tokens[l].i\n",
    "        l_label = [Entity.ITEM]\n",
    "        \n",
    "        r_i = tokens[r].i\n",
    "        r_label = [Entity.ITEM]\n",
    "        for ent in self.enclosures:\n",
    "            if not ent.label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                continue\n",
    "            \n",
    "            l_overlap = ent.l <= tokens[l].i <= ent.r\n",
    "            r_overlap = ent.l <= tokens[r].i <= ent.r\n",
    "\n",
    "            # Left Item\n",
    "            if l_overlap and not r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Entity.BRACKETS, Entity.QUOTE])))\n",
    "                l_i = min(ent.l, l_i)\n",
    "\n",
    "            # Right Item\n",
    "            if not l_overlap and r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Entity.BRACKETS, Entity.QUOTE])))\n",
    "                r_i = max(ent.r, r_i)\n",
    "\n",
    "        e_item_l = Entity(self.main.sp_doc, label=l_label, l=l_i, r=m_i-1)\n",
    "        e_item_r = Entity(self.main.sp_doc, label=r_label, l=m_i+1, r=r_i)\n",
    "        e_list = Entity(self.main.sp_doc, label=Entity.LIST, l=l_i, r=r_i)\n",
    "        e_list.children.extend([e_item_l, e_item_r])\n",
    "        \n",
    "        return e_list\n",
    "\n",
    "    def bound_lists(self, lists):\n",
    "        bound_lists = []\n",
    "        \n",
    "        for lst in lists:\n",
    "            bound = None\n",
    "        \n",
    "            if len(lst) == 1:\n",
    "                bound = self.char_bound_pair(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_pair(lst)\n",
    "            else:\n",
    "                bound = self.char_bound_list(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_list(lst)\n",
    "            \n",
    "            if bound:\n",
    "                bound_lists.append(bound)\n",
    "\n",
    "        return bound_lists\n",
    "\n",
    "    def merge_lists(self, bound_lists):\n",
    "        # Map (L, R) to Entity List\n",
    "        mapped_bounds = {}\n",
    "        for lst in bound_lists:\n",
    "            mapped_bounds[(lst.l, lst.r)] = lst\n",
    "        bounds = list(mapped_bounds.keys())\n",
    "\n",
    "        # Find Largest Coverage of Bounds\n",
    "        max_coverage = []\n",
    "        \n",
    "        for bound in bounds:\n",
    "            overlap = False\n",
    "            for i, max_bound in enumerate(max_coverage):\n",
    "                contains = max_bound[0] <= bound[0] <= max_bound[1] or max_bound[0] <= bound[1] <= max_bound[1]\n",
    "                surround = bound[0] <= max_bound[0] <= bound[1] or bound[0] <= max_bound[1] <= bound[1]\n",
    "                \n",
    "                if contains or surround:\n",
    "                    overlap = True\n",
    "                \n",
    "                    if bound[1] - bound[0] > max_bound[1] - max_bound[0]:\n",
    "                        max_coverage[i] = bound\n",
    "            \n",
    "            if not overlap:\n",
    "                max_coverage.append(bound)\n",
    "        \n",
    "        # Integrate Lists\n",
    "        for bound in max_coverage:\n",
    "            l_overlap = None\n",
    "            l_overlap_i = None\n",
    "            \n",
    "            r_overlap = None\n",
    "            r_overlap_i = None\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(self.entities):\n",
    "                entity = self.entities[i]\n",
    "                \n",
    "                # Overlap w/ Left\n",
    "                if not l_overlap and entity.l <= bound[0] <= entity.r:\n",
    "                    l_overlap = entity\n",
    "                    l_overlap_i = i\n",
    "    \n",
    "                # Overlap w/ Right\n",
    "                if entity.l <= bound[1] <= entity.r:\n",
    "                    r_overlap = entity\n",
    "                    r_overlap_i = i\n",
    "\n",
    "                if l_overlap and r_overlap:\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            if l_overlap.label_has([Entity.BRACKETS, Entity.QUOTE]):\n",
    "                self.entities = self.entities[:l_overlap_i] + self.entities[r_overlap_i+1:]\n",
    "                self.entities.insert(l_overlap_i, mapped_bounds[bound])\n",
    "                \n",
    "                mapped_bounds[bound].l = min(l_overlap.l, mapped_bounds[bound].l)\n",
    "                mapped_bounds[bound].r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                \n",
    "            elif l_overlap.label_has([Entity.I_CLAUSE, Entity.D_CLAUSE, Entity.P_PHRASE]):\n",
    "                if l_overlap.l == mapped_bounds[bound].l:\n",
    "                    # Add Children\n",
    "                    l_overlap.r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                    l_overlap.children.append(mapped_bounds[bound])\n",
    "                    self.entities = self.entities[:l_overlap_i+1] + self.entities[r_overlap_i+1:]\n",
    "                else:\n",
    "                    # Add Children\n",
    "                    l_overlap.r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                    l_overlap.children.append(mapped_bounds[bound])\n",
    "                    self.entities = self.entities[:l_overlap_i+1] + self.entities[r_overlap_i+1:]\n",
    "                    \n",
    "            else:\n",
    "                self.entities = self.entities[:l_overlap_i] + self.entities[r_overlap_i+1:]\n",
    "                self.entities.insert(l_overlap_i, mapped_bounds[bound])\n",
    "\n",
    "        return self.entities\n",
    "        \n",
    "    def identify(self, sep):\n",
    "        lists = self.find_lists(sep)\n",
    "        # print(1, lists)\n",
    "        lists = self.clean_lists(lists)\n",
    "        # print(2, lists)\n",
    "        lists = self.bound_lists(lists)   \n",
    "        # print(3, lists)\n",
    "        lists = self.merge_lists(lists)\n",
    "        # print(4, lists)\n",
    "        return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca0f4319-9599-4d2d-be36-9a29f3f1ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parts:\n",
    "    def __init__(self, main):\n",
    "        self.main = main\n",
    "        self.root = Entity(self.main.sp_doc)\n",
    "        self.reg = []\n",
    "\n",
    "    def load_registry(self, ent):\n",
    "        reg = {(ent.l, ent.r): ent}\n",
    "        for child in ent.children:\n",
    "            if not child.label:\n",
    "                continue\n",
    "            reg.update(self.load_registry(child))\n",
    "        return reg\n",
    "    \n",
    "    def update(self):\n",
    "        reg = []\n",
    "        for sent in self.main.sp_doc.sents:\n",
    "            tokens = list(sent)\n",
    "            reg.append(self.load_entities(tokens))\n",
    "        self.reg = reg\n",
    "    \n",
    "    def load_entities(self, tokens, load_clauses=True):\n",
    "        entities = []\n",
    "        for token in tokens:\n",
    "            entity = Entity(\n",
    "                self.main.sp_doc, \n",
    "                l=token.i, \n",
    "                r=token.i\n",
    "            )\n",
    "            entities.append(entity)\n",
    "\n",
    "        # Enclosures\n",
    "        entities = Quotes(self.main, entities).identify()\n",
    "        entities = Brackets(self.main, entities).identify()\n",
    "\n",
    "        # These class of entities are put into other entities later\n",
    "        # on. However, we still need access to these enclosures for\n",
    "        # the list identification.\n",
    "        enclosures = [ent for ent in entities if ent.label_has([Entity.BRACKETS, Entity.QUOTE])]\n",
    "        \n",
    "        # Find Separator\n",
    "        sep = \",\"\n",
    "        for entity in entities:\n",
    "            if \";\" == entity.lower()[0]:\n",
    "                sep = \";\"\n",
    "                break\n",
    "\n",
    "        # Separators and Colons\n",
    "        entities = Separators(self.main, entities).identify()\n",
    "        entities = Colons(self.main, entities).identify()\n",
    "\n",
    "        if load_clauses:\n",
    "            entities = Dependent_Clauses(self.main, entities).identify(sep)\n",
    "            entities = Independent_Clauses(self.main, entities).identify([Entity.END])\n",
    "            entities = Prepositional_Phrases(self.main, entities).identify()\n",
    "        \n",
    "        entities = Lists(self.main, entities, enclosures).identify(sep)\n",
    "\n",
    "        # There is some overlap between lists and independent\n",
    "        # clauses because they both can use \", [AND/OR]\", but\n",
    "        # after the lists are identified, we can assume the\n",
    "        # remaining \", [AND/OR]\" are parts of independent clauses.\n",
    "        if load_clauses:\n",
    "            entities = Independent_Clauses(self.main, entities).identify([Entity.AND_OR_END])\n",
    "\n",
    "        # Merge Individual Entities\n",
    "        i = 0\n",
    "        while i < len(entities):\n",
    "            if not entities[i].label:\n",
    "                while i + 1 < len(entities) and (not entities[i+1].label or entities[i+1].label_has([Entity.CONJ])):\n",
    "                    entities.pop(i+1)\n",
    "                    entities[i].r += 1\n",
    "                entities[i].label = [Entity.FRAGMENT]\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        # Return Registry\n",
    "        parent = Entity(self.main.sp_doc, l=-1, r=-1, children=entities)\n",
    "        reg = self.load_registry(parent)\n",
    "        if (-1, -1) in reg:\n",
    "            del reg[(-1, -1)]\n",
    "\n",
    "        for ent in entities:\n",
    "            subset = 2 < len(ent.span()) < len(tokens)\n",
    "            content = ent.label_has([\n",
    "                Entity.I_CLAUSE, \n",
    "                Entity.D_CLAUSE, \n",
    "                Entity.FRAGMENT\n",
    "            ])\n",
    "            \n",
    "            if subset and content:\n",
    "                sub_reg = self.load_entities(ent.span(), load_clauses=False)\n",
    "                if (-1, -1) in sub_reg:\n",
    "                    del sub_reg[(-1, -1)]\n",
    "\n",
    "                for k, v in sub_reg.items():\n",
    "                    reg[k] = v\n",
    "            \n",
    "        return reg"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "053522d8-3910-427d-8137-dbd1804d27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(List) (carcinus maenas) and two ecologically important basal resources\n",
      "['(carcinus maenas)', 'two ecologically important basal resources']\n",
      "(List) (ascophyllum nodosum) and barnacles\n",
      "['(ascophyllum nodosum)', 'barnacles']\n",
      "(List) direct and indirect\n",
      "['direct', 'indirect']\n",
      "(List) (littorina) and carnivorous (nucella)\n",
      "['(littorina)', 'carnivorous (nucella)']\n",
      "(List) that had settled on or between barnacles to remain\n",
      "['that had settled on', 'between barnacles to remain']\n",
      "(List) barnacles and algae\n",
      "['barnacles', 'algae']\n",
      "(List) (littorina littorea) and carnivorous (nucella lapillus)\n",
      "['(littorina littorea)', 'carnivorous (nucella lapillus)']\n",
      "(List) consumers and resources\n",
      "['consumers', 'resources']\n",
      "(List) crab and each resource\n",
      "['crab', 'each resource']\n",
      "(List) crabs and barnacles\n",
      "['crabs', 'barnacles']\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# %run \"Helper.ipynb\"\n",
    "\n",
    "class Main:\n",
    "    def __init__(self):\n",
    "        self.sp_nlp = spacy.load(\"en_core_web_lg\")\n",
    "        self.sp_doc = self.sp_nlp(\"In simple, linear food chains, top predators can have positive indirect effects on basal resources by causing changes in the traits (e.g. behaviour, feeding rates) of intermediate consumers. Although less is known about trait - mediated indirect interactions (TMIIs) in more complex food webs, it has been suggested that such complexity dampens trophic cascades. We examined TMIIs between a predatory crab (Carcinus maenas) and two ecologically important basal resources, fucoid algae (Ascophyllum nodosum) and barnacles (Semibalanus balanoides), which are consumed by herbivorous (Littorina littorea) and carnivorous (Nucella lapillus) snails, respectively. Because crab predation risk suppresses snail feeding rates, we hypothesized that crabs would also shape direct and indirect interactions among the multiple consumers and resources. We found that the magnitude of TMIIs between the crab and each resource depended on the suite of intermediate consumers present in the food web. Carnivorous snails (Nucella) transmitted TMIIs between crabs and barnacles. However, crab – algae TMIIs were transmitted by both herbivorous (Littorina) and carnivorous (Nucella) snails, and these TMIIs were additive. By causing Nucella to consume fewer barnacles, crab predation risk allowed fucoids that had settled on or between barnacles to remain in the community. Hence, positive interactions between barnacles and algae caused crab – algae TMIIs to be strongest when both consumers were present. Studies of TMIIs in more realistic, reticulate food webs will be necessary for a more complete understanding of how predation risk shapes community dynamics.\")\n",
    "        # self.sp_doc = self.sp_nlp(\"We saw a small dog, a big cat, and a bird.\")\n",
    "\n",
    "main = Main()\n",
    "# main.sp_doc = main.sp_nlp(\"fucoid algae (Ascophyllum nodosum) and barnacles (Semibalanus balanoides), which are consumed by herbivorous (Littorina littorea) and carnivorous (Nucella lapillus) snails, respectively\")\n",
    "# main.sp_doc = main.sp_nlp(\"We examined TMIIs between a predatory crab (Carcinus maenas)\")\n",
    "\n",
    "parts = Parts(main)\n",
    "\n",
    "res = parts.load_entities(main.sp_doc)\n",
    "for ent in res.values():\n",
    "    if ent.label_has([Entity.LIST]):\n",
    "        print(f\"({ent.label_()}) {ent.lower()}\")\n",
    "        print([e.lower() for e in ent.children])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7a13d9dd-c424-4d3e-9d14-52a1718e9a86",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf2f280f-37e8-4874-81e3-20e3845a08c8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d8e18da7-48a7-4b82-9225-b5566ab69a40",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c03fe9e9-4eb2-498e-8861-742acba5bcc6",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d03253e-de14-4de2-975a-14b967cd7972",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b0820b9-e540-4eda-b2e7-80d446cb299a",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e823afe3-b592-4d70-9701-de90bd8f6ca9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6134cb1b-ae5a-4dcb-8abb-263c1d9d847d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1e84ec73-c54d-445d-8d7e-baf554a846fb",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
