{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9f05c4b1-2271-4c10-bb03-4c9b7310cb74",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit:\n",
    "    # Labels\n",
    "    LIST = 1\n",
    "    ITEM = 2\n",
    "    QUOTE = 3\n",
    "    BREAK = 4\n",
    "    END = 5\n",
    "    AND_OR_END = 6\n",
    "    COLON = 7\n",
    "    COLON_BREAK = 8\n",
    "    I_CLAUSE = 9\n",
    "    D_CLAUSE = 10\n",
    "    P_PHRASE = 11\n",
    "    BRACKETS = 12\n",
    "    FRAGMENT = 13\n",
    "    CONJ = 14\n",
    "\n",
    "    def __init__(self, doc, label=None, l=None, r=None, children=None):\n",
    "        self.doc = doc\n",
    "        self.label = [] if not label else [label] if not isinstance(label, list) else label\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "        self.children = children or []\n",
    "\n",
    "    def label_(self):\n",
    "        labels = []\n",
    "        if Unit.LIST in self.label:\n",
    "            labels.append(\"List\")\n",
    "        if Unit.ITEM in self.label:\n",
    "            labels.append(\"Item\")\n",
    "        if Unit.QUOTE in self.label:\n",
    "            labels.append(\"Quote\")\n",
    "        if Unit.BREAK in self.label:\n",
    "            labels.append(\"Break\")\n",
    "        if Unit.END in self.label:\n",
    "            labels.append(\"End\")\n",
    "        if Unit.AND_OR_END in self.label:\n",
    "            labels.append(\"And or End\")\n",
    "        if Unit.COLON in self.label:\n",
    "            labels.append(\"Colon\")\n",
    "        if Unit.COLON_BREAK in self.label:\n",
    "            labels.append(\"Colon Break\")\n",
    "        if Unit.I_CLAUSE in self.label:\n",
    "            labels.append(\"Independent Clause\")\n",
    "        if Unit.D_CLAUSE in self.label:\n",
    "            labels.append(\"Dependent Clause\")\n",
    "        if Unit.P_PHRASE in self.label:\n",
    "            labels.append(\"Prepositional Phrase\")\n",
    "        if Unit.BRACKETS in self.label:\n",
    "            labels.append(\"Brackets\")\n",
    "        if Unit.FRAGMENT in self.label:\n",
    "            labels.append(\"Fragment\")\n",
    "        if Unit.CONJ in self.label:\n",
    "            labels.append(\"Conjunction\")\n",
    "        return \", \".join(labels) or \"None\"\n",
    "        \n",
    "    def size(self):\n",
    "        return self.r - self.l + 1\n",
    "\n",
    "    def span(self):\n",
    "        return self.doc[self.l:self.r+1]\n",
    "\n",
    "    def text(self):\n",
    "        return self.doc[self.l:self.r+1].text\n",
    "    \n",
    "    def lower(self):\n",
    "        return self.doc[self.l:self.r+1].text.lower()\n",
    "\n",
    "    def start(self):\n",
    "        return self.doc[self.l]\n",
    "\n",
    "    def end(self):\n",
    "        return self.doc[self.r]\n",
    "\n",
    "    def sent_start(self):\n",
    "        for sent in self.doc.sents:\n",
    "            if sent.start <= self.l < sent.end:\n",
    "                return sent.start\n",
    "        return -1\n",
    "\n",
    "    def label_has(self, labels):\n",
    "        return set(self.label).intersection(labels)\n",
    "\n",
    "    @staticmethod\n",
    "    def tokens(*, unit=None, units=None):\n",
    "        if units:\n",
    "            tokens = flatten([list(unit.span()) for unit in units])\n",
    "            tokens = sorted(tokens, key=lambda token: token.i)\n",
    "            return tokens\n",
    "        if unit:\n",
    "            tokens = list(unit.span())\n",
    "            return tokens\n",
    "        return None\n",
    "\n",
    "    @staticmethod\n",
    "    def is_conjunction(token):\n",
    "        return token.lower_ in [\"and\", \"or\"]\n",
    "\n",
    "    @staticmethod\n",
    "    def same_speech(speech_1, speech_2):\n",
    "        nouns = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "        if speech_1 in nouns and speech_2 in nouns:\n",
    "            return True\n",
    "        return speech_1 == speech_2\n",
    "\n",
    "    @staticmethod\n",
    "    def same_speech_list(speech_1, speech_2_list):\n",
    "        for speech_2 in speech_2_list:\n",
    "            if Unit.same_speech(speech_1, speech_2):\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def __str__(self):\n",
    "        return self.text()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "04897364-b98a-4271-9ee0-f200c7b02c39",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quotes:\n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = units\n",
    "\n",
    "    def is_quote(self, i):\n",
    "        return i < len(self.units) and self.units[i].lower() == \"\\\"\"\n",
    "    \n",
    "    def identify(self):\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.units):\n",
    "            if not self.is_quote(i):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            self.units[i].label.append(Unit.QUOTE)\n",
    "            \n",
    "            while not self.is_quote(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "                self.units.pop(i+1)\n",
    "\n",
    "            if self.is_quote(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "                self.units.pop(i+1)\n",
    "\n",
    "        return self.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "d30f332f-9503-4c2a-a17c-593e2ecc0c45",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brackets:\n",
    "    MATCHES = {\n",
    "        \"[\": \"]\", \n",
    "        \"(\": \")\",\n",
    "        \"—\": \"—\",\n",
    "    }\n",
    "\n",
    "    OPENING = MATCHES.keys()\n",
    "    CLOSING = MATCHES.values()\n",
    "\n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.stack = []\n",
    "        self.units = [*units]\n",
    "\n",
    "    def is_opening(self, i):\n",
    "        return i < len(self.units) and self.units[i].lower()[0] in Brackets.OPENING\n",
    "\n",
    "    def is_closing(self, i):\n",
    "        return i < len(self.units) and self.units[i].lower()[0] in Brackets.CLOSING\n",
    "\n",
    "    def closes(self, i):\n",
    "        opener = self.units[self.stack[-1]].lower()[0]\n",
    "        closer = self.units[i].lower()[0]\n",
    "        return Brackets.MATCHES[opener] == closer\n",
    "    \n",
    "    def identify(self):\n",
    "        self.stack = []\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(self.units):\n",
    "            # Closing\n",
    "            if self.is_closing(i) and self.stack:\n",
    "                j = None if not self.closes(i) else self.stack.pop()\n",
    "                \n",
    "                if not self.stack and j != None:\n",
    "                    self.units[j].r = self.units[i].r\n",
    "                    self.units.pop(i)\n",
    "                    continue\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "            # Opening\n",
    "            elif self.is_opening(i):\n",
    "                if not self.stack:\n",
    "                    self.units[i].label.append(Unit.BRACKETS)\n",
    "                self.stack.append(i)\n",
    "                i += 1\n",
    "\n",
    "            # Consuming\n",
    "            elif self.stack:\n",
    "                # If you're at the end of the possible units,\n",
    "                # and the list is unclosed, we must stop.\n",
    "                if i + 1 >= len(self.units):\n",
    "                    break\n",
    "                self.units[self.stack[0]].r = self.units[i+1].r\n",
    "                self.units.pop(i)\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        return self.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e1224ba1-75fe-4fc5-a1f9-e021b214a4f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separators:\n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = [*units]\n",
    "\n",
    "    def is_break(self, i):\n",
    "        if i >= len(self.units):\n",
    "            return False\n",
    "        \n",
    "        if self.units[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "\n",
    "        # Breaks cannot have a following conjunction.\n",
    "        # Else, it would be an end and not a break.\n",
    "        return not bool(\n",
    "            i + 1 < len(self.units) and \n",
    "            self.units[i+1].size() == 1 and \n",
    "            self.units[i+1].span()[0].pos_ in [\"CCONJ\"]\n",
    "        )\n",
    "\n",
    "    def is_end(self, i):\n",
    "        if i >= len(self.units):\n",
    "            return False\n",
    "        \n",
    "        if self.units[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "        \n",
    "        return not self.is_break(i)\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.units):\n",
    "            # Break\n",
    "            if self.is_break(i):\n",
    "                self.units[i].label.append(Unit.BREAK)\n",
    "                i += 1\n",
    "\n",
    "            # End\n",
    "            elif self.is_end(i):\n",
    "                conj = self.units[i+1].start().lower_\n",
    "\n",
    "                if conj in [\"and\", \"or\"]:\n",
    "                    self.units[i].label.append(Unit.AND_OR_END)\n",
    "                else:\n",
    "                    self.units[i].label.append(Unit.END)\n",
    "                \n",
    "                self.units[i].r += 1\n",
    "                self.units.pop(i+1)\n",
    "\n",
    "            elif self.units[i].start().pos_ == \"CCONJ\":\n",
    "                self.units[i].label.append(Unit.CONJ)\n",
    "                i += 1\n",
    "\n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "        return self.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "851a2216-ed77-4486-ae0b-06e2b55ec029",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colons:\n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = [*units]\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.units):\n",
    "            if self.units[i].lower()[-1] != \":\":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if not self.units[i].label:\n",
    "                self.units[i].label.append(Unit.COLON_BREAK)\n",
    "\n",
    "            if i + 1 < len(self.units):\n",
    "                self.units[i+1].label.append(Unit.COLON)\n",
    "                self.units[i+1].r = self.units[-1].r\n",
    "                self.units = self.units[:i+2]\n",
    "            \n",
    "            break\n",
    "\n",
    "        return self.units        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "41e0a309-2be6-48be-8726-f8bfbece633a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Independent_Clauses:\n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = [*units]\n",
    "        self.allowed = []\n",
    "\n",
    "    def end(self, i):    \n",
    "        if i >= len(self.units):\n",
    "            return True\n",
    "\n",
    "        if self.units[i].label_has(self.allowed):\n",
    "            return True\n",
    "        \n",
    "        # Here, we check if the unit after\n",
    "        # the supposed end is a clause. If it\n",
    "        # is, then we can end at the current unit.\n",
    "        return bool(\n",
    "            i + 1 < len(self.units) and \n",
    "            self.units[i+1].label_has([\n",
    "                Unit.COLON,\n",
    "                Unit.COLON_BREAK,\n",
    "                Unit.I_CLAUSE,\n",
    "                Unit.D_CLAUSE\n",
    "            ])\n",
    "        )\n",
    "\n",
    "    def identify(self, allowed):\n",
    "        self.allowed = allowed\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.units):\n",
    "            if not self.units[i].label_has(self.allowed):\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Skip Clause\n",
    "            if self.units[i].label_has([\n",
    "                Unit.I_CLAUSE, \n",
    "                Unit.D_CLAUSE, \n",
    "                Unit.P_PHRASE\n",
    "            ]):\n",
    "                i = units[i].r + 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.units[i].label.append(Unit.I_CLAUSE)\n",
    "            while not self.end(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.units[i+1].label_has([Unit.BRACKETS, Unit.QUOTE, Unit.P_PHRASE]):\n",
    "                    self.units[i].children.append(self.units[i+1])\n",
    "                    \n",
    "                self.units.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        return self.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "9e6dce7b-963a-475c-9c40-d97f9bd15b06",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependent_Clauses:\n",
    "    RELATIVE_NOUNS = [\n",
    "        \"who\",\n",
    "        \"whom\",\n",
    "        \"which\",\n",
    "        \"what\",\n",
    "        \"that\",\n",
    "        \"whose\",\n",
    "        \"whomever\",\n",
    "        \"whoever\",\n",
    "        \"whichever\",\n",
    "        \"whatever\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = units\n",
    "        self.separator = None\n",
    "\n",
    "    def end(self, i):\n",
    "        if i >= len(self.units):\n",
    "            return True\n",
    "\n",
    "        # Here, we check if the unit after\n",
    "        # is a clause. As we don't combine two\n",
    "        # clauses, we must end here if that is\n",
    "        # the case.\n",
    "        if bool(\n",
    "            i + 1 < len(self.units) and \n",
    "            self.units[i+1].label_has([\n",
    "                Unit.COLON, \n",
    "                Unit.COLON_BREAK,\n",
    "                Unit.I_CLAUSE,\n",
    "                Unit.D_CLAUSE\n",
    "            ])\n",
    "        ):\n",
    "            return True\n",
    "\n",
    "        return bool(\n",
    "            self.units[i].lower()[0] == self.separator or\n",
    "            self.units[i].lower() in Dependent_Clauses.RELATIVE_NOUNS or\n",
    "            self.units[i].start().pos_ in [\"SCONJ\"]\n",
    "        )\n",
    "\n",
    "    def identify(self, separator):\n",
    "        self.separator = separator\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.units):\n",
    "            # Skip\n",
    "            if self.units[i].label_has([\n",
    "                Unit.COLON,\n",
    "                Unit.COLON_BREAK,\n",
    "                Unit.I_CLAUSE, \n",
    "                Unit.D_CLAUSE, \n",
    "                Unit.P_PHRASE\n",
    "            ]):\n",
    "                i = self.units[i].r + 1\n",
    "                continue\n",
    "\n",
    "            # Indicators of Dependent Clause\n",
    "            rel = self.units[i].lower() in Dependent_Clauses.RELATIVE_NOUNS\n",
    "            sub = self.units[i].start().pos_ == \"SCONJ\"\n",
    "            \n",
    "            if not sub and not rel:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.units[i].label.append(Unit.D_CLAUSE)\n",
    "            while not self.end(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.units[i+1].label_has([Unit.BRACKETS, Unit.QUOTE, Unit.P_PHRASE]):\n",
    "                    self.units[i].children.append(self.units[i+1])\n",
    "                \n",
    "                self.units.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        return self.units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "48b069be-4406-49fd-bcda-f03cb0944042",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepositional_Phrases:\n",
    "    \n",
    "    def __init__(self, main, units):\n",
    "        self.main = main\n",
    "        self.units = [*units]\n",
    "\n",
    "    # A prepositional phrase is typically ended by a noun.\n",
    "    # Therefore, when we run into a noun, we end the phrase.\n",
    "    # We must also check that it is the last of the first noun(s)\n",
    "    # we encounter.\n",
    "    def last_noun(self, i):\n",
    "        if bool(\n",
    "            # 1. End\n",
    "            i >= len(self.units) or \n",
    "            \n",
    "            # 2. Noun\n",
    "            self.units[i].start().pos_ not in [\n",
    "                \"NOUN\", \n",
    "                \"PROPN\", \n",
    "                \"PRON\"\n",
    "            ]\n",
    "        ):\n",
    "            return False\n",
    "\n",
    "        return bool(\n",
    "            i + 1 >= len(self.units) or \n",
    "            (\n",
    "                self.units[i+1].size() == 1 and \n",
    "                self.units[i+1].start().pos_ not in [\n",
    "                    \"NOUN\", \n",
    "                    \"PROPN\", \n",
    "                    \"PRON\", \n",
    "                    \"PART\"\n",
    "                ]\n",
    "            )\n",
    "        )\n",
    "    \n",
    "    def end(self, i):\n",
    "        return bool(\n",
    "            # 1. End of List\n",
    "            i + 1 >= len(self.units) or\n",
    "            \n",
    "            # 2. Clause\n",
    "            self.units[i+1].label_has([\n",
    "                Unit.COLON,\n",
    "                Unit.COLON_BREAK,\n",
    "                Unit.I_CLAUSE,\n",
    "                Unit.D_CLAUSE,\n",
    "                Unit.P_PHRASE\n",
    "            ]) or\n",
    "            \n",
    "            # 3. Noun\n",
    "            self.last_noun(i)\n",
    "        )\n",
    "\n",
    "    def identify(self):    \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.units):\n",
    "            # Skip\n",
    "            is_comp = self.units[i].size() != 1\n",
    "            is_non_adp = self.units[i].start().pos_ != \"ADP\"\n",
    "            is_not_to = self.units[i].lower() != \"to\"\n",
    "            \n",
    "            if (is_comp or is_non_adp) and is_not_to:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # Create Clause\n",
    "            self.units[i].label.append(Unit.P_PHRASE)\n",
    "            \n",
    "            while not self.end(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "\n",
    "                # Add Child\n",
    "                if self.units[i+1].label_has([Unit.BRACKETS, Unit.QUOTE]):\n",
    "                    self.units[i].children.append(self.units[i+1])\n",
    "                \n",
    "                self.units.pop(i+1)\n",
    "\n",
    "            if self.last_noun(i+1):\n",
    "                self.units[i].r = self.units[i+1].r\n",
    "                self.units.pop(i+1)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return self.units   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "65c4bbbe-94e6-49bd-a969-3323f0e891dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lists:\n",
    "    NOUNS = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, main, units, enclosures):\n",
    "        self.main = main\n",
    "        self.units = [*units]\n",
    "        self.separator = None\n",
    "        self.enclosures = enclosures\n",
    "\n",
    "\n",
    "    \n",
    "    def is_stop(self, unit):\n",
    "        is_break = Unit.BREAK in unit.label and unit.lower()[0] == self.separator\n",
    "        is_clause = unit.label_has([\n",
    "            Unit.I_CLAUSE, \n",
    "            Unit.D_CLAUSE, \n",
    "            Unit.P_PHRASE,\n",
    "            Unit.COLON,\n",
    "            Unit.COLON_BREAK\n",
    "        ])\n",
    "        return is_break or is_clause\n",
    "\n",
    "\n",
    "    \n",
    "    def find_lists(self, sep):\n",
    "        self.separator = sep\n",
    "        \n",
    "        lists = [\n",
    "            [\n",
    "                [None, None]\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(self.units):\n",
    "            unit = self.units[i]\n",
    "\n",
    "            opened = lists[-1][0] != [None, None]\n",
    "            remove_list = unit.label_has([Unit.COLON, Unit.COLON_BREAK])\n",
    "            close_list = unit.label_has([Unit.AND_OR_END]) and unit.lower()[0] == sep\n",
    "            close_item = unit.label_has([Unit.BREAK]) and unit.lower() == sep\n",
    "        \n",
    "            # Close List\n",
    "            if opened and close_list:\n",
    "                # Invalid List, Remove\n",
    "                if len(lists[-1]) < 2:\n",
    "                    lists[-1] = [[None, None]]\n",
    "                    i += 1\n",
    "                    continue\n",
    "                    \n",
    "                # Find the L Index of Last Item\n",
    "                last_item_l = i + 1\n",
    "\n",
    "                # Find the R Index of Last Item\n",
    "                last_item_r = last_item_l\n",
    "                \n",
    "                length = find_index(self.units[last_item_l:], lambda e: self.is_stop(e))\n",
    "                if length > 0:\n",
    "                    last_item_r += length - 1\n",
    "                elif length == -1:\n",
    "                    last_item_r = len(self.units) - 1\n",
    "\n",
    "                # Add Last Item\n",
    "                lists[-1].append([last_item_l, last_item_r])\n",
    "                lists.append([[None, None]])\n",
    "                i += 1\n",
    "\n",
    "            # Close Item\n",
    "            elif opened and close_item:\n",
    "                lists[-1].append([i + 1, i])\n",
    "                i += 1\n",
    "                \n",
    "            # Remove List\n",
    "            elif opened and remove_list:\n",
    "                lists[-1] = [[None, None]]\n",
    "                i += 1\n",
    "            \n",
    "            # Continue Item\n",
    "            else:\n",
    "                if not opened:\n",
    "                    lists[-1][0] = [i, i]\n",
    "                else:\n",
    "                    lists[-1][-1][1] += 1\n",
    "                i += 1\n",
    "        \n",
    "        # If we reach the end of the list and the last\n",
    "        # list is invalid (< 3 items), we remove it.\n",
    "        if bool(\n",
    "            lists and len(lists[-1]) < 3 or \n",
    "            (\n",
    "                lists and\n",
    "                not find(self.units[lists[-1][0][0]:], lambda e: e.label_has([Unit.AND_OR_END]) and e.lower()[0] == sep)\n",
    "            )\n",
    "        ):\n",
    "            lists.pop()\n",
    "        \n",
    "        # In each item, we look for pairs (e.g. X and Y).\n",
    "        # We only handle one conjunction.\n",
    "        num_lists = len(lists)\n",
    "        for i, lst in enumerate(lists):\n",
    "            if i >= num_lists:\n",
    "                break\n",
    "            \n",
    "            for l, r in lst:\n",
    "                tokens = Unit.tokens(units=self.units[l:r+1])\n",
    "                conj = find_all(tokens, lambda t: Unit.is_conjunction(t))\n",
    "                if len(conj) == 1:\n",
    "                    lists.append([[l, r]])\n",
    "        \n",
    "        # If there's no lists at all, we can take advantage\n",
    "        # of lax rules.\n",
    "        if not lists:\n",
    "            lst = [[None, None]]\n",
    "            i = 0\n",
    "            while i < len(self.units):\n",
    "                if self.units[i].label_has([Unit.BREAK, Unit.AND_OR_END, Unit.END]):\n",
    "                    if lst != [[None, None]]:\n",
    "                        lists.append(lst)\n",
    "                    lst = [[None, None]]\n",
    "                else:\n",
    "                    if lst == [[None, None]]:\n",
    "                        lst = [[i, i]]\n",
    "                    else:\n",
    "                        lst[-1][1] = i\n",
    "                \n",
    "                i += 1\n",
    "            \n",
    "            if lst != [[None, None]]:\n",
    "                lists.append(lst)\n",
    "        \n",
    "        # Here we remove duplicates, I'm not sure if duplicates still\n",
    "        # occur, I observed them once, but this is here in case.\n",
    "        # Note: I could do a cheeky list(set(...)), at least I think.\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            if lists[i] in lists[i+1:]:\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        # Remove Invalid Lists\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            # The list contains one item and that item only contains one\n",
    "            # token, or the list has two items.\n",
    "            if bool(\n",
    "                (\n",
    "                    len(lists[i]) == 1 and \n",
    "                    lists[i][0][0] == lists[i][0][1]\n",
    "                ) or\n",
    "                len(lists[i]) == 2\n",
    "            ):\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "        \n",
    "        return lists\n",
    "\n",
    "\n",
    "    \n",
    "    def clean_lists(self, lists):\n",
    "        overlaps = []\n",
    "\n",
    "        i = 0\n",
    "        while i + 1 < len(lists):\n",
    "            a = lists[i]\n",
    "            b = lists[i+1]\n",
    "                  \n",
    "            if a[-1] != b[0]:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if len(a) <= 1 or len(b) <= 1:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # No Way to Split\n",
    "            if a[-1][1] - a[-1][0] <= 1:\n",
    "                overlaps.extend([i, i + 1])\n",
    "                i += 2\n",
    "            else:\n",
    "                a[-1][1] = a[-1][0]\n",
    "                b[0][0] = b[0][1]\n",
    "                i += 2\n",
    "        \n",
    "        lists = [l for i, l in enumerate(lists) if i not in overlaps]\n",
    "        return lists\n",
    "\n",
    "\n",
    "    \n",
    "    def expand_noun(self, tokens, start, direction):\n",
    "        for group in [*self.main.sp_doc.noun_chunks, *self.main.sp_doc.ents]:\n",
    "            tokens_i = [t.i for t in group]\n",
    "            if tokens[start].i in tokens_i:\n",
    "                while start >= 0 and start < len(tokens) and tokens[start].i in tokens_i:\n",
    "                    start += 1 * direction\n",
    "                start += 1 * direction * -1\n",
    "                break\n",
    "        \n",
    "        return start\n",
    "\n",
    "\n",
    "    \n",
    "    def char_bound_list(self, lst):\n",
    "        # We bound each item according to characters or a speech.\n",
    "        # We find these bounds from the \"base item\", the second to last item.\n",
    "        base_tokens = Unit.tokens(units=self.units[lst[-2][0]:lst[-2][1]+1])\n",
    "        \n",
    "        # As we're bounding by characters, primarily, the left bound is just\n",
    "        # the characters of the first token\n",
    "        l_bound = base_tokens[0].lower_\n",
    "\n",
    "        # The right bound is the first tag, of the below set of tags, that we\n",
    "        # encounter in the base tokens. If there's not such a token, we cannot\n",
    "        # bound the items.\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\", \"NUM\"]\n",
    "        r_bound = None\n",
    "        for i in range(len(base_tokens) - 1, -1, -1):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                r_bound = base_tokens[i]\n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # The inner items are already bounded on the left and right sides.\n",
    "        # All we need to check is whether the start matches with the left bound.\n",
    "        inner_items = lst[1:-2]\n",
    "\n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            tokens = Unit.tokens(units=self.units[l:r+1])\n",
    "\n",
    "            # If it doesn't match, we check if the next set of items can be\n",
    "            # bounded. If not, we cannot bound the list.\n",
    "            if tokens[0].lower_ != l_bound:\n",
    "                if len(inner_items) - i - 1 >= 2:\n",
    "                    return self.bound_list(lst[i+2:])\n",
    "                return None\n",
    "            \n",
    "        # Check for L Bound in Starting Item\n",
    "        start_tokens = Unit.tokens(units=self.units[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        while start_l >= 0 and start_tokens[start_l].lower_ != l_bound:\n",
    "            start_l -= 1\n",
    "\n",
    "        # L Bound Not Found\n",
    "        if start_l < 0:\n",
    "            # If the list is greater than 4 items, we can\n",
    "            # cut off the starting item, and try again.\n",
    "            if len(inner_items) >= 2:\n",
    "                return self.bound_list(lst[1:])\n",
    "            return None\n",
    "\n",
    "        # If the first of the start tokens is a noun, there may be more\n",
    "        # to include.\n",
    "        if start_tokens[start_l].pos_ in Lists.NOUNS:\n",
    "            start_l = self.expand_noun(start_tokens, start_l, -1)\n",
    "                    \n",
    "        # Check for R Bound in Ending Item\n",
    "        end_tokens = Unit.tokens(units=self.units[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "        while end_r < num_end_tokens and end_tokens[end_r].pos_ not in speech:\n",
    "            end_r += 1\n",
    "\n",
    "        if end_r >= num_end_tokens:\n",
    "            return None\n",
    "\n",
    "        # If the last of the end tokens is a noun, there may be more\n",
    "        # to include.\n",
    "        if end_tokens[end_r].pos_ in Lists.NOUNS:\n",
    "            end_r = self.expand_noun(end_tokens, end_r, 1)\n",
    "        \n",
    "        # Create List\n",
    "        unit_start_item = Unit(self.main.sp_doc, label=Unit.ITEM, l=start_tokens[start_l].i, r=start_tokens[-1].i)\n",
    "        unit_end_item = Unit(self.main.sp_doc, label=Unit.ITEM, l=end_tokens[0].i, r=end_tokens[end_r].i)\n",
    "        \n",
    "        unit_list = Unit(self.main.sp_doc, label=Unit.LIST, l=start_tokens[start_l].i, r=end_tokens[end_r].i)\n",
    "        unit_list.children.extend([unit_start_item, unit_end_item])\n",
    "        \n",
    "        for item in lst[1:-1]:\n",
    "            tokens = Unit.tokens(units=self.units[item[0]:item[1]+1])\n",
    "            unit_item = Unit(self.main.sp_doc, label=Unit.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            unit_list.children.append(unit_item)\n",
    "\n",
    "        return unit_list\n",
    "\n",
    "\n",
    "    \n",
    "    def char_bound_pair(self, pair):\n",
    "        tokens = Unit.tokens(units=self.units[pair[0][0]:pair[0][1]+1])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        m = find_index(tokens, lambda t: Unit.is_conjunction(t))\n",
    "\n",
    "        l = m - 1\n",
    "        r = m + 1\n",
    "\n",
    "        # Bound L by R Token Characters\n",
    "        i = m - 1\n",
    "        while i >= 0 and tokens[i].lower_ != tokens[m + 1].lower_:\n",
    "            i -= 1\n",
    "\n",
    "        if i < 0:\n",
    "            return None\n",
    "\n",
    "        # Bound R by L Token Speech\n",
    "        j =  m + 1\n",
    "        while j < num_tokens and not Unit.same_speech(tokens[m-1].pos_, tokens[j].pos_):\n",
    "            j += 1\n",
    "\n",
    "        if j >= num_tokens:\n",
    "            return None\n",
    "        \n",
    "        e_item_l = Unit(self.main.sp_doc, label=Unit.ITEM, l=tokens[i].i, r=tokens[m-1].i)\n",
    "        e_item_r = Unit(self.main.sp_doc, label=Unit.ITEM, l=tokens[m+1].i, r=tokens[j].i)\n",
    "        e_list = Unit(self.main.sp_doc, label=Unit.LIST, l=tokens[i].i, r=tokens[j].i, children=[e_item_l, e_item_r])\n",
    "        return e_list\n",
    "\n",
    "\n",
    "    \n",
    "    def bound_list(self, lst):\n",
    "        # Base Item (2nd to Last Item) Tokens\n",
    "        # This item is already bounded by the\n",
    "        # left and right sides, which is useful.\n",
    "        base_tokens = Unit.tokens(units=self.units[lst[-2][0]:lst[-2][1]+1])\n",
    "        num_base_tokens = len(base_tokens)\n",
    "        \n",
    "        # Speech Bounds\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\"]\n",
    "        adjectives = [\"ADJ\", \"ADV\", \"NUM\", \"ADP\"]\n",
    "        \n",
    "        # Find L Bound\n",
    "        l_bound = []\n",
    "        for i in range(0, num_base_tokens):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                l_bound = [base_tokens[i].pos_]\n",
    "                break\n",
    "            elif base_tokens[i].pos_ in adjectives:\n",
    "                l_bound = [base_tokens[i].pos_]\n",
    "\n",
    "                j = i + 1\n",
    "                while j < num_base_tokens:\n",
    "                    if base_tokens[j].pos_ in speech:\n",
    "                        l_bound.append(base_tokens[j].pos_)\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if not l_bound:\n",
    "            return None\n",
    "        \n",
    "        # Find R Bound\n",
    "        r_bound = []\n",
    "        for i in range(num_base_tokens - 1, -1, -1):\n",
    "            if base_tokens[i].pos_ in speech:\n",
    "                r_bound = [base_tokens[i].pos_]\n",
    "                break\n",
    "            elif base_tokens[i].pos_ in adjectives:\n",
    "                r_bound = [base_tokens[i].pos_]\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0:\n",
    "                    if base_tokens[j].pos_ in speech:\n",
    "                        r_bound.append(base_tokens[j].pos_)\n",
    "                        break\n",
    "                    j -= 1\n",
    "                \n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "        \n",
    "        # Check Inner Items\n",
    "        # The inner items must have the left bound,\n",
    "        # the right bound isn't as important.\n",
    "        inner_items = lst[1:-1]\n",
    "\n",
    "        verb_seen = False\n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            item_tokens = Unit.tokens(units=self.units[l:r+1])\n",
    "            item_speech = [token.pos_ for token in item_tokens]\n",
    "\n",
    "            # Must be Homogeneous\n",
    "            if \"VERB\" not in item_speech and verb_seen:\n",
    "                if len(inner_items) >= 2:\n",
    "                    return self.bound_list(lst[1:])  \n",
    "                else:\n",
    "                    return None\n",
    "            elif \"VERB\" in item_speech:\n",
    "                verb_seen = True\n",
    "\n",
    "            # Not Found\n",
    "            if not set(l_bound).intersection(item_speech):\n",
    "                # We check if the list starting at the next\n",
    "                # item has a chance. If it does, that becomes\n",
    "                # the list.\n",
    "                if len(inner_items) - i + 1 >= 2:\n",
    "                    return self.bound_list(lst[i+2:])\n",
    "                return None\n",
    "        \n",
    "        # Check Starting Item\n",
    "        start_tokens = Unit.tokens(units=self.units[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        \n",
    "        while start_l >= 0 and not Unit.same_speech_list(start_tokens[start_l].pos_, l_bound):\n",
    "            start_l -= 1\n",
    "\n",
    "        if start_l < 0:\n",
    "            if len(inner_items) >= 2:\n",
    "                return self.bound_list(lst[1:])\n",
    "            return None\n",
    "\n",
    "        # Adjust Starting Item\n",
    "        if set(l_bound).intersection(Lists.NOUNS):\n",
    "            start_l = self.expand_noun(start_tokens, start_l, -1)\n",
    "        \n",
    "        # Check Ending Item\n",
    "        end_tokens = Unit.tokens(units=self.units[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "\n",
    "        while end_r < num_end_tokens and not Unit.same_speech_list(end_tokens[end_r].pos_, r_bound):\n",
    "            end_r += 1\n",
    "\n",
    "        if end_r >= num_end_tokens:\n",
    "            return None\n",
    "\n",
    "        # Adjust Ending Item\n",
    "        if set(r_bound).intersection(Lists.NOUNS):\n",
    "            end_r = self.expand_noun(end_tokens, end_r, 1)\n",
    "\n",
    "        # Create List\n",
    "        \n",
    "        # Adjusting Bounds for Start and End Entities\n",
    "        l_i = start_tokens[start_l].i\n",
    "        l_label = [Unit.ITEM]\n",
    "        \n",
    "        r_i = end_tokens[end_r].i\n",
    "        r_label = [Unit.ITEM]\n",
    "        \n",
    "        for ent in self.enclosures:\n",
    "            if not ent.label_has([Unit.BRACKETS, Unit.QUOTE]):\n",
    "                continue\n",
    "            \n",
    "            l_overlap = ent.l <= start_tokens[start_l].i <= ent.r\n",
    "            r_overlap = ent.l <= end_tokens[end_r].i <= ent.r\n",
    "\n",
    "            # Left Item\n",
    "            if l_overlap and not r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Unit.BRACKETS, Unit.QUOTE])))\n",
    "                l_i = min(ent.l, l_i)\n",
    "\n",
    "            # Right Item\n",
    "            if not l_overlap and r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Unit.BRACKETS, Unit.QUOTE])))\n",
    "                r_i = max(ent.r, r_i)\n",
    "      \n",
    "        unit_list = Unit(self.main.sp_doc, label=Unit.LIST, l=l_i, r=r_i)\n",
    "\n",
    "        unit_start_item = Unit(self.main.sp_doc, label=l_label, l=l_i, r=start_tokens[-1].i)\n",
    "        unit_end_item = Unit(self.main.sp_doc, label=r_label, l=end_tokens[0].i, r=r_i)\n",
    "        unit_list.children.extend([unit_start_item, unit_end_item])\n",
    "\n",
    "        for item in lst[1:-1]:\n",
    "            tokens = Unit.tokens(units=self.units[item[0]:item[1]+1])\n",
    "            unit_item = Unit(self.main.sp_doc, label=Unit.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            unit_list.children.append(unit_item)\n",
    "\n",
    "        return unit_list\n",
    "\n",
    "\n",
    "    \n",
    "    def bound_pair(self, pair):\n",
    "        tokens = Unit.tokens(units=self.units[pair[0][0]:pair[0][1]+1])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        # Verb Partitions\n",
    "        m = find_index(tokens, lambda t: Unit.is_conjunction(t))\n",
    "        m_i = tokens[m].i\n",
    "\n",
    "        # Speech for Bounding\n",
    "        # We handle lists of the types below.\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\"]\n",
    "        adjectives = [\"ADJ\", \"ADV\", \"NUM\", \"ADP\"]\n",
    "\n",
    "        # Find L Bound\n",
    "        l_bound = []\n",
    "        l_bound_i = None\n",
    "        \n",
    "        for i in range(m + 1, num_tokens):\n",
    "            if tokens[i].pos_ in speech:\n",
    "                l_bound = [tokens[i].pos_]\n",
    "                l_bound_i = tokens[i].i\n",
    "                break\n",
    "            # With adjectives, we can also add the following token\n",
    "            # as a bound. This allows a list like \"X and [ADJ] Y\"\n",
    "            # to be recognized.\n",
    "            elif tokens[i].pos_ in adjectives:\n",
    "                l_bound = [tokens[i].pos_]\n",
    "\n",
    "                j = i + 1\n",
    "                while j < num_tokens:\n",
    "                    if tokens[j].pos_ in speech:\n",
    "                        l_bound.append(tokens[j].pos_)\n",
    "                        break\n",
    "                    j += 1\n",
    "                \n",
    "                break\n",
    "\n",
    "        if not l_bound:\n",
    "            return None\n",
    "        \n",
    "        # Find R Bound\n",
    "        r_bound = []\n",
    "        r_bound_i = None\n",
    "        \n",
    "        for i in range(m - 1, -1, -1):\n",
    "            if tokens[i].pos_ in speech:\n",
    "                r_bound = [tokens[i].pos_]\n",
    "                r_bound_i = tokens[i].i\n",
    "                break\n",
    "            # With adjectives, we can also list the following token\n",
    "            # as a bound. This allows a list like \"X and [ADJ] Y\"\n",
    "            # to be recognized.\n",
    "            elif tokens[i].pos_ in adjectives:\n",
    "                r_bound = [tokens[i].pos_]\n",
    "\n",
    "                j = i - 1\n",
    "                while j >= 0:\n",
    "                    if tokens[j].pos_ in speech:\n",
    "                        r_bound.append(tokens[j].pos_)\n",
    "                        break\n",
    "                    j -= 1\n",
    "                \n",
    "                break\n",
    "        \n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # Bound L Item\n",
    "        l = m - 1\n",
    "        while l >= 0 and not Unit.same_speech_list(tokens[l].pos_, l_bound):\n",
    "            l -= 1\n",
    "\n",
    "        if l < 0:\n",
    "            return None\n",
    "\n",
    "        # Adjust L if Noun\n",
    "        if l_bound in Lists.NOUNS:\n",
    "            l = self.expand_noun(tokens, l, -1)\n",
    "        \n",
    "        # Bound R Item\n",
    "        r = m + 1\n",
    "        while r < num_tokens and not Unit.same_speech_list(tokens[r].pos_, r_bound):\n",
    "            r += 1\n",
    "        \n",
    "        if r >= num_tokens:\n",
    "            return None\n",
    "\n",
    "        # Adjust R if Noun\n",
    "        if r_bound in Lists.NOUNS:\n",
    "            r = self.expand_noun(tokens, r, 1)\n",
    "\n",
    "        # Further Adjusting Bounds for Entities\n",
    "        l_i = tokens[l].i\n",
    "        l_label = [Unit.ITEM]\n",
    "        \n",
    "        r_i = tokens[r].i\n",
    "        r_label = [Unit.ITEM]\n",
    "        for ent in self.enclosures:\n",
    "            if not ent.label_has([Unit.BRACKETS, Unit.QUOTE]):\n",
    "                continue\n",
    "            \n",
    "            l_overlap = ent.l <= tokens[l].i <= ent.r\n",
    "            r_overlap = ent.l <= tokens[r].i <= ent.r\n",
    "\n",
    "            # Left Item\n",
    "            if l_overlap and not r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Unit.BRACKETS, Unit.QUOTE])))\n",
    "                l_i = min(ent.l, l_i)\n",
    "\n",
    "            # Right Item\n",
    "            if not l_overlap and r_overlap:\n",
    "                l_label.extend(list(set(ent.label) & set([Unit.BRACKETS, Unit.QUOTE])))\n",
    "                r_i = max(ent.r, r_i)\n",
    "\n",
    "        e_item_l = Unit(self.main.sp_doc, label=l_label, l=l_i, r=m_i-1)\n",
    "        e_item_r = Unit(self.main.sp_doc, label=r_label, l=m_i+1, r=r_i)\n",
    "        e_list = Unit(self.main.sp_doc, label=Unit.LIST, l=l_i, r=r_i)\n",
    "        e_list.children.extend([e_item_l, e_item_r])\n",
    "        \n",
    "        return e_list\n",
    "\n",
    "\n",
    "    \n",
    "    def bound_lists(self, lists):\n",
    "        bound_lists = []\n",
    "        \n",
    "        for lst in lists:\n",
    "            bound = None\n",
    "        \n",
    "            if len(lst) == 1:\n",
    "                bound = self.char_bound_pair(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_pair(lst)\n",
    "            else:\n",
    "                bound = self.char_bound_list(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_list(lst)\n",
    "            \n",
    "            if bound:\n",
    "                bound_lists.append(bound)\n",
    "\n",
    "        return bound_lists\n",
    "\n",
    "\n",
    "    \n",
    "    def merge_lists(self, bound_lists):\n",
    "        # Map (L, R) to Unit List\n",
    "        mapped_bounds = {}\n",
    "        for lst in bound_lists:\n",
    "            mapped_bounds[(lst.l, lst.r)] = lst\n",
    "        bounds = list(mapped_bounds.keys())\n",
    "\n",
    "        # Find Largest Coverage of Bounds\n",
    "        max_coverage = []\n",
    "        \n",
    "        for bound in bounds:\n",
    "            overlap = False\n",
    "            for i, max_bound in enumerate(max_coverage):\n",
    "                contains = max_bound[0] <= bound[0] <= max_bound[1] or max_bound[0] <= bound[1] <= max_bound[1]\n",
    "                surround = bound[0] <= max_bound[0] <= bound[1] or bound[0] <= max_bound[1] <= bound[1]\n",
    "                \n",
    "                if contains or surround:\n",
    "                    overlap = True\n",
    "                \n",
    "                    if bound[1] - bound[0] > max_bound[1] - max_bound[0]:\n",
    "                        max_coverage[i] = bound\n",
    "            \n",
    "            if not overlap:\n",
    "                max_coverage.append(bound)\n",
    "        \n",
    "        # Integrate Lists\n",
    "        for bound in max_coverage:\n",
    "            l_overlap = None\n",
    "            l_overlap_i = None\n",
    "            \n",
    "            r_overlap = None\n",
    "            r_overlap_i = None\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(self.units):\n",
    "                unit = self.units[i]\n",
    "                \n",
    "                # Overlap w/ Left\n",
    "                if not l_overlap and unit.l <= bound[0] <= unit.r:\n",
    "                    l_overlap = unit\n",
    "                    l_overlap_i = i\n",
    "    \n",
    "                # Overlap w/ Right\n",
    "                if unit.l <= bound[1] <= unit.r:\n",
    "                    r_overlap = unit\n",
    "                    r_overlap_i = i\n",
    "\n",
    "                if l_overlap and r_overlap:\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            if l_overlap.label_has([Unit.BRACKETS, Unit.QUOTE]):\n",
    "                self.units = self.units[:l_overlap_i] + self.units[r_overlap_i+1:]\n",
    "                self.units.insert(l_overlap_i, mapped_bounds[bound])\n",
    "                \n",
    "                mapped_bounds[bound].l = min(l_overlap.l, mapped_bounds[bound].l)\n",
    "                mapped_bounds[bound].r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                \n",
    "            elif l_overlap.label_has([Unit.I_CLAUSE, Unit.D_CLAUSE, Unit.P_PHRASE]):\n",
    "                if l_overlap.l == mapped_bounds[bound].l:\n",
    "                    # Add Children\n",
    "                    l_overlap.r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                    l_overlap.children.append(mapped_bounds[bound])\n",
    "                    self.units = self.units[:l_overlap_i+1] + self.units[r_overlap_i+1:]\n",
    "                else:\n",
    "                    # Add Children\n",
    "                    l_overlap.r = max(l_overlap.r, mapped_bounds[bound].r)\n",
    "                    l_overlap.children.append(mapped_bounds[bound])\n",
    "                    self.units = self.units[:l_overlap_i+1] + self.units[r_overlap_i+1:]\n",
    "                    \n",
    "            else:\n",
    "                self.units = self.units[:l_overlap_i] + self.units[r_overlap_i+1:]\n",
    "                self.units.insert(l_overlap_i, mapped_bounds[bound])\n",
    "\n",
    "        return self.units\n",
    "        \n",
    "    def identify(self, sep):\n",
    "        lists = self.find_lists(sep)\n",
    "        lists = self.clean_lists(lists)\n",
    "        lists = self.bound_lists(lists)\n",
    "        lists = self.merge_lists(lists)\n",
    "        return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "ca0f4319-9599-4d2d-be36-9a29f3f1ba8a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Units:\n",
    "    def __init__(self, main):\n",
    "        self.main = main\n",
    "        self.unit_map = {}\n",
    "        \n",
    "    def update(self):\n",
    "        self.unit_map = self.load_full_unit_map()\n",
    "\n",
    "    def load_full_unit_map(self):\n",
    "        unit_map = {}\n",
    "        \n",
    "        for sent in self.main.sp_doc.sents:\n",
    "            sent_tokens = list(sent)\n",
    "            sent_unit_map = self.load_units(sent_tokens)\n",
    "            unit_map.update(sent_unit_map)\n",
    "        \n",
    "        return unit_map\n",
    "\n",
    "    def load_unit_map(self, ent):\n",
    "        ent_map = {}\n",
    "        if ent.l != -1:\n",
    "            ent_map[(ent.l, ent.r)] = ent\n",
    "\n",
    "        # Add Children\n",
    "        for child in ent.children:\n",
    "            child_ent_map = self.load_unit_map(child)\n",
    "            ent_map.update(child_ent_map)\n",
    "        \n",
    "        return ent_map\n",
    "    \n",
    "    def load_units(self, tokens, load_clauses=True):\n",
    "        units = []\n",
    "        for token in tokens:\n",
    "            unit = Unit(\n",
    "                self.main.sp_doc, \n",
    "                l=token.i, \n",
    "                r=token.i\n",
    "            )\n",
    "            units.append(unit)\n",
    "\n",
    "        # Enclosures\n",
    "        # These are extracted first due to their\n",
    "        # simplicity.\n",
    "        units = Quotes(self.main, units).identify()\n",
    "        units = Brackets(self.main, units).identify()\n",
    "\n",
    "        # These class of units can be put inside a larger\n",
    "        # unit (which makes it hard to know where they are\n",
    "        # later on). Thus, they're stored in this variable for\n",
    "        # later use in the list identification.\n",
    "        enclosures = []\n",
    "        for unit in units:\n",
    "            if unit.label_has([\n",
    "                Unit.BRACKETS, \n",
    "                Unit.QUOTE\n",
    "            ]):\n",
    "                enclosures.append(unit)\n",
    "        \n",
    "        # Find Partioning Separator\n",
    "        # If a sentence uses the below structure:\n",
    "        # \"When ... , .... ; therefore, ... .\"\n",
    "        # There is a hierarchical structure between\n",
    "        # the semicolons and commas where the former\n",
    "        # nests the latter. Therefore, we find the\n",
    "        # higher-ranking separator (which would be\n",
    "        # the semicolon, if there's any) to use for\n",
    "        # further separation.\n",
    "        sep = \",\"\n",
    "        for unit in units:\n",
    "            if \";\" == unit.lower()[0]:\n",
    "                sep = \";\"\n",
    "                break\n",
    "\n",
    "        # Separators and Colons\n",
    "        # The separators here also include conjunctions and\n",
    "        # the use of both conjunctions and punctuation.\n",
    "        units = Separators(self.main, units).identify()\n",
    "        units = Colons(self.main, units).identify()\n",
    "\n",
    "        if load_clauses:\n",
    "            units = Prepositional_Phrases(self.main, units).identify()\n",
    "            units = Dependent_Clauses(self.main, units).identify(sep)\n",
    "            units = Independent_Clauses(self.main, units).identify([Unit.END])\n",
    "        \n",
    "        units = Lists(self.main, units, enclosures).identify(sep)\n",
    "\n",
    "        # There is some overlap between lists and independent\n",
    "        # clauses because they both can use \", [AND/OR]\", but\n",
    "        # after the lists are identified, we can assume the\n",
    "        # remaining \", [AND/OR]\" are parts of independent \n",
    "        # clauses.\n",
    "        if load_clauses:\n",
    "            units = Independent_Clauses(self.main, units).identify([Unit.AND_OR_END])\n",
    "\n",
    "        # Merge Ungrouped Entities\n",
    "        i = 0\n",
    "        while i < len(units):\n",
    "            if not units[i].label:\n",
    "                while i + 1 < len(units) and (not units[i+1].label or units[i+1].label_has([Unit.CONJ])):\n",
    "                    units.pop(i+1)\n",
    "                    units[i].r += 1\n",
    "                units[i].label = [Unit.FRAGMENT]\n",
    "            i += 1\n",
    "\n",
    "        # Remove Fragments\n",
    "        # If we're already parsing a fragment\n",
    "        # (indicated by load_clauses = False), we\n",
    "        # should not add meaningless, duplicate fragments.\n",
    "        if not load_clauses:\n",
    "            units = [ent for ent in units if ent.label != [Unit.FRAGMENT]]\n",
    "        \n",
    "        # Map Entities\n",
    "        # This map lists the units, the units' children,\n",
    "        # those childrens' children, and so on, in a convenient\n",
    "        # manner, arguably. It all starts with one unit, which\n",
    "        # we have as the \"parent\". It encapsulates the units\n",
    "        # we want to list.\n",
    "        parent = Unit(self.main.sp_doc, l=-1, r=-1, children=units)\n",
    "        parent_ent_map = self.load_unit_map(parent)\n",
    "        \n",
    "        for unit in units:\n",
    "            unit_tokens = [*unit.span()]\n",
    "\n",
    "            visitable = unit.label_has([\n",
    "                Unit.I_CLAUSE, \n",
    "                Unit.D_CLAUSE, \n",
    "                Unit.FRAGMENT\n",
    "            ])\n",
    "            non_empty_subset = 2 < len(unit_tokens) < len(tokens)\n",
    "            \n",
    "            if not non_empty_subset or not visitable:\n",
    "                continue\n",
    "\n",
    "            unit_map = self.load_units(unit_tokens, load_clauses=False)\n",
    "            for k, v in unit_map.items():\n",
    "                parent_ent_map[k] = v\n",
    "            \n",
    "        return parent_ent_map\n",
    "\n",
    "    def units_at_i(self, i):\n",
    "        units = []\n",
    "        for k, v in self.unit_map.items():\n",
    "            if k[0] <= i <= k[1]:\n",
    "                units.append(v)\n",
    "        return units\n",
    "\n",
    "    def aggregate_units(self, aggregate_labels=[Unit.P_PHRASE, Unit.LIST]):\n",
    "        unit_bounds = list(self.unit_map.keys())\n",
    "        distinct_unit_bounds = self.main.distinct_bounds(unit_bounds)\n",
    "        units = [unit[1] for unit in self.unit_map.items() if unit[0] in distinct_unit_bounds]\n",
    "\n",
    "        i = 0\n",
    "        tokens = []\n",
    "        units_tokens = []\n",
    "        \n",
    "        while i < len(units):\n",
    "            unit = units[i]\n",
    "            tokens.extend(list(unit.span()))\n",
    "\n",
    "            next_unit = None if i+1 >= len(units) else units[i+1]\n",
    "            \n",
    "            if next_unit and next_unit.label_has(aggregate_labels):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            units_tokens.append(tokens)\n",
    "            tokens = []\n",
    "            \n",
    "            i += 1\n",
    "\n",
    "        if tokens:\n",
    "            units_tokens.append(tokens)\n",
    "\n",
    "        return units_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "053522d8-3910-427d-8137-dbd1804d27c4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(0, 5) (Dependent Clause) -> Who caused Craig to cry?\n",
      "(3, 4) (Prepositional Phrase) -> to cry\n"
     ]
    }
   ],
   "source": [
    "# import spacy\n",
    "# %run \"Helper.ipynb\"\n",
    "\n",
    "# class Main:\n",
    "#     def __init__(self):\n",
    "#         self.sp_nlp = spacy.load(\"en_core_web_lg\")\n",
    "#         self.sp_doc = self.sp_nlp(\"Who caused Craig to cry?\")\n",
    "\n",
    "# main = Main()\n",
    "# units = Units(main)\n",
    "\n",
    "# unit_map = units.load_full_unit_map()\n",
    "# unit_map_bounds = unit_map.keys()\n",
    "# unit_map_bounds = sorted(unit_map_bounds)\n",
    "\n",
    "# for bound in unit_map_bounds:\n",
    "#     unit = unit_map[bound]\n",
    "#     print(f\"({unit.l}, {unit.r}) ({unit.label_()}) -> {main.sp_doc[unit.l:unit.r+1]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "53db30d8-619d-4e79-9d58-fb9b26d85f68",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Who PRON\n",
      "caused VERB\n",
      "Craig PROPN\n",
      "to PART\n",
      "cry VERB\n",
      "? PUNCT\n"
     ]
    }
   ],
   "source": [
    "# for token in main.sp_doc:\n",
    "#     print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "031ff08c-2b87-4928-8290-437f0084f802",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fdbe019a-974b-487c-95bf-51a655655f08",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7675a3ac-edb8-4e7a-aa26-7ccd516bdc77",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8009756c-a12b-46bb-8af3-4c50b647a6ca",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7116e16f-676c-49ce-a814-d6eb9c3464cb",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4cbacf6a-f5f1-45b9-a071-ec1168bbb188",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53becc74-7bfb-4c2d-9976-29ab7b4f3621",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "006e78db-b3af-4d1e-b297-ba18c3edc0f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "770ccf49-13d5-405b-b882-ea151a175fbf",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "829ab584-38fc-44e1-b3bb-8653db64ecdc",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8030b03b-1a65-4533-8f93-b4d38ad07758",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b59125b3-01c0-4358-9aad-d85686244f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "168bba88-cc86-4228-9b43-17d05b5cd8a9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "47bd4e97-57fa-4870-98be-8fba0f0a28b1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ea2d061b-3862-4e04-a137-07129e1615af",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1192bb4c-9b0c-4e4d-89ce-bda46e3b79fe",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "20e5e9ce-ea63-466b-b0b6-b940ae0d763d",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
