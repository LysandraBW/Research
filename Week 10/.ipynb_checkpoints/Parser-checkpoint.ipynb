{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "cbad3bc0-44ed-4f26-a445-ad4a2e027b7b",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import time\n",
    "import spacy\n",
    "import textacy\n",
    "from fastcoref import FCoref\n",
    "from taxonerd import TaxoNERD\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import DependencyMatcher, PhraseMatcher\n",
    "from pprint import pprint\n",
    "import requests"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "e5a08af5-045d-4b57-8c9f-a543f5115832",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "spacy.require_gpu()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "960be1f2-9233-459d-8217-1d9848776472",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Tools:\n",
    "    def __init__(self, *, text=None):\n",
    "        # Tools\n",
    "        self.sp_nlp = spacy.load(\"en_core_web_trf\")\n",
    "        self.sp_doc = None\n",
    "        self.tn_nlp = TaxoNERD().load(model=\"en_ner_eco_biobert\")\n",
    "        self.tn_doc = None\n",
    "        self.fcoref = FCoref(device='cuda:0', enable_progress_bar=False)\n",
    "        self.token_map = None\n",
    "        if text:\n",
    "            self.update(text)\n",
    "\n",
    "    @staticmethod\n",
    "    def clean_text(text):\n",
    "        cleaned_text = re.sub(\"[\\(\\[].*?[\\)\\]]\", \"\", text)\n",
    "        cleaned_text = re.sub(\"\\s+\", \" \", cleaned_text)\n",
    "        cleaned_text = re.sub(r\"\\s+([?.!,])\", r\"\\1\", cleaned_text)\n",
    "        return cleaned_text\n",
    "        \n",
    "    def update(self, text):\n",
    "        self.sp_doc = self.sp_nlp(text)\n",
    "        self.tn_doc = self.tn_nlp(text)\n",
    "        # Map Tokens to Index\n",
    "        self.token_map = {}\n",
    "        for token in self.sp_doc:\n",
    "            self.token_map[token.idx] = token.i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "3d6711e0-ee21-47d0-ade1-e15515725ebc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class References:\n",
    "    def __init__(self, tools, texts=None):\n",
    "        self.tools = tools\n",
    "        self.predictions = None\n",
    "        self.cluster_map = None\n",
    "        if texts:\n",
    "            self.update(texts)\n",
    "\n",
    "    def update(self, texts):\n",
    "        if not self.tools.sp_doc:\n",
    "            return\n",
    "        self.predictions = self.tools.fcoref.predict(texts=texts)\n",
    "        self.cluster_map = self.get_cluster_map(self.predictions)\n",
    "        \n",
    "    def get_cluster_map(self, predictions):\n",
    "        cluster_map = {}\n",
    "        for prediction in predictions:\n",
    "            clusters = prediction.get_clusters(as_strings=False)\n",
    "            for cluster in clusters:\n",
    "                # Converting the spans in a cluster to tokens.\n",
    "                # This makes it easier when using it later.\n",
    "                token_cluster = []\n",
    "                for span in cluster:\n",
    "                    if span[0] not in self.tools.token_map:\n",
    "                        raise Exception(\"Invalid Token\")\n",
    "                    index = self.tools.token_map[span[0]]\n",
    "                    token_cluster.append(self.tools.sp_doc[index])\n",
    "                # Mapping\n",
    "                for token in token_cluster:\n",
    "                    cluster_map[token.i] = list(filter(lambda t: t != token, token_cluster))\n",
    "        return cluster_map\n",
    "            \n",
    "    def get_references(self, tokens):\n",
    "        refs = []\n",
    "        for token in tokens:\n",
    "            index = token.i\n",
    "            if index in self.cluster_map:\n",
    "                refs += self.cluster_map[index]\n",
    "        return refs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "9d07f01e-584a-453c-8dca-153d5c6556cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Possession:\n",
    "    # There's no definite names for these patterns as I do not know what\n",
    "    # to call them. These patterns are used to extract possessive\n",
    "    # relationships from a sentence. I also could not find better names for\n",
    "    # the two variables below.\n",
    "    OWNER = \"owner\"\n",
    "    OWNED = \"owned\"\n",
    "    \n",
    "    patterns = {\n",
    "        \"Pattern1\": [\n",
    "            {\n",
    "                \"RIGHT_ID\": OWNED,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"POS\": {\n",
    "                        \"IN\": [\"NOUN\", \"PROPN\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": OWNED,\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNER,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"poss\"\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"Pattern2\": [\n",
    "             {\n",
    "                \"RIGHT_ID\": OWNED,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"POS\": {\n",
    "                        \"IN\": [\"NOUN\", \"PROPN\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": OWNED,\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"adp\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"prep\",\n",
    "                    \"POS\": {\n",
    "                        \"IN\": [\"ADP\"]\n",
    "                    }\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"adp\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNER,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"pobj\",\n",
    "                    \"POS\": {\n",
    "                        \"IN\": [\"NOUN\", \"PROPN\"]\n",
    "                    }\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"Pattern3\": [\n",
    "            {\n",
    "                \"RIGHT_ID\": \"verb\",\n",
    "                \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"verb\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNER,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"nsubj\",\n",
    "                    \"POS\": {\"IN\": [\"PRON\"]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"verb\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNED,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"dobj\",\n",
    "                    \"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "        \"Pattern4\": [\n",
    "            {\n",
    "                \"RIGHT_ID\": \"verb\",\n",
    "                \"RIGHT_ATTRS\": {\"POS\": {\"IN\": [\"VERB\"]}}\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"verb\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNED,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"nsubj\",\n",
    "                    \"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"verb\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": \"adp\",\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"prep\",\n",
    "                    \"POS\": {\"IN\": [\"ADP\"]}\n",
    "                }\n",
    "            },\n",
    "            {\n",
    "                \"LEFT_ID\": \"adp\",\n",
    "                \"REL_OP\": \">\",\n",
    "                \"RIGHT_ID\": OWNER,\n",
    "                \"RIGHT_ATTRS\": {\n",
    "                    \"DEP\": \"pobj\",\n",
    "                    \"POS\": {\"IN\": [\"NOUN\", \"PROPN\"]}\n",
    "                }\n",
    "            }\n",
    "        ],\n",
    "    }\n",
    "    \n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "        self.matcher = DependencyMatcher(self.tools.sp_nlp.vocab)\n",
    "        for pattern_id, pattern in Possession.patterns.items():\n",
    "            self.matcher.add(pattern_id, [pattern])\n",
    "        self.owner_map = None\n",
    "        self.owned_map = None\n",
    "        self.update()\n",
    "    \n",
    "    def update(self):\n",
    "        if not self.tools.sp_doc:\n",
    "            return\n",
    "        matches = self.matcher(self.tools.sp_doc)\n",
    "        owner_map, owned_map = self.get_ownership_map(matches)\n",
    "        self.owner_map = owner_map # Maps Owner to Owned\n",
    "        self.owned_map = owned_map # Maps Owned to Owner\n",
    "        \n",
    "    def get_ownership_map(self, matches):\n",
    "        owner_map = {}\n",
    "        owned_map = {}\n",
    "\n",
    "        for match_id, token_ids in matches:\n",
    "            pattern_id = self.tools.sp_nlp.vocab.strings[match_id]\n",
    "            # print(pattern_id)\n",
    "            owner = None\n",
    "            owned = None\n",
    "            for i in range(len(token_ids)):\n",
    "                right_id = Possession.patterns[pattern_id][i][\"RIGHT_ID\"]\n",
    "                if right_id == Possession.OWNER:\n",
    "                    owner = self.tools.sp_doc[token_ids[i]]\n",
    "                if right_id == Possession.OWNED:\n",
    "                    owned = self.tools.sp_doc[token_ids[i]]\n",
    "\n",
    "            # Owner to Owned\n",
    "            if owner.i not in owner_map:\n",
    "                owner_map[owner.i] = []\n",
    "            owner_map[owner.i].append(owned)\n",
    "\n",
    "            # Owned to Owner\n",
    "            if owned.i not in owned_map:\n",
    "                owned_map[owned.i] = []\n",
    "            owned_map[owned.i].append(owner)\n",
    "            \n",
    "        return (owner_map, owned_map)\n",
    "\n",
    "    def get_owner(self, tokens):\n",
    "        owners = []\n",
    "        for token in tokens:\n",
    "            index = token.i\n",
    "            if index in self.owned_map:\n",
    "                owners += self.owned_map[index]\n",
    "        return owners\n",
    "\n",
    "    def get_owned(self, tokens):\n",
    "        owned = []\n",
    "        for token in tokens:\n",
    "            index = token.i\n",
    "            if index in self.owner_map:\n",
    "                owned += self.owner_map[index]\n",
    "        return owned"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b0d752ef-11de-4c19-a0cc-b5c32a199dc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit:\n",
    "    def __init__(self, *, species=None, trait=None, change=None, cause=None):\n",
    "        self.species = species\n",
    "        self.trait = trait\n",
    "        self.cause = cause\n",
    "        self.change = change\n",
    "        # Flag\n",
    "        self.is_cause = False\n",
    "\n",
    "    def empty(self):\n",
    "        if not self.species and not self.trait and not self.cause and not self.change:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def not_empty(self):\n",
    "        return not self.empty()\n",
    "\n",
    "    def can_merge(self, unit):\n",
    "        # Two units can merge if there's no\n",
    "        # overlap.\n",
    "        if self.species and unit.species:\n",
    "            return False\n",
    "        if self.trait and unit.trait:\n",
    "            return False\n",
    "        if self.cause and unit.cause:\n",
    "            return False\n",
    "        if self.change and unit.change:\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def merge(self, unit):\n",
    "        # We take the parts that the\n",
    "        # other unit has; assuming that\n",
    "        # there's no overlap, there's\n",
    "        # no loss of information.\n",
    "        if unit.species:\n",
    "            self.species = unit.species\n",
    "        if unit.trait:\n",
    "            self.trait = unit.trait\n",
    "        if unit.cause:\n",
    "            self.cause = unit.cause\n",
    "        if unit.change:\n",
    "            self.change = unit.change\n",
    "\n",
    "    def get_score(self):\n",
    "        score = 0\n",
    "        if self.species:\n",
    "            score += 1\n",
    "        if self.trait:\n",
    "            score += 1\n",
    "        if self.cause:\n",
    "            score += 1\n",
    "        if self.change:\n",
    "            score += 1    \n",
    "        return score\n",
    "    def __str__(self):\n",
    "        return f\"Species: {self.species}, Trait: {self.trait}, Cause: ({self.cause}), Change: {self.change}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "47b3361d-db39-43bb-bc44-aa4edb4d97a6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species:\n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "        self.species_indices = None\n",
    "        self.update()\n",
    "\n",
    "    def update(self):\n",
    "        if not self.tools.sp_doc:\n",
    "            return\n",
    "        self.species_indices = self.get_species_indices()\n",
    "        \n",
    "    def get_species_indices(self):\n",
    "        indices = []\n",
    "\n",
    "        lowered_text = self.tools.sp_doc.text.lower()\n",
    "        # for token in self.tools.sp_doc:\n",
    "        #     if token.pos_ not in [\"NOUN\", \"PROPN\"]:\n",
    "        #         continue\n",
    "        #     try:\n",
    "        #         results = requests.get(f\"https://api.inaturalist.org/v1/search?q={token.lemma_}&sources=taxa&include_taxon_ancestors=false\")\n",
    "        #         results = results.json()\n",
    "        #         results = results[\"results\"]\n",
    "        #         for result in results:\n",
    "        #             if \"record\" not in result or \"name\" not in result[\"record\"]:\n",
    "        #                 continue\n",
    "        #             if lowered_text.find(result[\"record\"][\"name\"].lower()) == -1:\n",
    "        #                 continue\n",
    "        #             indices.append(token.i)\n",
    "        #     except Exception as e:\n",
    "        #         print(\"Network Error\")\n",
    "                \n",
    "        for species_span in self.tools.tn_doc.ents:\n",
    "            for species in species_span:\n",
    "                if species.idx not in self.tools.token_map:\n",
    "                    raise Exception(\"Invalid Token\")\n",
    "                index = self.tools.token_map[species.idx]\n",
    "                if index in indices:\n",
    "                    continue\n",
    "                indices.append(index)\n",
    "        return indices\n",
    "\n",
    "    def is_species(self, token):\n",
    "        index = token.i\n",
    "        return index in self.species_indices\n",
    "        \n",
    "    def contains_species(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token.i in self.species_indices:\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "b95190af-07ec-46f0-ad6d-6b0b784408a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keywords:    \n",
    "    def __init__(self, tools):\n",
    "        self.tools = tools\n",
    "        # References\n",
    "        self.unit_keywords = [self.tools.sp_nlp(keyword) for keyword in {\"unit\", \"%\", \"percent\"}]\n",
    "        self.change_keywords = [self.tools.sp_nlp(keyword) for keyword in {\"increase\", \"decrease\", \"change\", \"weaken\", \"shift\", \"cause\"}]\n",
    "        self.quantity_keywords = [self.tools.sp_nlp(keyword) for keyword in {\"tenfold\", \"half\", \"double\", \"triple\", \"quadruple\", \"one\", \"two\", \"three\", \"four\", \"five\", \"six\", \"seven\", \"eight\", \"nine\", \"ten\"}]\n",
    "        # Instances\n",
    "        self.unit_indices = []\n",
    "        self.change_indices = []\n",
    "        self.quantity_indices = []\n",
    "        self.cause_indices = []\n",
    "        self.update()\n",
    "        \n",
    "    def update(self):\n",
    "        if not self.tools.sp_doc:\n",
    "            return\n",
    "        self.unit_indices = self.load_unit_indices()\n",
    "        self.change_indices = self.load_change_indices()\n",
    "        self.quantity_indices = self.load_quantity_indices()\n",
    "        self.cause_indices = self.load_cause_indices()\n",
    "        return\n",
    "\n",
    "    def is_unit(self, token):\n",
    "        return token.i in self.unit_indices\n",
    "\n",
    "    def has_unit(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token.i in self.unit_indices:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def load_unit_indices(self):\n",
    "        indices = []\n",
    "        for token in self.tools.sp_doc:\n",
    "            if token.pos_ not in [\"NOUN\"]:\n",
    "                continue\n",
    "            lemma = self.tools.sp_nlp(token.lemma_)\n",
    "            for keyword in self.unit_keywords:\n",
    "                similarity = keyword.similarity(lemma)\n",
    "                # print(f\"{lemma} and {keyword} Similarity: {similarity}\")\n",
    "                if similarity > 0.7:\n",
    "                    indices.append(token.i)\n",
    "        return indices\n",
    "\n",
    "    def is_change(self, token):\n",
    "        return token.i in self.change_indices\n",
    "\n",
    "    def has_change(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token.i in self.change_indices:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def load_change_indices(self):\n",
    "        indices = []\n",
    "        for token in self.tools.sp_doc:\n",
    "            if token.lower_ == \"to\" and token.head and token.head.lower_ == \"from\":\n",
    "                indices.append(token.i)\n",
    "                continue\n",
    "            if token.pos_ not in [\"NOUN\", \"VERB\"]:\n",
    "                continue\n",
    "            lemma = self.tools.sp_nlp(token.lemma_)\n",
    "            for keyword in self.change_keywords:\n",
    "                similarity = keyword.similarity(lemma)\n",
    "                # print(f\"{lemma} and {keyword} Similarity: {similarity}\")\n",
    "                if similarity > 0.7:\n",
    "                    indices.append(token.i)\n",
    "        return indices\n",
    "\n",
    "    def is_quantity(self, token):\n",
    "        return token.i in self.quantity_indices\n",
    "\n",
    "    def has_quantity(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token.i in self.quantity_indices:\n",
    "                return True\n",
    "        return False\n",
    "        \n",
    "    def load_quantity_indices(self):\n",
    "        indices = []\n",
    "        for token in self.tools.sp_doc:\n",
    "            if token.pos_ not in [\"NOUN\", \"NUM\"]:\n",
    "                continue\n",
    "            lemma = self.tools.sp_nlp(token.lemma_)\n",
    "            for keyword in self.quantity_keywords:\n",
    "                similarity = keyword.similarity(lemma)\n",
    "                # print(f\"{lemma} and {keyword} Similarity: {similarity}\")\n",
    "                if similarity > 0.7:\n",
    "                    # Make sure that if there is a noun the quantity\n",
    "                    # modifies, that it is a unit.\n",
    "                    if token.head and token.head.pos_ == \"NOUN\" and not self.is_unit(token.head):\n",
    "                        continue\n",
    "                    indices.append(token.i)\n",
    "        return indices\n",
    "\n",
    "    def is_cause(self, token):\n",
    "        return token.i in self.cause_indices\n",
    "\n",
    "    def has_cause(self, tokens):\n",
    "        for token in tokens:\n",
    "            if token.i in self.cause_indices:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "    def load_cause_indices(self):\n",
    "        indices = []\n",
    "        for token in self.tools.sp_doc:\n",
    "            if token.pos_ not in [\"ADP\", \"SCONJ\", \"PART\", \"PRON\"]:\n",
    "                continue\n",
    "            # print(token, token.pos_)\n",
    "            if token.pos_ == \"SCONJ\":\n",
    "                # print(\"It's a SCONJ\")\n",
    "                indices.append(token.i)\n",
    "                continue\n",
    "            elif token.pos_ == \"PART\":\n",
    "                if token.head and token.head.pos_ == \"VERB\":\n",
    "                    # print(\"It's a PART + VERB\")\n",
    "                    indices.append(token.i)\n",
    "                    continue\n",
    "            elif token.pos_ == \"ADP\":\n",
    "                if token.lower_ == \"due\" and self.tools.sp_doc[token.i + 1] and self.tools.sp_doc[token.i + 1].lower_ == \"to\":\n",
    "                    # print(\"It's a DUE TO\")\n",
    "                    indices.append(token.i)\n",
    "                    continue\n",
    "                elif token.head:\n",
    "                    if token.head.pos_ == \"AUX\":\n",
    "                        # print(\"The head is an AUX\")\n",
    "                        indices.append(token.i)\n",
    "                        continue\n",
    "                    elif token.head.pos_ == \"VERB\" and token.head.i < token.i and self.is_change(token.head):\n",
    "                        # print(\"The head is a change-VERB\")\n",
    "                        indices.append(token.i)\n",
    "                        continue\n",
    "                    elif token.lower_ != \"to\" and \"AUX\" in [child.pos_ for child in list(filter(lambda t: t.i < token.i,token.head.children))]:\n",
    "                        # print(\"There's an AUX in the head's children\")\n",
    "                        # for child in token.head.children:\n",
    "                            # print(f\"\\t\\t{child}, {child.pos_}\")\n",
    "                        indices.append(token.i)\n",
    "                        continue\n",
    "                elif token.ancestors:\n",
    "                    # print(\"There's an AUX ancestor\")\n",
    "                    if \"AUX\" in [ancestor.pos_ for ancestor in token.ancestors]:\n",
    "                        indices.append(token.i)\n",
    "                        continue\n",
    "            elif token.pos_ == \"PRON\":\n",
    "                if token.head and token.head.pos_ == \"VERB\" and self.is_change(token.head):\n",
    "                    indices.append(token.i)\n",
    "                    continue\n",
    "        return indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "fc5cc71f-45c1-4cd7-b446-1e25b4468ae6",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self, *, text=None, tools=None, species=None, possession=None, references=None, keywords=None):\n",
    "        self.tools = tools if tools else Tools(text=text)\n",
    "        self.species = species if species else Species(self.tools)\n",
    "        self.possession = possession if possession else Possession(self.tools)\n",
    "        self.references = references if references else References(self.tools, texts=list(filter(lambda t: t is not None,[text])))\n",
    "        self.keywords = keywords if keywords else Keywords(self.tools)\n",
    "            \n",
    "    def update(self, text):\n",
    "        self.tools.update(text)\n",
    "        self.species.update()\n",
    "        self.possession.update()\n",
    "        self.references.update(texts=[text])\n",
    "        self.keywords.update()\n",
    "                \n",
    "    def parse_segment(self, l_i, r_i):\n",
    "        # print(f\"\\nPARSING SEGMENT\\n\")\n",
    "        # print(f\"Text: {self.tools.sp_doc[l_i:r_i+1].text}\")\n",
    "        used = []\n",
    "\n",
    "        # Find Cause\n",
    "        cause = []\n",
    "        for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "            if token not in used and token.pos_ in [\"SCONJ\"] and self.keywords.is_cause(token):\n",
    "                start_i = token.i + 1\n",
    "                end_i = start_i\n",
    "                while end_i <= r_i and self.tools.sp_doc[end_i] not in used and self.tools.sp_doc[end_i].pos_ in [\"ADP\", \"DET\", \"NOUN\", \"PROPN\", \"AUX\", \"ADV\", \"PRON\", \"ADJ\"]:\n",
    "                    used.append(self.tools.sp_doc[end_i])\n",
    "                    cause.append(self.tools.sp_doc[end_i])\n",
    "                    end_i += 1\n",
    "                used.append(token)\n",
    "        # print(f\"Cause 1: {cause}\")\n",
    "        \n",
    "        # Find Species\n",
    "        species = []\n",
    "        for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "            if self.species.is_species(token) and token not in used and (token.head and (token.head.pos_ not in [\"SCONJ\", \"ADP\"] or token.head.lower_ == \"of\")):\n",
    "                species.append(token)\n",
    "                used.append(species)\n",
    "                break\n",
    "        # print(f\"Species: {species}\")\n",
    "        \n",
    "        # Find Change\n",
    "        change = []\n",
    "        for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "            if token not in used and not token.is_oov:\n",
    "                if self.keywords.is_change(token):\n",
    "                    change.append(token)\n",
    "                    used.append(token)\n",
    "            # I only want one word that represents\n",
    "            # the change for simplicity\n",
    "            if change:\n",
    "                break\n",
    "        # print(f\"Change 1: {change}\")\n",
    "\n",
    "        # Next Method to Find Change\n",
    "        for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "            if token not in used and token.pos_ == \"ADP\" and token.lower_ != \"of\":\n",
    "                # print(\"In Next Method...\", token, token not in used, token.pos_)\n",
    "                start_i = token.i + 1\n",
    "                end_i = start_i\n",
    "                possible_changes = []\n",
    "                while end_i <= r_i and self.tools.sp_doc[end_i].pos_ in [\"NUM\", \"SYM\", \"NOUN\", \"ADP\", \"DET\"]:\n",
    "                    possible_changes.append(self.tools.sp_doc[end_i])\n",
    "                    end_i += 1\n",
    "                if not self.keywords.has_quantity(possible_changes):\n",
    "                    continue\n",
    "                # print(f\"Actual Changes: {possible_changes}\")\n",
    "                for possible_change in possible_changes:\n",
    "                    used.append(possible_change)\n",
    "                    change.append(possible_change)\n",
    "                used.append(token)\n",
    "                break\n",
    "        # print(f\"Change 2: {change}\")\n",
    "\n",
    "        # Find Trait\n",
    "        trait = []\n",
    "        if species:\n",
    "            possible_traits = list(filter(lambda t: t.i >= l_i and t.i <= r_i, self.possession.get_owned(species)))\n",
    "            valid_trait = False\n",
    "            for possible_trait in possible_traits:\n",
    "                for ancestor in possible_trait.ancestors:\n",
    "                    if self.keywords.is_change(ancestor):\n",
    "                        valid_trait = True\n",
    "                        break\n",
    "            if valid_trait:\n",
    "                trait = possible_traits\n",
    "        elif change:\n",
    "            # The trait is listed before the change (i.e. \"diet shifts from ...\")\n",
    "            prev_i = change[0].i - 1\n",
    "            prev_token = None if prev_i < 0 else self.tools.sp_doc[prev_i]\n",
    "            if prev_token and prev_token not in used and prev_token.pos_ == \"NOUN\":\n",
    "                used.append(prev_token)\n",
    "                trait.append(prev_token)\n",
    "            else:\n",
    "                # Look for \"in\" (i.e. \"increase in ...\")\n",
    "                for child in change[0].children:\n",
    "                    # print(child, child.pos_, child.children)\n",
    "                    if child in used:\n",
    "                        continue\n",
    "                    if child.pos_ == \"ADP\" and child.children:\n",
    "                        children = list(child.children)\n",
    "                        if children[0] not in used:\n",
    "                            used.append(children[0])\n",
    "                            trait.append(children[0])\n",
    "        else:\n",
    "            for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "                if token.head and self.keywords.is_change(token.head):\n",
    "                    trait.append(token)\n",
    "                    used.append(token)\n",
    "\n",
    "                    possible_species = self.possession.get_owner(trait)\n",
    "                    if self.species.contains_species(possible_species):\n",
    "                        for sp in possible_species:\n",
    "                            if token in sp.ancestors:\n",
    "                                species.append(sp)\n",
    "                                used.append(sp)\n",
    "                                break\n",
    "                    break\n",
    "        # print(f\"Trait: {trait}\")\n",
    "        \n",
    "        # Find Cause\n",
    "        is_cause = False\n",
    "        for token in self.tools.sp_doc[l_i:r_i+1]:\n",
    "            if token not in used and token.pos_ in [\"PRON\"] and self.keywords.is_cause(token):\n",
    "                is_cause = True\n",
    "                used.append(token)\n",
    "            elif token not in used and token.pos_ in [\"ADP\"] and self.keywords.is_cause(token):\n",
    "                start_i = token.i + 1\n",
    "                end_i = start_i\n",
    "                buffer = []\n",
    "                noun_found = False\n",
    "                while end_i <= r_i and self.tools.sp_doc[end_i] not in used and self.tools.sp_doc[end_i].pos_ in [\"ADP\", \"DET\", \"NOUN\", \"PROPN\", \"AUX\", \"ADV\", \"PRON\", \"ADJ\"]:\n",
    "                    if self.tools.sp_doc[end_i].pos_ in [\"NOUN\", \"PROPN\", \"PRON\"]:\n",
    "                        noun_found = True\n",
    "                    buffer.append(self.tools.sp_doc[end_i])\n",
    "                    end_i += 1\n",
    "                if noun_found:\n",
    "                    for token in buffer:\n",
    "                        used.append(token)\n",
    "                        cause.append(token)\n",
    "                    used.append(token)\n",
    "        # print(f\"Cause 2: {cause}\")\n",
    "        \n",
    "        unit = Unit(species=species, trait=trait, change=change, cause=cause)\n",
    "        unit.is_cause = is_cause\n",
    "        return unit\n",
    "\n",
    "    def parse_sentence(self, l_i, r_i):\n",
    "        units = []\n",
    "        \n",
    "        # Recursive Split\n",
    "        # We're extracting the core information\n",
    "        # in the sentence into units.\n",
    "        def recursive_split(r_l_i, r_r_i):\n",
    "            nonlocal units\n",
    "            # Find Verb\n",
    "            # The verb is used to divide\n",
    "            # the \"parsing\" space, which\n",
    "            # makes the work simpler.\n",
    "            verb = None\n",
    "            for token in self.tools.sp_doc[r_l_i:r_r_i+1]:\n",
    "                if token.pos_ == \"VERB\":\n",
    "                    verb = token\n",
    "                    break\n",
    "    \n",
    "            # Base Case\n",
    "            # If there is no verb, we have\n",
    "            # reached the simplest case and\n",
    "            # can extract information.\n",
    "            if verb == None:\n",
    "                units.append(self.parse_segment(r_l_i, r_r_i))\n",
    "            else:\n",
    "                recursive_split(r_l_i, verb.i - 1)\n",
    "                units.append(verb)\n",
    "                recursive_split(verb.i + 1, r_r_i)\n",
    "            return\n",
    "        recursive_split(l_i, r_i)\n",
    "\n",
    "        # Recursive Merge\n",
    "        # We are putting the pieces back together,\n",
    "        # so that we, the computer, can understand\n",
    "        # what's going on.\n",
    "        def recursive_merge():\n",
    "            nonlocal units\n",
    "            if len(units) < 3:\n",
    "                return\n",
    "            \n",
    "            l_unit = units[0]\n",
    "            verb = units[1]\n",
    "            r_unit = units[2]\n",
    "            verb_is_change = self.keywords.is_change(verb)\n",
    "            \n",
    "            if l_unit.empty() and r_unit.empty():\n",
    "                m_unit = Unit()  \n",
    "            elif l_unit.not_empty() and r_unit.empty():\n",
    "                # print(1)\n",
    "                if verb_is_change:\n",
    "                    l_unit.change.append(verb)\n",
    "                m_unit = l_unit\n",
    "            elif r_unit.not_empty() and l_unit.empty():\n",
    "                # print(2)\n",
    "                if verb_is_change:\n",
    "                    r_unit.change.append(verb)\n",
    "                m_unit = r_unit    \n",
    "            elif l_unit.can_merge(r_unit):\n",
    "                # print(3)\n",
    "                l_unit.merge(r_unit)\n",
    "                if verb_is_change:\n",
    "                    l_unit.change.append(verb)\n",
    "                m_unit = l_unit\n",
    "            elif verb_is_change:\n",
    "                # print(4)\n",
    "                r_unit.cause = l_unit\n",
    "                if verb_is_change:\n",
    "                    r_unit.change.append(verb)\n",
    "                m_unit = r_unit\n",
    "            else:\n",
    "                # print(5)\n",
    "                if l_unit.get_score() >= r_unit.get_score():\n",
    "                    m_unit = l_unit\n",
    "                else:\n",
    "                    m_unit = r_unit\n",
    "            units = [m_unit] + units[3:]\n",
    "            recursive_merge()\n",
    "            return\n",
    "        recursive_merge()\n",
    "\n",
    "        assert len(units) == 1\n",
    "        return units[0]\n",
    "\n",
    "    def parse(self):\n",
    "        units = []\n",
    "        for sent in self.tools.sp_doc.sents:\n",
    "            print(f\"Sentence: {self.tools.sp_doc[sent.start:sent.end].text}\")\n",
    "            unit = self.parse_sentence(sent.start, sent.end - 1)\n",
    "            print(unit)\n",
    "            units.append(unit)\n",
    "            print()\n",
    "        return units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9903d921-8cd0-4038-bfef-4d711540d921",
   "metadata": {},
   "outputs": [],
   "source": [
    "text00 = Tools.clean_text(\"Acridoidea exhibited significant diet shifts from grass to herbs (Kruskal-Wallis test, P 0.01, df 3) when they were in the presence of the comparatively sedentary species (the smaller Pisaurina and the larger Hogna) compared to controls without spiders (Fig. 2).\")\n",
    "text01 = Tools.clean_text(\"Our results show that phototrophs can indirectly decrease the population density of heterotrophic bacteria by modification of the nature of bacterial interactions with predators.\")\n",
    "text02 = Tools.clean_text(\"Our results show that Selachii can indirectly decrease the population density of Selachimorpha by modification of the nature of bacterial interactions with predators.\")\n",
    "text03 = Tools.clean_text(\"All predators inflicted significant mortality on the prey at each prey density compared to the predator-free control for that density\")\n",
    "text04 = Tools.clean_text(\"Our results show that an increase in sediment organic matter content is associated to a decline in the abundance of Loripes lucinalis (lucinid bivalve) in the Cymodocea nodosa meadows studied, which potentially may weaken the mutualism between the two species.\")\n",
    "text05 = Tools.clean_text(\"The abundance of lucinids showed a negative correlation with the organic matter content in vegetated sediments (Fig. 3a), but showed no correlation in bare ones (Fig. 3b).\")\n",
    "text06 = Tools.clean_text(\"The MANOVA on the cattle tank experiment showed that the presence of Tramea, nonlethal Anax, and large bullfrog tadpoles all had significant effects on both small tadpole species (Table 1).\")\n",
    "text07 = Tools.clean_text(\"Thus the presence of predators, both nonlethal Anax and lethal Tramea, modified the tank environment in a way that facilitated invasion by midges, but only in the absence of large bullfrogs.\")\n",
    "text08 = Tools.clean_text(\"We hypothesized that the presence of Anax would decrease foraging activity of small tadpoles, which in turn would decrease predation by Tramea on the small tadpoles.\")\n",
    "text09 = Tools.clean_text('''Only a fraction of the individuals in a given prey population are likely to be killed and consumed by predators. In contrast, nearly all individuals experience the chronic effects of predation risk. When threatened by predators, prey adopt defensive tactics whole costs can lead to reduced growth, maturation rates, survivorship, fecundity, or population density. This nonconsumptive impact of predation risk on prey is known as a \"trait-mediated interaction\" (TMI) because it results from changes in prey traits such as behavior or physiology. Ecological theory suggests that the strength of TMI effects will reflect a balance between the conflicting demands of reproduction vs. predator avoidance. Competitor density and resource availability are expected to alter the balance between these conflicting forces. We conducted a meta-analysis of experimental studies that measured TMI effect size while varying competitor and/or resource density. The threat of predation had an overall negative effect on prey performance, but the strength of this effect varied with the level of competition. High competition exacerbated the negative effect of intimidation on prey density but moderated the negative effect of intimidation on prey life history and growth. We discuss these results in light of previously published theoretical expectations. Our results highlight the variable and context-dependent nature of interspecific interactions.''')\n",
    "text10 = Tools.clean_text(\"Current theory on trophic interactions in food webs assumes that ecologically similar species can be treated collectively as a single functional unit such as a guild or trophic level. This theory implies that all species within that unit transmit identical direct and indirect effects throughout the community. We evaluated this assumption by conducting experiments to compare the direct and indirect effects of three top-predator species, belonging to the same hunting spider guild, on the same species of grasshopper and on old-field grasses and herbs. Observations under field conditions revealed that each spider species exhibited different hunting behavior (i.e., sit-and-wait, sit-and-pursue, and active hunting) and occupied different locations within the vegetation canopy. These differences resulted in different direct effects on grasshopper prey. Grasshoppers demonstrated significant behavioral (diet) shifts in the presence of sit-and-wait and sit-and-pursue species but not when faced with actively hunting species. Grasshopper density was significantly reduced by spider species that occupied lower parts of the vegetation canopy (sit-and-pursue and actively hunting species), but it was not significantly reduced by the sit-and-wait spider species that occupied the upper parts of the canopy. These direct effects manifested themselves differently in the plant trophic level. The sit-and-wait spider caused indirect effects on plants by changing grasshopper foraging behavior (a trait-mediated effect). The sit-and-pursue spider caused indirect effects by reducing grasshopper density (density-mediated effects); the effects of changes in grasshopper behavior were thus not reflected in the plant trophic level. The actively hunting spiders had strictly density-mediated indirect effects on plants. The study offers mechanistic insight into how predator species within the same guild can have very different trophic effects in food webs. Thus classical modeling approaches that treat all predator species as a single functional unit may not adequately capture biologically relevant details that influence community dynamics.\")\n",
    "text11 = Tools.clean_text(\"Diversity and plasticity are hallmarks of cells of the monocyte-macrophage lineage. In response to IFNs, Toll-like receptor engagement, or IL-4/IL-13 signaling, macrophages undergo M1 (classical) or M2 (alternative) activation, which represent extremes of a continuum in a universe of activation states. Progress has now been made in defining the signaling pathways, transcriptional networks, and epigenetic mechanisms underlying M1-M2 or M2-like polarized activation. Functional skewing of mononuclear phagocytes occurs in vivo under physiological conditions (e.g., ontogenesis and pregnancy) and in pathology (allergic and chronic inflammation, tissue repair, infection, and cancer). However, in selected preclinical and clinical conditions, coexistence of cells in different activation states and unique or mixed phenotypes have been observed, a reflection of dynamic changes and complex tissue-derived signals. The identification of mechanisms and molecules associated with macrophage plasticity and polarized activation provides a basis for macrophage-centered diagnostic and therapeutic strategies.\")\n",
    "text12 = Tools.clean_text(\"This investigation examines the role of trait-mediated indirect interactions in a simple aquatic food web. We conducted the experiments in cattle watering tanks in order to establish whether competitive and predator-prey interactions between two species are affected by other species in the system; i.e., are pairwise interaction strengths affected by the background species assemblage? We examined the survival and growth response of small bullfrog (Rana catesbeiana) and small green frog (Rana clamitans) tadpoles in the presence and absence of a competitor (large bullfrogs), the lethal presence of the larval odonate predator Tramea lacerata,and the nonlethal (caged) presence of the larval odonate predators Anax junius and Anax longipes. We demonstrate that large bullfrog competitors and caged Anax affect traits (foraging activity level) of small bullfrog and small green frog tadpoles and that these changes in traits, in turn, affect interactions of the small tadpole species with each other and with the other species. In particular, the following four trait- mediated indirect interactions were evident: (1) Presence of large bullfrog competitors increased the predation rate of Trameaon small green frogs and small bullfrogs. (2) Presence of nonlethal Anax reduced the predation rate of Tramea on small green frogs. (3) Presence of nonlethal Anax increased the competitive advantage of bullfrogs over green frogs. (4) Presence of nonlethal Anax facilitated midge invasion of the experimental units. The pro- posed mechanisms (changes in small tadpole activity) involved in these trait-mediated indirect interactions were supported by observational data on tadpole activity and resource levels in the experimental units, and in laboratory experiments examining tadpole activity responses to predators. The occurrence of strong trait-mediated indirect interactions in this simple food web underscores the potential importance of such interactions in animal com- munities.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b54981fc-2d82-4ea6-942b-b37a15023624",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2025 10:47:54 - INFO - \t missing_keys: []\n",
      "05/04/2025 10:47:54 - INFO - \t unexpected_keys: []\n",
      "05/04/2025 10:47:54 - INFO - \t mismatched_keys: []\n",
      "05/04/2025 10:47:54 - INFO - \t error_msgs: []\n",
      "05/04/2025 10:47:54 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser Initialization Took 38.257277965545654s\n",
      "Text: This investigation examines the role of trait-mediated indirect interactions in a simple aquatic food web. We conducted the experiments in cattle watering tanks in order to establish whether competitive and predator-prey interactions between two species are affected by other species in the system; i.e., are pairwise interaction strengths affected by the background species assemblage? We examined the survival and growth response of small bullfrog and small green frog tadpoles in the presence and absence of a competitor, the lethal presence of the larval odonate predator Tramea lacerata,and the nonlethal presence of the larval odonate predators Anax junius and Anax longipes. We demonstrate that large bullfrog competitors and caged Anax affect traits of small bullfrog and small green frog tadpoles and that these changes in traits, in turn, affect interactions of the small tadpole species with each other and with the other species. In particular, the following four trait- mediated indirect interactions were evident: Presence of large bullfrog competitors increased the predation rate of Trameaon small green frogs and small bullfrogs. Presence of nonlethal Anax reduced the predation rate of Tramea on small green frogs. Presence of nonlethal Anax increased the competitive advantage of bullfrogs over green frogs. Presence of nonlethal Anax facilitated midge invasion of the experimental units. The pro- posed mechanisms involved in these trait-mediated indirect interactions were supported by observational data on tadpole activity and resource levels in the experimental units, and in laboratory experiments examining tadpole activity responses to predators. The occurrence of strong trait-mediated indirect interactions in this simple food web underscores the potential importance of such interactions in animal com- munities.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "05/04/2025 10:47:55 - INFO - \t Tokenize 1 inputs...\n",
      "Map: 100%|██████████| 1/1 [00:00<00:00, 17.12 examples/s]\n",
      "05/04/2025 10:47:56 - INFO - \t ***** Running Inference on 1 texts *****\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Parser Update Took 13.471240520477295s\n",
      "Sentence: This investigation examines the role of trait-mediated indirect interactions in a simple aquatic food web.\n",
      "\n",
      "Sentence: We conducted the experiments in cattle watering tanks in order to establish whether competitive and predator-prey interactions between two species are affected by other species in the system; i.e., are pairwise interaction strengths affected by the background species assemblage?\n",
      "\n",
      "Sentence: We examined the survival and growth response of small bullfrog and small green frog tadpoles in the presence and absence of a competitor, the lethal presence of the larval odonate predator Tramea lacerata,and the nonlethal presence of the larval odonate predators Anax junius and Anax longipes.\n",
      "\n",
      "Sentence: We demonstrate that large bullfrog competitors and caged Anax affect traits of small bullfrog and small green frog tadpoles and that these changes in traits, in turn, affect interactions of the small tadpole species with each other and with the other species.\n",
      "\n",
      "Sentence: In particular, the following four trait- mediated indirect interactions were evident: Presence of large bullfrog competitors increased the predation rate of Trameaon small green frogs and small bullfrogs.\n",
      "\n",
      "Sentence: Presence of nonlethal Anax reduced the predation rate of Tramea on small green frogs.\n",
      "\n",
      "Sentence: Presence of nonlethal Anax increased the competitive advantage of bullfrogs over green frogs.\n",
      "\n",
      "Sentence: Presence of nonlethal Anax facilitated midge invasion of the experimental units.\n",
      "\n",
      "Sentence: The pro- posed mechanisms involved in these trait-mediated indirect interactions were supported by observational data on tadpole activity and resource levels in the experimental units, and in laboratory experiments examining tadpole activity responses to predators.\n",
      "\n",
      "Sentence: The occurrence of strong trait-mediated indirect interactions in this simple food web underscores the potential importance of such interactions in animal com- munities.\n",
      "\n",
      "Parsing Took 0.0s\n",
      "Species: None, Trait: None, Cause: (None), Change: None\n",
      "Species: [species], Trait: [], Cause: ([the, background, species, assemblage]), Change: []\n",
      "Species: [bullfrog], Trait: [], Cause: ([]), Change: []\n",
      "Species: [Anax], Trait: [], Cause: ([large, bullfrog, competitors]), Change: []\n",
      "Species: [Trameaon], Trait: [In], Cause: ([]), Change: [increased]\n",
      "Species: [Anax], Trait: [], Cause: ([]), Change: []\n",
      "Species: [bullfrogs], Trait: [advantage], Cause: (Species: [Anax], Trait: [Presence], Cause: ([]), Change: []), Change: [increased]\n",
      "Species: [Anax], Trait: [], Cause: ([]), Change: []\n",
      "Species: [], Trait: [], Cause: ([observational, data, on, tadpole, activity, laboratory, experiments]), Change: []\n",
      "Species: None, Trait: None, Cause: (None), Change: None\n",
      "\n"
     ]
    }
   ],
   "source": [
    "t0 = time.time()\n",
    "parser = Parser()\n",
    "t1 = time.time()\n",
    "print(f\"Parser Initialization Took {t1 - t0}s\")\n",
    "\n",
    "for text in [text12]:\n",
    "    print(f\"Text: {text}\")\n",
    "    \n",
    "    # Update\n",
    "    t0 = time.time()\n",
    "    parser.update(text)\n",
    "    t1 = time.time()\n",
    "    print(f\"Parser Update Took {t1 - t0}s\")\n",
    "    \n",
    "    # Parse\n",
    "    t0 = time.time()\n",
    "    units = parser.parse()\n",
    "    t1 = time.time()\n",
    "    print(f\"Parsing Took {t1 - t0}s\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8296c13c-4d5d-44d5-ad02-06be08ed1346",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
