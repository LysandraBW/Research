{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "dae54da2-75f8-44ab-a0f4-78cbe2947947",
   "metadata": {},
   "outputs": [],
   "source": [
    "# I used this notebook as reference\n",
    "# https://www.kaggle.com/code/keitazoumana/scientific-document-similarity-search-with-scibert/notebook\n",
    "import pickle\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.metrics.pairwise import cosine_similarity\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "%run -i \"../utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "174f977f-6b23-48e0-bf93-a1c300076381",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n",
      "Some weights of BertForSequenceClassification were not initialized from the model checkpoint at allenai/scibert_scivocab_uncased and are newly initialized: ['classifier.bias', 'classifier.weight']\n",
      "You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"
     ]
    }
   ],
   "source": [
    "import torch\n",
    "from transformers import BertTokenizer,  AutoModelForSequenceClassification\n",
    "\n",
    "pretrained_model = 'allenai/scibert_scivocab_uncased'\n",
    "tokenizer = BertTokenizer.from_pretrained(pretrained_model, do_lower_case=True)\n",
    "model = AutoModelForSequenceClassification.from_pretrained(pretrained_model, output_attentions=False, output_hidden_states=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "693ff430-b839-431a-bdcc-fc0110aa2ac1",
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "def embed(string, verbose=False):\n",
    "    input_ids = tokenizer.encode(string, add_special_tokens=True)\n",
    "    if verbose:\n",
    "        print(f\"Input IDs: {[input_ids]}\")\n",
    "    padded_input_ids = pad_sequences([input_ids], maxlen=210, dtype=\"long\", truncating=\"post\", padding=\"post\")\n",
    "    if verbose:\n",
    "        print(f\"Padded Input IDs: {[padded_input_ids]}\")\n",
    "    \n",
    "    input_ids = padded_input_ids[0]\n",
    "    if verbose:\n",
    "        print(f\"Input IDs: {[input_ids]}\")\n",
    "\n",
    "    # Attention Mask\n",
    "    # It seems that it holds boolean values.\n",
    "    attention_mask = [int(i > 0) for i in input_ids]\n",
    "    \n",
    "    # Convert to Tensors\n",
    "    input_ids = torch.tensor(input_ids)\n",
    "    attention_mask = torch.tensor(attention_mask)\n",
    "    \n",
    "    # Pseudo-Batch\n",
    "    input_ids = input_ids.unsqueeze(0)\n",
    "    attention_mask = attention_mask.unsqueeze(0)\n",
    "    \n",
    "    model.eval()\n",
    "    \n",
    "    # Run the text through BERT, and collect all of the hidden states produced\n",
    "    # from all 12 layers. \n",
    "    with torch.no_grad():        \n",
    "        logits, encoded_layers = model(input_ids=input_ids, token_type_ids=None, attention_mask=attention_mask, return_dict=False)\n",
    "\n",
    "    layer_i = 12 # The last BERT layer before the classifier.\n",
    "    batch_i = 0 # Only one input in the batch.\n",
    "    token_i = 0 # The first token, corresponding to [CLS]\n",
    "        \n",
    "    # Extract the embedding.\n",
    "    embedding = encoded_layers[layer_i][batch_i][token_i]\n",
    "    embedding = embedding.detach().cpu().numpy()\n",
    "\n",
    "    if verbose:\n",
    "        print(f\"Embedding Shape: {embedding.shape}\")\n",
    "    return (embedding)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "172a5c81-1520-4b8f-b57c-40994461860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_embeddings(data):\n",
    "    data = data.copy()\n",
    "    embeddings = []\n",
    "    for abstract in data.Abstract:\n",
    "        embeddings.append(embed(abstract))\n",
    "    data[\"Embeddings\"] = embeddings\n",
    "    return data\n",
    "\n",
    "def process_embedding(embedding, verbose=False):\n",
    "    if verbose:\n",
    "        print(f\"Shape: {embedding.shape}\")\n",
    "    # The embedding needs to be a row vector\n",
    "    # for the cosine similarity calculation.\n",
    "    # I think, I might have misremembered.\n",
    "    embedding = np.array(embedding)\n",
    "    embedding = embedding.reshape(1, -1)\n",
    "    if verbose:\n",
    "        print(f\"Shape: {embedding.shape}\")\n",
    "    return embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c40fef39-caa8-41f6-836f-a07c82b0292b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(name, verbose=False):\n",
    "    # Load Dataset\n",
    "    data = load_preprocessed_dataset(name)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        print(\"Nothing to Score\")\n",
    "        return\n",
    "    \n",
    "    # Add Embeddings\n",
    "    # Embeddings are vectors that represent real-world objects, like words, images, \n",
    "    # or videos, in a form that machine learning models can easily process.\n",
    "    # (CloudFlare)\n",
    "    data = add_embeddings(data)\n",
    "\n",
    "    # Load Examples\n",
    "    # These are the abstracts that the papers will be scored against\n",
    "    # (in terms of similarity).\n",
    "    with open(f\"../../Datasets/Examples.pkl\", \"rb\") as f: \n",
    "        examples = pickle.load(f)\n",
    "    if verbose:\n",
    "        print(f\"Examples Shape: {examples.shape}\")\n",
    "\n",
    "    for i, example in enumerate(examples.Abstract):\n",
    "        example_embedding = process_embedding(embed(example))\n",
    "        if verbose:\n",
    "            print(f\"Example Embedding Shape: {example_embedding.shape}\")\n",
    "            print(f\"Abstract Embedding Shape: {np.array(data.Abstract[0]).shape}\")\n",
    "        data[f\"Similarity{i}\"] = data[\"Embeddings\"].apply(lambda x: cosine_similarity(example_embedding, [x])[0][0])\n",
    "\n",
    "    # Average Similarity\n",
    "    # So, we have a value of how similar a paper is to each example. Now, we'll\n",
    "    # take an average to get an overall idea.\n",
    "    data['Score'] = data[[f\"Similarity{i}\" for i in range(len(examples))]].mean(axis=1)\n",
    "    data.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ba23640f-aa1d-403d-afe8-844ef4435cc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (4, 4)\n",
      "Data Shape: (28, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (3, 4)\n",
      "Data Shape: (6, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (153, 4)\n",
      "Data Shape: (52, 4)\n"
     ]
    }
   ],
   "source": [
    "# Score Datasets\n",
    "dataset_names = [\"Examples\", \"Baseline-1\", \"SubA\", \"SubAFiltered\", \"SubB\", \"SubBFiltered\", \"C\", \"CFiltered\", \"D\", \"DFiltered\"]\n",
    "for name in dataset_names:\n",
    "    scored_data = score_dataset(name)\n",
    "    store_scored_dataset(scored_data, name, version='')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
