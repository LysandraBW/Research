{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5a0e3f5-afe6-4f0b-9d0c-5b7af7bdb050",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "%run -i \"../utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ccc9ba32-abfe-4b01-aaf0-2464ed490f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Khang Pham's Article\n",
    "# https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c008b965-7506-45b1-a628-03a1c906e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# A transformer model is a \"type of neural network architecture that excels at processing sequential data, most prominently associated with large language models (LLMs).\" [1]\n",
    "# \"BERT is a bidirectional transformer pretrained on unlabeled text to predict masked tokens in a sentence and to predict whether one sentence follows another. The main idea is that by randomly masking some tokens, the model can train on text to the left and right, giving it a more thorough understanding. BERT is also very versatile because its learned language representations can be adapted for other NLP tasks by fine-tuning an additional layer or head.\"\n",
    "# BERT uses subword tokens -- these tokens can be identified with the pound symbols.\n",
    "# Tokenization is \"the process of splitting text into smaller units called tokens... [which] ensures that the raw text is transformed into a format that models can process effectively\" [3].\n",
    "# Tokenization is \"crucial because modern NLP models... cannot process raw text directly. Instead, they require numerical input that captures both meaning and structure. Tokenization provides this bridge by\" [3] (1) standardizing input; (2) handling out-of-vocabulary words; and (3) adding special tokens that provide models with structural context (e.g. [CLS], [SEP]) [3].\n",
    "# 1. https://www.ibm.com/think/topics/transformer-model\n",
    "# 2. https://huggingface.co/docs/transformers/en/model_doc/bert\n",
    "# 3. https://medium.com/@piyushkashyap045/guide-to-tokenization-and-padding-with-bert-transforming-text-into-machine-readable-data-5a24bf59d36b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0cb77064-7931-4b53-97ce-5426e7f2ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "TARGET_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49557485-727a-4386-b351-55ee521ca879",
   "metadata": {},
   "outputs": [],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef89636d-e84b-46e3-aca5-73ce438b275d",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = pd.read_csv(\"../../Scores/Baseline-1/BingKan.csv\")\n",
    "# Process Dataset\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "print(f\"Processed Dataset Shape: {dataset.shape}\")\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72f22514-f08b-4389-a24a-fe4239be87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f45d0ba6-ea34-4b97-ab85-8d3b933714e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Example of Tokenizer\n",
    "inputs = [\n",
    "    \"Hello, world!\", \n",
    "    \"Goodbye, world!\",\n",
    "    \"I love NLP.\",\n",
    "    # \"I think. Therefore I am not.\"\n",
    "]\n",
    "\n",
    "for _ in inputs:\n",
    "    print(f\"Input: {_}\")\n",
    "    print(f\"Tokenized Input: {tokenizer.tokenize(_)}\")\n",
    "\n",
    "    # Encoding converts \"a string to a sequence of ids (integer), \n",
    "    # using the tokenizer and vocabulary.\" [4]\n",
    "    token_ids = tokenizer.encode(_)\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "    # Decoding converts \"a sequence of ids in a string, using the tokenizer\n",
    "    # and vocabulary with options to remove special tokens and clean up tokenization spaces.\" [4]\n",
    "    print(f\"Decoded Token IDs: {tokenizer.decode(token_ids)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Calling the tokenizer like this uses the main method to \"tokenize and prepare\n",
    "# for the model one or several sequence(s) or one or several pair(s) of sequences.\" [4]\n",
    "# This returns a \"BatchEncoding\" that contains \n",
    "# (1) input_ids: A list of token ids to be fed to a model;\n",
    "# (2) token_type_ids: A list of token type IDs to be fed to a model;\n",
    "# (3) attention_mask: A list of indices specifying which tokens should be attended to by the model.\n",
    "output = tokenizer(inputs, padding=True, truncation=True, max_length=128)\n",
    "print(\"Batch Encoding:\")\n",
    "print(output)\n",
    "# This works the same as the lines above (in the for loop). However,\n",
    "# the token IDs are labeled as \"input_ids\".\n",
    "# print(tokenizer.decode(output[\"input_ids\"][0]))\n",
    "# print(tokenizer.decode(output[\"input_ids\"][1]))\n",
    "\n",
    "# 4. https://huggingface.co/docs/transformers/en/main_classes/tokenizer\n",
    "# 5. https://huggingface.co/docs/transformers/en/glossary#input-ids\n",
    "# 6. https://huggingface.co/docs/transformers/en/glossary#token-type-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c6761376-2415-49f6-8c50-a4a70b4dc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index, verbose=False):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        # The return_tensors of 'pt' means that the BatchEncoding will\n",
    "        # return torch.Tensor objects (which is what we're using for this model).\n",
    "        # We determine the maximum length of the returned sequence, including padding,\n",
    "        # with max_length.\n",
    "        # A padding of 'max_length\" will pad the sequence to the given maximum length.\n",
    "        # If it were True or 'longest' it would pad to the longest sequence in the batch.\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', \n",
    "            truncation=True\n",
    "        )\n",
    "        if verbose:\n",
    "            print(encoding)\n",
    "\n",
    "        return {\n",
    "            # The flatten function is being used here because\n",
    "            # the call to tokenizer returns an array of those sequences.\n",
    "            # However, we've only passed in 1 text, so there's only 1 sequence we need.\n",
    "            # You could use .flatten() and I am sure that you could also use [0].\n",
    "            # We don't use the token_type_ids as we're not passing in a batch of pairs --\n",
    "            # meaning that there's only one sequence.\n",
    "            'input_ids': encoding['input_ids'].flatten(), \n",
    "            'attention_mask': encoding['attention_mask'].flatten(), \n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        # The BertModel will take in the information from tokenization\n",
    "        # (all contained in BatchEncoding) and outputs a corresponding\n",
    "        # embedding -- more or less. An embedding is \"a means of representing objects \n",
    "        # like text, images and audio as points in a continuous vector space where the\n",
    "        # locations of those points in space are semantically meaningful to machine \n",
    "        # learning (ML) algorithms.\" [7]\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        # A dropout layer is used as a regularization technique.\n",
    "        # Here, 10% of the neurons will be randomly dropped (set to 0).\n",
    "        # This prevents the model from overly depending on certain neurons (overfitting)\n",
    "        # and promotes a better understanding overall (generalization).\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # This is just a \"fully-connected\" dense layer.\n",
    "        # The hidden_size is presumably the size of BERT's last output layer.\n",
    "        # The 2 is the number of outputs this layer has. Since we're only dealing with 0 and 1,\n",
    "        # there's only 2 classes.\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, verbose=False):\n",
    "        # We do a forward pass with BERT's model and it returns a\n",
    "        # \"BaseModelOutputWithPoolingAndCrossAttentions\".\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # The pooler_output is \"the last layer hidden-state of the first token of the\n",
    "        # sequence (classification token)\" [8]. I wasn't sure why the first token of the sequence\n",
    "        # would be used (instead of all the tokens), but from Google's AI Overview: \"the first token \n",
    "        # of the sequence, typically a special \"CLS\" token, is considered to represent the overall \n",
    "        # semantic meaning of the entire input sequence during training, and its last layer hidden-state \n",
    "        # is used as a representative for the whole input when performing classification tasks\". The more\n",
    "        # experienced people are in agreement with that overview [9].\n",
    "        pooled_output = outputs.pooler_output\n",
    "        if verbose:\n",
    "            print(f\"Pooled Output Shape: {pooled_output.shape}\")\n",
    "        # The pooled output is passed through the dropout layer,\n",
    "        # and then the final layer which outputs logits.\n",
    "        # Logits are the outputs of a layer. They're passed through an\n",
    "        # activation function (likely softmax) to turn them into probabilities.\n",
    "        # This makes them interpretable.\n",
    "        x = self.dropout(pooled_output)\n",
    "        if verbose:\n",
    "            print(f\"Dropout Layer's Output Shape: {x.shape}\")\n",
    "        logits = self.fc(x)\n",
    "        if verbose:\n",
    "            print(f\"Logits: {logits}\")\n",
    "            print(f\"Logits Shape: {logits.shape}\")\n",
    "\n",
    "        # You'd normally use softmax here, but the loss function\n",
    "        # in the next cell already uses it and you don't want to apply\n",
    "        # it twice.\n",
    "        return logits\n",
    "\n",
    "# Early stopping is a technique used to prevent overfitting by stopping\n",
    "# the model when the gap between the validation loss and accuracy loss\n",
    "# continues to increase after a point.\n",
    "# https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# 7. https://www.ibm.com/think/topics/embedding\n",
    "# 8. https://huggingface.co/docs/transformers/en/model_doc/bert?usage=AutoModel#transformers.BertModel.forward.returns\n",
    "# 9. https://discuss.huggingface.co/t/significance-of-the-cls-token/3180/6\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, device, verbose=False):\n",
    "    expected = []\n",
    "    predictions = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader:\n",
    "    \n",
    "        # Resets Gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Model Inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Input IDs: {input_ids}\")\n",
    "            print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "\n",
    "            print(f\"Attention Mask: {attention_mask}\")\n",
    "            print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "\n",
    "        # Model Target/Expected Output\n",
    "        labels = batch['label'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Labels: {labels}\")\n",
    "            print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "        # Model's Actual Output/Predictions\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"Outputs: {outputs}\")\n",
    "            print(f\"Outputs Shape: {outputs.shape}\")\n",
    "\n",
    "        # Gradient Descent and Backpropagation\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # These are both used to improve the model's learning\n",
    "        # in similar but different ways.\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accuracy\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        if verbose:\n",
    "            print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "        expected.extend(labels.cpu().tolist())\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100, \n",
    "        \"report\": classification_report(expected, predictions, zero_division=0)\n",
    "    }\n",
    "\n",
    "def evaluate(model, data_loader, device, verbose=False):\n",
    "    model.eval()\n",
    "    \n",
    "    expected = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Model Inputs\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Input IDs: {input_ids}\")\n",
    "                print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "    \n",
    "                print(f\"Attention Mask: {attention_mask}\")\n",
    "                print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "    \n",
    "            # Model Target Output (Expected)\n",
    "            labels = batch['label'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Labels: {labels}\")\n",
    "                print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "            # Model's Actual Output/Predictions\n",
    "            # There's no loss being calculated here, so the softmax function\n",
    "            # is not being applied. Therefore, it's added here.\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "            if verbose:\n",
    "                print(f\"Outputs: {outputs}\")\n",
    "\n",
    "            # As early stopping is now being used, I'll have to calculate the loss.\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            if verbose:\n",
    "                print(f\"Loss: {loss}, {type(loss)}\")\n",
    "            losses.append(loss.item())\n",
    "            # outputs = nn.Softmax(dim=1)(outputs)\n",
    "            # if verbose:\n",
    "            #     print(f\"Outputs (After Softmax): {outputs}\")\n",
    "\n",
    "            # torch.max(...) returns \"a named tumple (values, indices) where values is the maximum\n",
    "            # value of each row of the input tensor in the given dimension dim. And indices is the index\"\n",
    "            # location of each maximum value found (argmax).\" [10] Since there's only 2 classes (0 and 1),\n",
    "            # and the two indices correspond to those classes, the line below is neat.\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            if verbose:\n",
    "                print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "            expected.extend(labels.cpu().tolist())\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    # Loss\n",
    "    # Taking the average of the losses\n",
    "    # from each batch.\n",
    "    if verbose:\n",
    "        print(f\"Losses: {losses}\")\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100,\n",
    "        \"report\": classification_report(expected, predictions, zero_division=0),\n",
    "        \"loss\": avg_loss\n",
    "    }\n",
    "\n",
    "def predict(text, model, tokenizer, device, max_length=MAX_LENGTH, return_integer=False):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs = nn.Softmax(dim=1)(outputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    if return_integer:\n",
    "        return preds.item()\n",
    "    return \"Example of TMII\" if preds.item() == 1 else \"No Example of TMII\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6ec5769-5817-4714-b106-40a966eac233",
   "metadata": {},
   "outputs": [],
   "source": [
    "X = dataset[\"Abstract\"].to_numpy()\n",
    "y = dataset[\"Score\"].apply(lambda score: 1 if score >= TARGET_THRESHOLD else 0).to_numpy()\n",
    "\n",
    "# Training and Validation/Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "\n",
    "# The tokenizer is needed for the datasets and data loaders below,\n",
    "# which is why it's defined here. I probably didn't need to add this comment.\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Train Dataset\n",
    "train_dataset = TextClassificationDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Validation Dataset\n",
    "val_dataset = TextClassificationDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fc1e815d-62f1-4b98-a232-551f484b227b",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = BERTClassifier().to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, no_deprecation_warning=True)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_data_loader) * NUM_EPOCHS)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=10)\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # Train\n",
    "    train_performance = train(model, train_data_loader, optimizer, scheduler, device, verbose=False)\n",
    "    print(f\"Training Accuracy: {train_performance['accuracy']:.2f}%\")\n",
    "\n",
    "    # Validate\n",
    "    val_performance = evaluate(model, val_data_loader, device, verbose=True)\n",
    "    print(f\"Validation Loss: {val_performance['loss']:.2f}\")\n",
    "    print(f\"Validation Accuracy: {val_performance['accuracy']:.2f}%\\n\")\n",
    "\n",
    "    # Early Stop\n",
    "    if early_stopping.early_stop(val_performance['loss']):\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b7958770-4e79-47a4-bcd6-431d7a478203",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Try It Out\n",
    "df = pd.read_csv(\"../../Datasets/Baseline-1.csv\")\n",
    "# texts = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    is_example = predict(row['Abstract'], model, tokenizer, device)\n",
    "    print(row['Title'])\n",
    "    print(f\"\\tPredicted: '{is_example}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "54d0b6fb-03e8-4bd2-a395-eef0f050c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(name, verbose=False):\n",
    "    # Load Dataset\n",
    "    data = load_preprocessed_dataset(name)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        print(\"Nothing to Score\")\n",
    "        return\n",
    "    \n",
    "    # Run Model\n",
    "    data['Score'] = data['Abstract'].apply(lambda abstract: predict(abstract, model, tokenizer, device, return_integer=True))\n",
    "    data.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1c64ed6f-f712-4779-8306-4670d3045dbb",
   "metadata": {},
   "outputs": [],
   "source": [
    "version = ''\n",
    "\n",
    "dataset_names = [\"Examples\", \"Baseline-1\", \"SubA\", \"SubAFiltered\", \"SubB\", \"SubBFiltered\", \"C\", \"CFiltered\", \"D\", \"DFiltered\"]\n",
    "for name in dataset_names:\n",
    "    scored_data = score_dataset(name)\n",
    "    store_scored_dataset(scored_data, name, version=version)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "6a96c2fd-dda5-4a4e-8bed-7265015611bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 59.26%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%run -i \"../utils.py\"\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "\n",
    "measurements = measure_method_by_class(\n",
    "    output_fp=\"./ScoredBaseline-1.csv\",\n",
    "    target_threshold=TARGET_THRESHOLD,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {measurements['accuracy'] * 100:.2f}%\")\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=measurements['confusion_matrix'])\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
