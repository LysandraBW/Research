{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a0e3f5-afe6-4f0b-9d0c-5b7af7bdb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%run -i \"../utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc9ba32-abfe-4b01-aaf0-2464ed490f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Khang Pham's Article\n",
    "# https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c008b965-7506-45b1-a628-03a1c906e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# A transformer model is a \"type of neural network architecture that excels at processing sequential data, most prominently associated with large language models (LLMs).\" [1]\n",
    "# \"BERT is a bidirectional transformer pretrained on unlabeled text to predict masked tokens in a sentence and to predict whether one sentence follows another. The main idea is that by randomly masking some tokens, the model can train on text to the left and right, giving it a more thorough understanding. BERT is also very versatile because its learned language representations can be adapted for other NLP tasks by fine-tuning an additional layer or head.\"\n",
    "# BERT uses subword tokens -- these tokens can be identified with the pound symbols.\n",
    "# Tokenization is \"the process of splitting text into smaller units called tokens... [which] ensures that the raw text is transformed into a format that models can process effectively\" [3].\n",
    "# Tokenization is \"crucial because modern NLP models... cannot process raw text directly. Instead, they require numerical input that captures both meaning and structure. Tokenization provides this bridge by\" [3] (1) standardizing input; (2) handling out-of-vocabulary words; and (3) adding special tokens that provide models with structural context (e.g. [CLS], [SEP]) [3].\n",
    "# 1. https://www.ibm.com/think/topics/transformer-model\n",
    "# 2. https://huggingface.co/docs/transformers/en/model_doc/bert\n",
    "# 3. https://medium.com/@piyushkashyap045/guide-to-tokenization-and-padding-with-bert-transforming-text-into-machine-readable-data-5a24bf59d36b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb77064-7931-4b53-97ce-5426e7f2ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "TARGET_THRESHOLD = 3"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49557485-727a-4386-b351-55ee521ca879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef89636d-e84b-46e3-aca5-73ce438b275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Dataset Shape: (25, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.157584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score\n",
       "count  25.000000\n",
       "mean    1.440000\n",
       "std     1.157584\n",
       "min     0.000000\n",
       "25%     0.000000\n",
       "50%     1.000000\n",
       "75%     2.000000\n",
       "max     3.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../../Scores/Baseline-1-BingKan.csv\")\n",
    "# Process Dataset\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "print(f\"Processed Dataset Shape: {dataset.shape}\")\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f22514-f08b-4389-a24a-fe4239be87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45d0ba6-ea34-4b97-ab85-8d3b933714e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hello, world!\n",
      "Tokenized Input: ['hell', '##o', ',', 'world', '!']\n",
      "Token IDs: [102, 29423, 30112, 422, 2399, 3190, 103]\n",
      "Decoded Token IDs: [CLS] hello, world! [SEP]\n",
      "\n",
      "Input: Goodbye, world!\n",
      "Tokenized Input: ['good', '##by', '##e', ',', 'world', '!']\n",
      "Token IDs: [102, 1846, 2301, 30107, 422, 2399, 3190, 103]\n",
      "Decoded Token IDs: [CLS] goodbye, world! [SEP]\n",
      "\n",
      "Input: I love NLP.\n",
      "Tokenized Input: ['i', 'love', 'nl', '##p', '.']\n",
      "Token IDs: [102, 259, 16780, 4588, 30121, 205, 103]\n",
      "Decoded Token IDs: [CLS] i love nlp. [SEP]\n",
      "\n",
      "Batch Encoding:\n",
      "{'input_ids': [[102, 29423, 30112, 422, 2399, 3190, 103, 0], [102, 1846, 2301, 30107, 422, 2399, 3190, 103], [102, 259, 16780, 4588, 30121, 205, 103, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# Example of Tokenizer\n",
    "inputs = [\n",
    "    \"Hello, world!\", \n",
    "    \"Goodbye, world!\",\n",
    "    \"I love NLP.\",\n",
    "    # \"I think. Therefore I am not.\"\n",
    "]\n",
    "\n",
    "for _ in inputs:\n",
    "    print(f\"Input: {_}\")\n",
    "    print(f\"Tokenized Input: {tokenizer.tokenize(_)}\")\n",
    "\n",
    "    # Encoding converts \"a string to a sequence of ids (integer), \n",
    "    # using the tokenizer and vocabulary.\" [4]\n",
    "    token_ids = tokenizer.encode(_)\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "    # Decoding converts \"a sequence of ids in a string, using the tokenizer\n",
    "    # and vocabulary with options to remove special tokens and clean up tokenization spaces.\" [4]\n",
    "    print(f\"Decoded Token IDs: {tokenizer.decode(token_ids)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Calling the tokenizer like this uses the main method to \"tokenize and prepare\n",
    "# for the model one or several sequence(s) or one or several pair(s) of sequences.\" [4]\n",
    "# This returns a \"BatchEncoding\" that contains \n",
    "# (1) input_ids: A list of token ids to be fed to a model;\n",
    "# (2) token_type_ids: A list of token type IDs to be fed to a model;\n",
    "# (3) attention_mask: A list of indices specifying which tokens should be attended to by the model.\n",
    "output = tokenizer(inputs, padding=True, truncation=True, max_length=128)\n",
    "print(\"Batch Encoding:\")\n",
    "print(output)\n",
    "# This works the same as the lines above (in the for loop). However,\n",
    "# the token IDs are labeled as \"input_ids\".\n",
    "# print(tokenizer.decode(output[\"input_ids\"][0]))\n",
    "# print(tokenizer.decode(output[\"input_ids\"][1]))\n",
    "\n",
    "# 4. https://huggingface.co/docs/transformers/en/main_classes/tokenizer\n",
    "# 5. https://huggingface.co/docs/transformers/en/glossary#input-ids\n",
    "# 6. https://huggingface.co/docs/transformers/en/glossary#token-type-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6761376-2415-49f6-8c50-a4a70b4dc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index, verbose=False):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        # The return_tensors of 'pt' means that the BatchEncoding will\n",
    "        # return torch.Tensor objects (which is what we're using for this model).\n",
    "        # We determine the maximum length of the returned sequence, including padding,\n",
    "        # with max_length.\n",
    "        # A padding of 'max_length\" will pad the sequence to the given maximum length.\n",
    "        # If it were True or 'longest' it would pad to the longest sequence in the batch.\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', \n",
    "            truncation=True\n",
    "        )\n",
    "        if verbose:\n",
    "            print(encoding)\n",
    "\n",
    "        return {\n",
    "            # The flatten function is being used here because\n",
    "            # the call to tokenizer returns an array of those sequences.\n",
    "            # However, we've only passed in 1 text, so there's only 1 sequence we need.\n",
    "            # You could use .flatten() and I am sure that you could also use [0].\n",
    "            # We don't use the token_type_ids as we're not passing in a batch of pairs --\n",
    "            # meaning that there's only one sequence.\n",
    "            'input_ids': encoding['input_ids'].flatten(), \n",
    "            'attention_mask': encoding['attention_mask'].flatten(), \n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        # The BertModel will take in the information from tokenization\n",
    "        # (all contained in BatchEncoding) and outputs a corresponding\n",
    "        # embedding -- more or less. An embedding is \"a means of representing objects \n",
    "        # like text, images and audio as points in a continuous vector space where the\n",
    "        # locations of those points in space are semantically meaningful to machine \n",
    "        # learning (ML) algorithms.\" [7]\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        # A dropout layer is used as a regularization technique.\n",
    "        # Here, 10% of the neurons will be randomly dropped (set to 0).\n",
    "        # This prevents the model from overly depending on certain neurons (overfitting)\n",
    "        # and promotes a better understanding overall (generalization).\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # This is just a \"fully-connected\" dense layer.\n",
    "        # The hidden_size is presumably the size of BERT's last output layer.\n",
    "        # The 2 is the number of outputs this layer has. Since we're only dealing with 0 and 1,\n",
    "        # there's only 2 classes.\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, verbose=False):\n",
    "        # We do a forward pass with BERT's model and it returns a\n",
    "        # \"BaseModelOutputWithPoolingAndCrossAttentions\".\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # The pooler_output is \"the last layer hidden-state of the first token of the\n",
    "        # sequence (classification token)\" [8]. I wasn't sure why the first token of the sequence\n",
    "        # would be used (instead of all the tokens), but from Google's AI Overview: \"the first token \n",
    "        # of the sequence, typically a special \"CLS\" token, is considered to represent the overall \n",
    "        # semantic meaning of the entire input sequence during training, and its last layer hidden-state \n",
    "        # is used as a representative for the whole input when performing classification tasks\". The more\n",
    "        # experienced people are in agreement with that overview [9].\n",
    "        pooled_output = outputs.pooler_output\n",
    "        if verbose:\n",
    "            print(f\"Pooled Output Shape: {pooled_output.shape}\")\n",
    "        # The pooled output is passed through the dropout layer,\n",
    "        # and then the final layer which outputs logits.\n",
    "        # Logits are the outputs of a layer. They're passed through an\n",
    "        # activation function (likely softmax) to turn them into probabilities.\n",
    "        # This makes them interpretable.\n",
    "        x = self.dropout(pooled_output)\n",
    "        if verbose:\n",
    "            print(f\"Dropout Layer's Output Shape: {x.shape}\")\n",
    "        logits = self.fc(x)\n",
    "        if verbose:\n",
    "            print(f\"Logits: {logits}\")\n",
    "            print(f\"Logits Shape: {logits.shape}\")\n",
    "\n",
    "        # You'd normally use softmax here, but the loss function\n",
    "        # in the next cell already uses it and you don't want to apply\n",
    "        # it twice.\n",
    "        return logits\n",
    "\n",
    "# Early stopping is a technique used to prevent overfitting by stopping\n",
    "# the model when the gap between the validation loss and accuracy loss\n",
    "# continues to increase after a point.\n",
    "# https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# 7. https://www.ibm.com/think/topics/embedding\n",
    "# 8. https://huggingface.co/docs/transformers/en/model_doc/bert?usage=AutoModel#transformers.BertModel.forward.returns\n",
    "# 9. https://discuss.huggingface.co/t/significance-of-the-cls-token/3180/6\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, device, verbose=False):\n",
    "    expected = []\n",
    "    predictions = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader:\n",
    "    \n",
    "        # Resets Gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Model Inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Input IDs: {input_ids}\")\n",
    "            print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "\n",
    "            print(f\"Attention Mask: {attention_mask}\")\n",
    "            print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "\n",
    "        # Model Target/Expected Output\n",
    "        labels = batch['label'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Labels: {labels}\")\n",
    "            print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "        # Model's Actual Output/Predictions\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"Outputs: {outputs}\")\n",
    "            print(f\"Outputs Shape: {outputs.shape}\")\n",
    "\n",
    "        # Gradient Descent and Backpropagation\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # These are both used to improve the model's learning\n",
    "        # in similar but different ways.\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accuracy\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        if verbose:\n",
    "            print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "        expected.extend(labels.cpu().tolist())\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100, \n",
    "        \"report\": classification_report(expected, predictions, zero_division=0)\n",
    "    }\n",
    "\n",
    "def evaluate(model, data_loader, device, verbose=False):\n",
    "    model.eval()\n",
    "    \n",
    "    expected = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Model Inputs\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Input IDs: {input_ids}\")\n",
    "                print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "    \n",
    "                print(f\"Attention Mask: {attention_mask}\")\n",
    "                print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "    \n",
    "            # Model Target Output (Expected)\n",
    "            labels = batch['label'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Labels: {labels}\")\n",
    "                print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "            # Model's Actual Output/Predictions\n",
    "            # There's no loss being calculated here, so the softmax function\n",
    "            # is not being applied. Therefore, it's added here.\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "            if verbose:\n",
    "                print(f\"Outputs: {outputs}\")\n",
    "\n",
    "            # As early stopping is now being used, I'll have to calculate the loss.\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            if verbose:\n",
    "                print(f\"Loss: {loss}, {type(loss)}\")\n",
    "            losses.append(loss.item())\n",
    "            # outputs = nn.Softmax(dim=1)(outputs)\n",
    "            # if verbose:\n",
    "            #     print(f\"Outputs (After Softmax): {outputs}\")\n",
    "\n",
    "            # torch.max(...) returns \"a named tumple (values, indices) where values is the maximum\n",
    "            # value of each row of the input tensor in the given dimension dim. And indices is the index\"\n",
    "            # location of each maximum value found (argmax).\" [10] Since there's only 2 classes (0 and 1),\n",
    "            # and the two indices correspond to those classes, the line below is neat.\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            if verbose:\n",
    "                print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "            expected.extend(labels.cpu().tolist())\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    # Loss\n",
    "    # Taking the average of the losses\n",
    "    # from each batch.\n",
    "    if verbose:\n",
    "        print(f\"Losses: {losses}\")\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100,\n",
    "        \"report\": classification_report(expected, predictions, zero_division=0),\n",
    "        \"loss\": avg_loss\n",
    "    }\n",
    "\n",
    "def predict(text, model, tokenizer, device, max_length=MAX_LENGTH, return_integer=False):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs = nn.Softmax(dim=1)(outputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    if return_integer:\n",
    "        return preds.item()\n",
    "    return \"Example of TMII\" if preds.item() == 1 else \"No Example of TMII\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ec5769-5817-4714-b106-40a966eac233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (15,)\n",
      "y_train Shape: (15,)\n",
      "X_test Shape: (10,)\n",
      "y_test Shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[\"Abstract\"].to_numpy()\n",
    "y = dataset[\"Score\"].apply(lambda score: 1 if score >= TARGET_THRESHOLD else 0).to_numpy()\n",
    "\n",
    "# Training and Validation/Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "\n",
    "# The tokenizer is needed for the datasets and data loaders below,\n",
    "# which is why it's defined here. I probably didn't need to add this comment.\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Train Dataset\n",
    "train_dataset = TextClassificationDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Validation Dataset\n",
    "val_dataset = TextClassificationDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1e815d-62f1-4b98-a232-551f484b227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "Training Accuracy: 66.67%\n",
      "Validation Loss: 0.63\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 2/8\n",
      "Training Accuracy: 80.00%\n",
      "Validation Loss: 0.61\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 3/8\n",
      "Training Accuracy: 80.00%\n",
      "Validation Loss: 0.60\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 4/8\n",
      "Training Accuracy: 80.00%\n",
      "Validation Loss: 0.57\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 5/8\n",
      "Training Accuracy: 93.33%\n",
      "Validation Loss: 0.50\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 6/8\n",
      "Training Accuracy: 93.33%\n",
      "Validation Loss: 0.51\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 7/8\n",
      "Training Accuracy: 93.33%\n",
      "Validation Loss: 0.51\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 8/8\n",
      "Training Accuracy: 93.33%\n",
      "Validation Loss: 0.51\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier().to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, no_deprecation_warning=True)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_data_loader) * NUM_EPOCHS)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=10)\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # Train\n",
    "    train_performance = train(model, train_data_loader, optimizer, scheduler, device, verbose=False)\n",
    "    print(f\"Training Accuracy: {train_performance['accuracy']:.2f}%\")\n",
    "\n",
    "    # Validate\n",
    "    val_performance = evaluate(model, val_data_loader, device, verbose=False)\n",
    "    print(f\"Validation Loss: {val_performance['loss']:.2f}\")\n",
    "    print(f\"Validation Accuracy: {val_performance['accuracy']:.2f}%\\n\")\n",
    "\n",
    "    # Early Stop\n",
    "    if early_stopping.early_stop(val_performance['loss']):\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "b7958770-4e79-47a4-bcd6-431d7a478203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving beyond linear food chains: trait-mediated indirect interactions in a rocky intertidal food web\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Keep Your Eggs Away: Ant Presence Reduces Ceratitis capitata Oviposition Behaviour through Trait-Mediated Indirect Interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Higher Order Interactions in Ecological Communities: What Are They and How Can They be Detected?\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Competition Between Aquatic Insects and Vertebrates: Interaction Strength and Higher Order Interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "The mechanistic basis for higher-order interactions and non-additivity in competitive communities\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Higher order interactions and species coexistence\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Coexistence in diverse communities with higher-order interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Coexistence in diverse communities with higher-order interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Variable Virulence and Efficacy of BCG Vaccine Strains in Mice and Correlation With Genome Polymorphisms\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Insect-mediated apparent competition between mammals in a boreal food web\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Global Warming Could Magnify Insect-Driven Apparent Competition Between Native and Introduced Host Plants in Sub-Antarctic Islands\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Refuge-mediated apparent competition in a tallgrass prairie?\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Data from: Density-dependent indirect effects: apparent mutualism and apparent competition coexist in a two-prey system\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Resource Competition Triggers the Co-Evolution of Long Tongues and Deep Corolla Tubes\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Intraguild Predation of Beneficial Arthropods by Red Imported Fire Ants in Cotton\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Facultative Intraguild Predation by Larval Cerambycidae (Coleoptera) on Bark Beetle Larvae (Coleoptera: Scolytidae): Fig. 1.\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "The roles of habitat and intraguild predation by coyotes on the spatial dynamics of kit foxes\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Top predators and habitat complexity alter an intraguild predation module in pond communities\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Temperature dependency of intraguild predation between native and invasive crabs\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Does nitrogen limitation promote intraguild predation in an aphidophagous ladybird?\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Competition and intraguild predation between the braconid parasitoid<i>Bracon hylobii</i>and the entomopathogenic nematode<i>Heterorhabditis downesi</i>, natural enemies of the large pine weevil,<i>Hylobius abietis</i>\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Competitive Plant-Mediated and Intraguild Predation Interactions of the Invasive Spodoptera frugiperda and Resident Stemborers Busseola fusca and Chilo partellus in Maize Cropping Systems in Kenya\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Diet type and prey preference of predators affect intraguild predation between Amblyseius andersoni and Neoseiulus barkeri\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Impact of intraspecific and intraguild predation on predator invasion and coexistence. Can exotic ladybeetles displace native species\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Slow-Release Sachets of Neoseiulus cucumeris Predatory Mites Reduce Intraguild Predation by Dalotia coriaria in Greenhouse Biological Control Systems\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Toxicity of CeO<sub>2</sub>nanoparticles on a freshwater experimental trophic chain: A study in environmentally relevant conditions through the use of mesocosms\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "The effect of copper stress on inter-trophic relationships in a model tri-trophic food chain.\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Data from: Density-dependent indirect effects: apparent mutualism and apparent competition coexist in a two-prey system\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# Try It Out\n",
    "df = pd.read_csv(\"../../Datasets/Baseline-1.csv\")\n",
    "# texts = []\n",
    "\n",
    "for i, row in df.iterrows():\n",
    "    is_example = predict(row['Abstract'], model, tokenizer, device)\n",
    "    print(row['Title'])\n",
    "    print(f\"\\tPredicted: '{is_example}'\")\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d0b6fb-03e8-4bd2-a395-eef0f050c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(name, verbose=False):\n",
    "    # Load Dataset\n",
    "    data = load_preprocessed_dataset(name)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        print(\"Nothing to Score\")\n",
    "        return\n",
    "    \n",
    "    # Run Model\n",
    "    data['Score'] = data['Abstract'].apply(lambda abstract: predict(abstract, model, tokenizer, device, return_integer=True))\n",
    "    data.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c64ed6f-f712-4779-8306-4670d3045dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (4, 4)\n",
      "Data Shape: (28, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (3, 4)\n",
      "Data Shape: (6, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (153, 4)\n",
      "Data Shape: (52, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"Examples\", \"Baseline-1\", \"SubA\", \"SubAFiltered\", \"SubB\", \"SubBFiltered\", \"C\", \"CFiltered\", \"D\", \"DFiltered\"]\n",
    "for name in dataset_names:\n",
    "    scored_data = score_dataset(name)\n",
    "    store_scored_dataset(scored_data, name, version='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a96c2fd-dda5-4a4e-8bed-7265015611bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 88.89%\n"
     ]
    },
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "measurements = measure_method_by_class(\n",
    "    output_fp=\"./ScoredBaseline-1.csv\",\n",
    "    target_threshold=TARGET_THRESHOLD,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {measurements['accuracy'] * 100:.2f}%\")\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=measurements['confusion_matrix'])\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
