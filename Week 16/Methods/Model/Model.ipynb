{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "d5a0e3f5-afe6-4f0b-9d0c-5b7af7bdb050",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.utils.data import DataLoader, Dataset\n",
    "from transformers import BertTokenizer, BertModel, AdamW, get_linear_schedule_with_warmup\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score, classification_report\n",
    "import pandas as pd\n",
    "import pickle\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%run -i \"../utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ccc9ba32-abfe-4b01-aaf0-2464ed490f95",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Following Khang Pham's Article\n",
    "# https://medium.com/@khang.pham.exxact/text-classification-with-bert-7afaacc5e49b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "c008b965-7506-45b1-a628-03a1c906e985",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Notes\n",
    "# A transformer model is a \"type of neural network architecture that excels at processing sequential data, most prominently associated with large language models (LLMs).\" [1]\n",
    "# \"BERT is a bidirectional transformer pretrained on unlabeled text to predict masked tokens in a sentence and to predict whether one sentence follows another. The main idea is that by randomly masking some tokens, the model can train on text to the left and right, giving it a more thorough understanding. BERT is also very versatile because its learned language representations can be adapted for other NLP tasks by fine-tuning an additional layer or head.\"\n",
    "# BERT uses subword tokens -- these tokens can be identified with the pound symbols.\n",
    "# Tokenization is \"the process of splitting text into smaller units called tokens... [which] ensures that the raw text is transformed into a format that models can process effectively\" [3].\n",
    "# Tokenization is \"crucial because modern NLP models... cannot process raw text directly. Instead, they require numerical input that captures both meaning and structure. Tokenization provides this bridge by\" [3] (1) standardizing input; (2) handling out-of-vocabulary words; and (3) adding special tokens that provide models with structural context (e.g. [CLS], [SEP]) [3].\n",
    "# 1. https://www.ibm.com/think/topics/transformer-model\n",
    "# 2. https://huggingface.co/docs/transformers/en/model_doc/bert\n",
    "# 3. https://medium.com/@piyushkashyap045/guide-to-tokenization-and-padding-with-bert-transforming-text-into-machine-readable-data-5a24bf59d36b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "0cb77064-7931-4b53-97ce-5426e7f2ba06",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Constants\n",
    "MAX_LENGTH = 128\n",
    "BATCH_SIZE = 2\n",
    "NUM_EPOCHS = 8\n",
    "LEARNING_RATE = 2e-5\n",
    "MODEL_NAME = 'allenai/scibert_scivocab_uncased'\n",
    "TARGET_THRESHOLD = 2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "49557485-727a-4386-b351-55ee521ca879",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Device: cuda\n"
     ]
    }
   ],
   "source": [
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "print(f\"Device: {device}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "ef89636d-e84b-46e3-aca5-73ce438b275d",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Processed Dataset Shape: (25, 4)\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>count</th>\n",
       "      <td>25.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>mean</th>\n",
       "      <td>1.440000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>std</th>\n",
       "      <td>1.157584</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>min</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>25%</th>\n",
       "      <td>0.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>50%</th>\n",
       "      <td>1.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>75%</th>\n",
       "      <td>2.000000</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>max</th>\n",
       "      <td>3.000000</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "           Score\n",
       "count  25.000000\n",
       "mean    1.440000\n",
       "std     1.157584\n",
       "min     0.000000\n",
       "25%     0.000000\n",
       "50%     1.000000\n",
       "75%     2.000000\n",
       "max     3.000000"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset = pd.read_csv(\"../../Scores/Baseline-1-BingKan.csv\")\n",
    "# Process Dataset\n",
    "dataset.dropna(inplace=True)\n",
    "dataset.drop_duplicates(inplace=True)\n",
    "print(f\"Processed Dataset Shape: {dataset.shape}\")\n",
    "dataset.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "72f22514-f08b-4389-a24a-fe4239be87d6",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "f45d0ba6-ea34-4b97-ab85-8d3b933714e4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Input: Hello, world!\n",
      "Tokenized Input: ['hell', '##o', ',', 'world', '!']\n",
      "Token IDs: [102, 29423, 30112, 422, 2399, 3190, 103]\n",
      "Decoded Token IDs: [CLS] hello, world! [SEP]\n",
      "\n",
      "Input: Goodbye, world!\n",
      "Tokenized Input: ['good', '##by', '##e', ',', 'world', '!']\n",
      "Token IDs: [102, 1846, 2301, 30107, 422, 2399, 3190, 103]\n",
      "Decoded Token IDs: [CLS] goodbye, world! [SEP]\n",
      "\n",
      "Input: I love NLP.\n",
      "Tokenized Input: ['i', 'love', 'nl', '##p', '.']\n",
      "Token IDs: [102, 259, 16780, 4588, 30121, 205, 103]\n",
      "Decoded Token IDs: [CLS] i love nlp. [SEP]\n",
      "\n",
      "Batch Encoding:\n",
      "{'input_ids': [[102, 29423, 30112, 422, 2399, 3190, 103, 0], [102, 1846, 2301, 30107, 422, 2399, 3190, 103], [102, 259, 16780, 4588, 30121, 205, 103, 0]], 'token_type_ids': [[0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0], [0, 0, 0, 0, 0, 0, 0, 0]], 'attention_mask': [[1, 1, 1, 1, 1, 1, 1, 0], [1, 1, 1, 1, 1, 1, 1, 1], [1, 1, 1, 1, 1, 1, 1, 0]]}\n"
     ]
    }
   ],
   "source": [
    "# Example of Tokenizer\n",
    "inputs = [\n",
    "    \"Hello, world!\", \n",
    "    \"Goodbye, world!\",\n",
    "    \"I love NLP.\",\n",
    "    # \"I think. Therefore I am not.\"\n",
    "]\n",
    "\n",
    "for _ in inputs:\n",
    "    print(f\"Input: {_}\")\n",
    "    print(f\"Tokenized Input: {tokenizer.tokenize(_)}\")\n",
    "\n",
    "    # Encoding converts \"a string to a sequence of ids (integer), \n",
    "    # using the tokenizer and vocabulary.\" [4]\n",
    "    token_ids = tokenizer.encode(_)\n",
    "    print(f\"Token IDs: {token_ids}\")\n",
    "\n",
    "    # Decoding converts \"a sequence of ids in a string, using the tokenizer\n",
    "    # and vocabulary with options to remove special tokens and clean up tokenization spaces.\" [4]\n",
    "    print(f\"Decoded Token IDs: {tokenizer.decode(token_ids)}\")\n",
    "    \n",
    "    print()\n",
    "\n",
    "# Calling the tokenizer like this uses the main method to \"tokenize and prepare\n",
    "# for the model one or several sequence(s) or one or several pair(s) of sequences.\" [4]\n",
    "# This returns a \"BatchEncoding\" that contains \n",
    "# (1) input_ids: A list of token ids to be fed to a model;\n",
    "# (2) token_type_ids: A list of token type IDs to be fed to a model;\n",
    "# (3) attention_mask: A list of indices specifying which tokens should be attended to by the model.\n",
    "output = tokenizer(inputs, padding=True, truncation=True, max_length=128)\n",
    "print(\"Batch Encoding:\")\n",
    "print(output)\n",
    "# This works the same as the lines above (in the for loop). However,\n",
    "# the token IDs are labeled as \"input_ids\".\n",
    "# print(tokenizer.decode(output[\"input_ids\"][0]))\n",
    "# print(tokenizer.decode(output[\"input_ids\"][1]))\n",
    "\n",
    "# 4. https://huggingface.co/docs/transformers/en/main_classes/tokenizer\n",
    "# 5. https://huggingface.co/docs/transformers/en/glossary#input-ids\n",
    "# 6. https://huggingface.co/docs/transformers/en/glossary#token-type-ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "c6761376-2415-49f6-8c50-a4a70b4dc94f",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TextClassificationDataset(Dataset):\n",
    "    def __init__(self, texts, labels, tokenizer, max_length):\n",
    "        self.texts = texts\n",
    "        self.labels = labels\n",
    "        self.tokenizer = tokenizer\n",
    "        self.max_length = max_length\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.texts)\n",
    "\n",
    "    def __getitem__(self, index, verbose=False):\n",
    "        text = self.texts[index]\n",
    "        label = self.labels[index]\n",
    "        # The return_tensors of 'pt' means that the BatchEncoding will\n",
    "        # return torch.Tensor objects (which is what we're using for this model).\n",
    "        # We determine the maximum length of the returned sequence, including padding,\n",
    "        # with max_length.\n",
    "        # A padding of 'max_length\" will pad the sequence to the given maximum length.\n",
    "        # If it were True or 'longest' it would pad to the longest sequence in the batch.\n",
    "        encoding = self.tokenizer(\n",
    "            text,\n",
    "            return_tensors='pt',\n",
    "            max_length=self.max_length,\n",
    "            padding='max_length', \n",
    "            truncation=True\n",
    "        )\n",
    "        if verbose:\n",
    "            print(encoding)\n",
    "\n",
    "        return {\n",
    "            # The flatten function is being used here because\n",
    "            # the call to tokenizer returns an array of those sequences.\n",
    "            # However, we've only passed in 1 text, so there's only 1 sequence we need.\n",
    "            # You could use .flatten() and I am sure that you could also use [0].\n",
    "            # We don't use the token_type_ids as we're not passing in a batch of pairs --\n",
    "            # meaning that there's only one sequence.\n",
    "            'input_ids': encoding['input_ids'].flatten(), \n",
    "            'attention_mask': encoding['attention_mask'].flatten(), \n",
    "            'label': torch.tensor(label)\n",
    "        }\n",
    "\n",
    "class BERTClassifier(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(BERTClassifier, self).__init__()\n",
    "        # The BertModel will take in the information from tokenization\n",
    "        # (all contained in BatchEncoding) and outputs a corresponding\n",
    "        # embedding -- more or less. An embedding is \"a means of representing objects \n",
    "        # like text, images and audio as points in a continuous vector space where the\n",
    "        # locations of those points in space are semantically meaningful to machine \n",
    "        # learning (ML) algorithms.\" [7]\n",
    "        self.bert = BertModel.from_pretrained(MODEL_NAME)\n",
    "        # A dropout layer is used as a regularization technique.\n",
    "        # Here, 10% of the neurons will be randomly dropped (set to 0).\n",
    "        # This prevents the model from overly depending on certain neurons (overfitting)\n",
    "        # and promotes a better understanding overall (generalization).\n",
    "        self.dropout = nn.Dropout(0.1)\n",
    "        # This is just a \"fully-connected\" dense layer.\n",
    "        # The hidden_size is presumably the size of BERT's last output layer.\n",
    "        # The 2 is the number of outputs this layer has. Since we're only dealing with 0 and 1,\n",
    "        # there's only 2 classes.\n",
    "        self.fc = nn.Linear(self.bert.config.hidden_size, 2)\n",
    "\n",
    "    def forward(self, input_ids, attention_mask, verbose=False):\n",
    "        # We do a forward pass with BERT's model and it returns a\n",
    "        # \"BaseModelOutputWithPoolingAndCrossAttentions\".\n",
    "        outputs = self.bert(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        # The pooler_output is \"the last layer hidden-state of the first token of the\n",
    "        # sequence (classification token)\" [8]. I wasn't sure why the first token of the sequence\n",
    "        # would be used (instead of all the tokens), but from Google's AI Overview: \"the first token \n",
    "        # of the sequence, typically a special \"CLS\" token, is considered to represent the overall \n",
    "        # semantic meaning of the entire input sequence during training, and its last layer hidden-state \n",
    "        # is used as a representative for the whole input when performing classification tasks\". The more\n",
    "        # experienced people are in agreement with that overview [9].\n",
    "        pooled_output = outputs.pooler_output\n",
    "        if verbose:\n",
    "            print(f\"Pooled Output Shape: {pooled_output.shape}\")\n",
    "        # The pooled output is passed through the dropout layer,\n",
    "        # and then the final layer which outputs logits.\n",
    "        # Logits are the outputs of a layer. They're passed through an\n",
    "        # activation function (likely softmax) to turn them into probabilities.\n",
    "        # This makes them interpretable.\n",
    "        x = self.dropout(pooled_output)\n",
    "        if verbose:\n",
    "            print(f\"Dropout Layer's Output Shape: {x.shape}\")\n",
    "        logits = self.fc(x)\n",
    "        if verbose:\n",
    "            print(f\"Logits: {logits}\")\n",
    "            print(f\"Logits Shape: {logits.shape}\")\n",
    "\n",
    "        # You'd normally use softmax here, but the loss function\n",
    "        # in the next cell already uses it and you don't want to apply\n",
    "        # it twice.\n",
    "        return logits\n",
    "\n",
    "# Early stopping is a technique used to prevent overfitting by stopping\n",
    "# the model when the gap between the validation loss and accuracy loss\n",
    "# continues to increase after a point.\n",
    "# https://stackoverflow.com/questions/71998978/early-stopping-in-pytorch\n",
    "class EarlyStopping():\n",
    "    def __init__(self, patience=1, min_delta=0):\n",
    "        self.patience = patience\n",
    "        self.min_delta = min_delta\n",
    "        self.counter = 0\n",
    "        self.min_validation_loss = float('inf')\n",
    "\n",
    "    def early_stop(self, validation_loss):\n",
    "        if validation_loss < self.min_validation_loss:\n",
    "            self.min_validation_loss = validation_loss\n",
    "            self.counter = 0\n",
    "        elif validation_loss > (self.min_validation_loss + self.min_delta):\n",
    "            self.counter += 1\n",
    "            if self.counter >= self.patience:\n",
    "                return True\n",
    "        return False\n",
    "\n",
    "# 7. https://www.ibm.com/think/topics/embedding\n",
    "# 8. https://huggingface.co/docs/transformers/en/model_doc/bert?usage=AutoModel#transformers.BertModel.forward.returns\n",
    "# 9. https://discuss.huggingface.co/t/significance-of-the-cls-token/3180/6\n",
    "\n",
    "def train(model, data_loader, optimizer, scheduler, device, verbose=False):\n",
    "    expected = []\n",
    "    predictions = []\n",
    "    \n",
    "    model.train()\n",
    "\n",
    "    for batch in data_loader:\n",
    "    \n",
    "        # Resets Gradients to 0\n",
    "        optimizer.zero_grad()\n",
    "\n",
    "        # Model Inputs\n",
    "        input_ids = batch['input_ids'].to(device)\n",
    "        attention_mask = batch['attention_mask'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Input IDs: {input_ids}\")\n",
    "            print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "\n",
    "            print(f\"Attention Mask: {attention_mask}\")\n",
    "            print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "\n",
    "        # Model Target/Expected Output\n",
    "        labels = batch['label'].to(device)\n",
    "        if verbose:\n",
    "            print(f\"Labels: {labels}\")\n",
    "            print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "        # Model's Actual Output/Predictions\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "        if verbose:\n",
    "            print(f\"Outputs: {outputs}\")\n",
    "            print(f\"Outputs Shape: {outputs.shape}\")\n",
    "\n",
    "        # Gradient Descent and Backpropagation\n",
    "        loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "        loss.backward()\n",
    "\n",
    "        # These are both used to improve the model's learning\n",
    "        # in similar but different ways.\n",
    "        optimizer.step()\n",
    "        scheduler.step()\n",
    "\n",
    "        # Accuracy\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "        if verbose:\n",
    "            print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "        expected.extend(labels.cpu().tolist())\n",
    "        predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100, \n",
    "        \"report\": classification_report(expected, predictions, zero_division=0)\n",
    "    }\n",
    "\n",
    "def evaluate(model, data_loader, device, verbose=False):\n",
    "    model.eval()\n",
    "    \n",
    "    expected = []\n",
    "    predictions = []\n",
    "    losses = []\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for batch in data_loader:\n",
    "            # Model Inputs\n",
    "            input_ids = batch['input_ids'].to(device)\n",
    "            attention_mask = batch['attention_mask'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Input IDs: {input_ids}\")\n",
    "                print(f\"Input IDs Shape: {input_ids.shape}\")\n",
    "    \n",
    "                print(f\"Attention Mask: {attention_mask}\")\n",
    "                print(f\"Attention Mask Shape: {attention_mask.shape}\")\n",
    "    \n",
    "            # Model Target Output (Expected)\n",
    "            labels = batch['label'].to(device)\n",
    "            if verbose:\n",
    "                print(f\"Labels: {labels}\")\n",
    "                print(f\"Labels Shape: {labels.shape}\")\n",
    "\n",
    "            # Model's Actual Output/Predictions\n",
    "            # There's no loss being calculated here, so the softmax function\n",
    "            # is not being applied. Therefore, it's added here.\n",
    "            outputs = model(input_ids=input_ids, attention_mask=attention_mask, verbose=verbose)\n",
    "            if verbose:\n",
    "                print(f\"Outputs: {outputs}\")\n",
    "\n",
    "            # As early stopping is now being used, I'll have to calculate the loss.\n",
    "            loss = nn.CrossEntropyLoss()(outputs, labels)\n",
    "            if verbose:\n",
    "                print(f\"Loss: {loss}, {type(loss)}\")\n",
    "            losses.append(loss.item())\n",
    "            # outputs = nn.Softmax(dim=1)(outputs)\n",
    "            # if verbose:\n",
    "            #     print(f\"Outputs (After Softmax): {outputs}\")\n",
    "\n",
    "            # torch.max(...) returns \"a named tumple (values, indices) where values is the maximum\n",
    "            # value of each row of the input tensor in the given dimension dim. And indices is the index\"\n",
    "            # location of each maximum value found (argmax).\" [10] Since there's only 2 classes (0 and 1),\n",
    "            # and the two indices correspond to those classes, the line below is neat.\n",
    "            _, preds = torch.max(outputs, dim=1)\n",
    "            if verbose:\n",
    "                print(f\"Predictions:\\n\\t{_}\\n\\t{preds}\")\n",
    "\n",
    "            expected.extend(labels.cpu().tolist())\n",
    "            predictions.extend(preds.cpu().tolist())\n",
    "\n",
    "    # Loss\n",
    "    # Taking the average of the losses\n",
    "    # from each batch.\n",
    "    if verbose:\n",
    "        print(f\"Losses: {losses}\")\n",
    "    avg_loss = np.mean(losses)\n",
    "    \n",
    "    return {\n",
    "        \"accuracy\": accuracy_score(expected, predictions) * 100,\n",
    "        \"report\": classification_report(expected, predictions, zero_division=0),\n",
    "        \"loss\": avg_loss\n",
    "    }\n",
    "\n",
    "def predict(text, model, tokenizer, device, max_length=MAX_LENGTH, return_integer=False):\n",
    "    model.eval()\n",
    "    encoding = tokenizer(text, return_tensors='pt', max_length=max_length, padding='max_length', truncation=True)\n",
    "    input_ids = encoding['input_ids'].to(device)\n",
    "    attention_mask = encoding['attention_mask'].to(device)\n",
    "\n",
    "    with torch.no_grad():\n",
    "        outputs = model(input_ids=input_ids, attention_mask=attention_mask)\n",
    "        outputs = nn.Softmax(dim=1)(outputs)\n",
    "        _, preds = torch.max(outputs, dim=1)\n",
    "\n",
    "    if return_integer:\n",
    "        return preds.item()\n",
    "    return \"Example of TMII\" if preds.item() == 1 else \"No Example of TMII\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "b6ec5769-5817-4714-b106-40a966eac233",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "X_train Shape: (15,)\n",
      "y_train Shape: (15,)\n",
      "X_test Shape: (10,)\n",
      "y_test Shape: (10,)\n"
     ]
    }
   ],
   "source": [
    "X = dataset[\"Abstract\"].to_numpy()\n",
    "y = dataset[\"Score\"].apply(lambda score: 1 if score >= TARGET_THRESHOLD else 0).to_numpy()\n",
    "\n",
    "# Training and Validation/Test Sets\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.4, random_state=42)\n",
    "print(f\"X_train Shape: {X_train.shape}\")\n",
    "print(f\"y_train Shape: {y_train.shape}\")\n",
    "print(f\"X_test Shape: {X_test.shape}\")\n",
    "print(f\"y_test Shape: {y_test.shape}\")\n",
    "\n",
    "# The tokenizer is needed for the datasets and data loaders below,\n",
    "# which is why it's defined here. I probably didn't need to add this comment.\n",
    "tokenizer = BertTokenizer.from_pretrained(MODEL_NAME)\n",
    "\n",
    "# Train Dataset\n",
    "train_dataset = TextClassificationDataset(X_train, y_train, tokenizer, MAX_LENGTH)\n",
    "train_data_loader = DataLoader(train_dataset, batch_size=BATCH_SIZE, shuffle=True)\n",
    "\n",
    "# Validation Dataset\n",
    "val_dataset = TextClassificationDataset(X_test, y_test, tokenizer, MAX_LENGTH)\n",
    "val_data_loader = DataLoader(val_dataset, batch_size=BATCH_SIZE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "fc1e815d-62f1-4b98-a232-551f484b227b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/8\n",
      "Training Accuracy: 53.33%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[0.2248, 0.1764],\n",
      "        [0.1371, 0.1030]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[0.2248, 0.1764],\n",
      "        [0.1371, 0.1030]], device='cuda:0')\n",
      "Loss: 0.6897659301757812, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2248, 0.1371], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[0.2176, 0.0919],\n",
      "        [0.2618, 0.0302]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[0.2176, 0.0919],\n",
      "        [0.2618, 0.0302]], device='cuda:0')\n",
      "Loss: 0.6710115671157837, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2176, 0.2618], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[0.0700, 0.2001],\n",
      "        [0.2331, 0.1607]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[0.0700, 0.2001],\n",
      "        [0.2331, 0.1607]], device='cuda:0')\n",
      "Loss: 0.7089657783508301, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2001, 0.2331], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.3051, -0.0262],\n",
      "        [ 0.1780,  0.2662]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.3051, -0.0262],\n",
      "        [ 0.1780,  0.2662]], device='cuda:0')\n",
      "Loss: 0.7612612247467041, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3051, 0.2662], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.2868,  0.1154],\n",
      "        [ 0.2118, -0.0580]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.2868,  0.1154],\n",
      "        [ 0.2118, -0.0580]], device='cuda:0')\n",
      "Loss: 0.6749252080917358, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2868, 0.2118], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Losses: [0.6897659301757812, 0.6710115671157837, 0.7089657783508301, 0.7612612247467041, 0.6749252080917358]\n",
      "Validation Loss: 0.70\n",
      "Validation Accuracy: 50.00%\n",
      "\n",
      "\n",
      "Epoch 2/8\n",
      "Training Accuracy: 86.67%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.2120,  0.0648],\n",
      "        [-0.0880, -0.0484]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.2120,  0.0648],\n",
      "        [-0.0880, -0.0484]], device='cuda:0')\n",
      "Loss: 0.6479061841964722, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([ 0.2120, -0.0484], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0333, -0.0520],\n",
      "        [ 0.1366, -0.1273]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0333, -0.0520],\n",
      "        [ 0.1366, -0.1273]], device='cuda:0')\n",
      "Loss: 0.6532902717590332, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.0333, 0.1366], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0129,  0.0519],\n",
      "        [ 0.1103, -0.1419]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0129,  0.0519],\n",
      "        [ 0.1103, -0.1419]], device='cuda:0')\n",
      "Loss: 0.6439236402511597, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.0519, 0.1103], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.2228, -0.1785],\n",
      "        [-0.0305,  0.1339]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.2228, -0.1785],\n",
      "        [-0.0305,  0.1339]], device='cuda:0')\n",
      "Loss: 0.7640261650085449, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2228, 0.1339], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.1594, -0.0176],\n",
      "        [ 0.0849, -0.2522]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.1594, -0.0176],\n",
      "        [ 0.0849, -0.2522]], device='cuda:0')\n",
      "Loss: 0.6621475219726562, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.1594, 0.0849], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Losses: [0.6479061841964722, 0.6532902717590332, 0.6439236402511597, 0.7640261650085449, 0.6621475219726562]\n",
      "Validation Loss: 0.67\n",
      "Validation Accuracy: 60.00%\n",
      "\n",
      "\n",
      "Epoch 3/8\n",
      "Training Accuracy: 80.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.1948,  0.1232],\n",
      "        [-0.0220, -0.0231]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.1948,  0.1232],\n",
      "        [-0.0220, -0.0231]], device='cuda:0')\n",
      "Loss: 0.6758301854133606, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([ 0.1948, -0.0220], device='cuda:0')\n",
      "\ttensor([0, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0002,  0.0908],\n",
      "        [ 0.0176, -0.0211]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0002,  0.0908],\n",
      "        [ 0.0176, -0.0211]], device='cuda:0')\n",
      "Loss: 0.6613178849220276, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.0908, 0.0176], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0340,  0.1612],\n",
      "        [ 0.0875, -0.0240]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0340,  0.1612],\n",
      "        [ 0.0875, -0.0240]], device='cuda:0')\n",
      "Loss: 0.71723473072052, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.1612, 0.0875], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.3566, -0.1348],\n",
      "        [-0.1479,  0.2652]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.3566, -0.1348],\n",
      "        [-0.1479,  0.2652]], device='cuda:0')\n",
      "Loss: 0.738275945186615, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3566, 0.2652], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0282,  0.0640],\n",
      "        [ 0.1927, -0.2012]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0282,  0.0640],\n",
      "        [ 0.1927, -0.2012]], device='cuda:0')\n",
      "Loss: 0.5954577922821045, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.0640, 0.1927], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.6758301854133606, 0.6613178849220276, 0.71723473072052, 0.738275945186615, 0.5954577922821045]\n",
      "Validation Loss: 0.68\n",
      "Validation Accuracy: 70.00%\n",
      "\n",
      "\n",
      "Epoch 4/8\n",
      "Training Accuracy: 100.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0845,  0.3148],\n",
      "        [-0.1865,  0.2187]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0845,  0.3148],\n",
      "        [-0.1865,  0.2187]], device='cuda:0')\n",
      "Loss: 0.6629410982131958, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3148, 0.2187], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.1173,  0.2369],\n",
      "        [ 0.0065,  0.1119]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.1173,  0.2369],\n",
      "        [ 0.0065,  0.1119]], device='cuda:0')\n",
      "Loss: 0.639433741569519, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2369, 0.1119], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.1518,  0.3026],\n",
      "        [ 0.0599,  0.1342]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.1518,  0.3026],\n",
      "        [ 0.0599,  0.1342]], device='cuda:0')\n",
      "Loss: 0.8384605050086975, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3026, 0.1342], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.3577, -0.0584],\n",
      "        [-0.2777,  0.4820]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.3577, -0.0584],\n",
      "        [-0.2777,  0.4820]], device='cuda:0')\n",
      "Loss: 0.6532251834869385, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3577, 0.4820], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0152,  0.2216],\n",
      "        [ 0.2730, -0.1494]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0152,  0.2216],\n",
      "        [ 0.2730, -0.1494]], device='cuda:0')\n",
      "Loss: 0.5496783256530762, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2216, 0.2730], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.6629410982131958, 0.639433741569519, 0.8384605050086975, 0.6532251834869385, 0.5496783256530762]\n",
      "Validation Loss: 0.67\n",
      "Validation Accuracy: 50.00%\n",
      "\n",
      "\n",
      "Epoch 5/8\n",
      "Training Accuracy: 100.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0750,  0.3106],\n",
      "        [-0.0063,  0.1628]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0750,  0.3106],\n",
      "        [-0.0063,  0.1628]], device='cuda:0')\n",
      "Loss: 0.715018630027771, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3106, 0.1628], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0864,  0.2639],\n",
      "        [ 0.1070,  0.1109]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0864,  0.2639],\n",
      "        [ 0.1070,  0.1109]], device='cuda:0')\n",
      "Loss: 0.6141650676727295, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2639, 0.1109], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0977,  0.3007],\n",
      "        [ 0.2140,  0.0910]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0977,  0.3007],\n",
      "        [ 0.2140,  0.0910]], device='cuda:0')\n",
      "Loss: 0.7728022336959839, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3007, 0.2140], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.5398, -0.1759],\n",
      "        [-0.3388,  0.5739]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.5398, -0.1759],\n",
      "        [-0.3388,  0.5739]], device='cuda:0')\n",
      "Loss: 0.7255787253379822, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.5398, 0.5739], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0623,  0.2585],\n",
      "        [ 0.4877, -0.2660]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0623,  0.2585],\n",
      "        [ 0.4877, -0.2660]], device='cuda:0')\n",
      "Loss: 0.49277329444885254, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.2585, 0.4877], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.715018630027771, 0.6141650676727295, 0.7728022336959839, 0.7255787253379822, 0.49277329444885254]\n",
      "Validation Loss: 0.66\n",
      "Validation Accuracy: 60.00%\n",
      "\n",
      "\n",
      "Epoch 6/8\n",
      "Training Accuracy: 100.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[0.0430, 0.3070],\n",
      "        [0.0134, 0.1238]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[0.0430, 0.3070],\n",
      "        [0.0134, 0.1238]], device='cuda:0')\n",
      "Loss: 0.736647367477417, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3070, 0.1238], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.1957,  0.3174],\n",
      "        [ 0.0833,  0.1003]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.1957,  0.3174],\n",
      "        [ 0.0833,  0.1003]], device='cuda:0')\n",
      "Loss: 0.5854214429855347, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3174, 0.1003], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.1708,  0.3366],\n",
      "        [ 0.2225,  0.0316]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.1708,  0.3366],\n",
      "        [ 0.2225,  0.0316]], device='cuda:0')\n",
      "Loss: 0.7904720306396484, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3366, 0.2225], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.5880, -0.2408],\n",
      "        [-0.5022,  0.6543]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.5880, -0.2408],\n",
      "        [-0.5022,  0.6543]], device='cuda:0')\n",
      "Loss: 0.7322795391082764, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.5880, 0.6543], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0028,  0.3428],\n",
      "        [ 0.5021, -0.3310]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0028,  0.3428],\n",
      "        [ 0.5021, -0.3310]], device='cuda:0')\n",
      "Loss: 0.4480726718902588, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3428, 0.5021], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.736647367477417, 0.5854214429855347, 0.7904720306396484, 0.7322795391082764, 0.4480726718902588]\n",
      "Validation Loss: 0.66\n",
      "Validation Accuracy: 60.00%\n",
      "\n",
      "\n",
      "Epoch 7/8\n",
      "Training Accuracy: 100.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0071,  0.3337],\n",
      "        [-0.0278,  0.1518]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0071,  0.3337],\n",
      "        [-0.0278,  0.1518]], device='cuda:0')\n",
      "Loss: 0.7385354042053223, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3337, 0.1518], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.2888,  0.3764],\n",
      "        [ 0.0600,  0.1315]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.2888,  0.3764],\n",
      "        [ 0.0600,  0.1315]], device='cuda:0')\n",
      "Loss: 0.5721825361251831, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3764, 0.1315], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.2394,  0.3917],\n",
      "        [ 0.2072,  0.0403]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.2394,  0.3917],\n",
      "        [ 0.2072,  0.0403]], device='cuda:0')\n",
      "Loss: 0.8354394435882568, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3917, 0.2072], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.5911, -0.2503],\n",
      "        [-0.6177,  0.7364]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.5911, -0.2503],\n",
      "        [-0.6177,  0.7364]], device='cuda:0')\n",
      "Loss: 0.7147436738014221, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.5911, 0.7364], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0546,  0.4360],\n",
      "        [ 0.4880, -0.3408]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0546,  0.4360],\n",
      "        [ 0.4880, -0.3408]], device='cuda:0')\n",
      "Loss: 0.41995981335639954, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.4360, 0.4880], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.7385354042053223, 0.5721825361251831, 0.8354394435882568, 0.7147436738014221, 0.41995981335639954]\n",
      "Validation Loss: 0.66\n",
      "Validation Accuracy: 60.00%\n",
      "\n",
      "\n",
      "Epoch 8/8\n",
      "Training Accuracy: 100.00%\n",
      "Input IDs: tensor([[  102,  7555,  6341,   771,  1566,   282,  1159,  1328, 26022,   145,\n",
      "         23882,   546,   422,   130, 11899,  3467,   131, 21427,  7888,   129,\n",
      "           422,   165,   111,   617,  7039,  1427,   168,  9757,   145,  6226,\n",
      "           546,   602,   205,   694,   422, 23882,   165,   302,   130,  5312,\n",
      "          7039,   137,   434,   502,  1626,  4761,   862, 23882,  9160,  2487,\n",
      "          2249,  4826,  2089,   111,  1120,   131,  6226,   655,   121,  6946,\n",
      "           137,  3873,  3521,   137,   300,  2836, 23002, 23882,  1288,   121,\n",
      "         22825, 13386,  1736,  2374,   205, 23882, 12292,   106,   649,   131,\n",
      "          3052,  1014,   198,   220, 13086,  3646,   205,  1681,   137,   539,\n",
      "           407,  2576,  1595,  2606, 23882,  4684,  3492,  5939,  4384,   205,\n",
      "           121,   238,   527,   422,   185,  1260,  6935,  2519,   131,   111,\n",
      "         13701,   137,  4684,   131,  1041, 23882,  3983,   422,  5674,   643,\n",
      "          2576, 15313,   422,   121,  1066, 30118,   137,   103],\n",
      "        [  102,  4940,  4743,  4268,   780, 19885,   145,  2648, 30121,   546,\n",
      "           214,   106,  5521, 19459,   300,  7021,   111,  2829,  3277,   131,\n",
      "           106,   414, 18147, 19459,   137,   552,  4490,  1630, 23659,   626,\n",
      "          2465,   198, 25294,   263,  3966,  6755,   198,  1578,   650,   626,\n",
      "          2326,   198,  9889,   111,  5232,   131,  2379,  2965,   145,  3955,\n",
      "          5232,  3323,   546,   205,  4743,  4268,   780, 19885,   552,  6457,\n",
      "           111,  1382,   137,  6743,   131, 24729,   285,  1688,   422,   563,\n",
      "          2829,  3955, 10725,   552,  6367, 23653,   422,   190,   111,   414,\n",
      "         18147, 25232,   296,   257, 10032, 18634, 13864,   205,   121, 29111,\n",
      "          1078,   422,  2159, 23659, 12816,  1506,   241, 18371, 18901,   422,\n",
      "          8408,   111,  1382,   131,  2331, 23659, 15399,   511, 19759,   137,\n",
      "         14072,  1135,  2326,   131,  1198,   308,   426,   168,  3039,   422,\n",
      "         29111, 23659,  8030,  1578,   422,   555,   188,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.0084,  0.3284],\n",
      "        [-0.0284,  0.1458]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.0084,  0.3284],\n",
      "        [-0.0284,  0.1458]], device='cuda:0')\n",
      "Loss: 0.7378907203674316, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3284, 0.1458], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   121,  2177,   422,  1724,  2599,  7299,   422,  1623, 19759,\n",
      "           300,   360,  1532,  5726,  1056,   191,  5941,  2965,   214,  7879,\n",
      "          1334,   121,   111,  7378,   145,   139,   205,   159,   205,  3993,\n",
      "           422,  6983,  1975,   546,   131,  4959,  8348,   205,  1363,  1279,\n",
      "           165,  1721,  1011,  9491,   579,  6224,  5726,  2697,   145,  5178,\n",
      "          1465, 30113,   546,   121,   475,  1127,  2599,  8240,   422,   256,\n",
      "           434,   528,  2995,   198,   555,  3480, 10606,   499, 21537, 23959,\n",
      "           205,   185,  2959,  5178,  1465, 30113,   467,   106, 19459, 30126,\n",
      "         28995,   145,  4106,   153,  1048,  9793, 30113,   546,   137,   502,\n",
      "          8384,   179,  1060,  5941,  2965,   422, 27100,  1153, 17894,   145,\n",
      "          7661, 13371,   200,  6603, 19404,   546,   137,  2261, 20830,   671,\n",
      "           145,  6317,  4141, 21045,  2679,  4861,  1974,   546,   422,   334,\n",
      "           220, 10440,   214, 20565,  8753,   145,  2824,   103],\n",
      "        [  102,  4743,  4268,   780, 19885,   131, 15107, 29203,  5509, 23681,\n",
      "         22742,   129,  7049,  8864,   323,   145, 14432, 29203,  9602,   546,\n",
      "           214,  3115,   579, 23694,   140, 19759,   422, 10902,  3032, 30110,\n",
      "           470,   426,  5410, 26224,  8665,   145, 13695,  4983,  2526, 30107,\n",
      "           546,   552,  1847,   111,  5427,   131,  1937, 27054,  1078,   121,\n",
      "         17403, 29808,   870,  1837,  3996,   205,   185,  1822,   111,  1013,\n",
      "           131,   128,   205,   470,   426,  5410,  8268,   131,   146,   205,\n",
      "         23681, 22742,   129, 19314,   114,  1440,  1632,   121, 27659, 30113,\n",
      "           234,  9540, 11744, 30113,   422, 11530, 27659, 30113,   145,  1319,\n",
      "         29370, 30113,   546,   422,   137, 10261,  7668,   187, 27659, 30113,\n",
      "           205,   185,   469,  1058, 29370, 15255,   263, 19314,   114, 27659,\n",
      "         30113,   137,  9540, 11744, 30113,   603,   128,   205,   470,   426,\n",
      "          5410,   267,   302,   709,   205, 10902,  3032,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.2987,  0.3779],\n",
      "        [ 0.0784,  0.1314]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.2987,  0.3779],\n",
      "        [ 0.0784,  0.1314]], device='cuda:0')\n",
      "Loss: 0.5655165910720825, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3779, 0.1314], device='cuda:0')\n",
      "\ttensor([1, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,   111, 21221,   579,  6224,  4408,  6543,  3323,   145,  4842,\n",
      "           339,   546, 18636, 30113,   198,   106,  2529,  1578,   300, 12151,\n",
      "          2637,  1503,   131, 21076,   422,   137,   959,   593,   932,   422,\n",
      "           214,  3910, 21221,   168, 20565,  1343,   131,   475,  4449, 22354,\n",
      "          7160,  3528,   205,   543,   111,  4842,   339,  9203,   147,  2300,\n",
      "          5633, 11436, 30110, 23662, 11901,  2219,   422,   130,  7862,  2983,\n",
      "          1668,   190,  8505,   422, 17720, 16806,   119, 22454,   342,   422,\n",
      "           259,  3754,   145,   106,   546,   475, 28526,  9497,   582,   111,\n",
      "          7862,   165,   709,   422,  3909,   198,   256,  2315,   475,  4279,\n",
      "          9355,   422,   145,   132,   546,  2110, 20565,   479,   191,  3528,\n",
      "          7160,   111,  7862,   506,   191,   111,  7862,  3987,   422,  3909,\n",
      "           256,   165,   302,   106,  2599,  1908,   422,   137,   145,   115,\n",
      "           546,  1797, 20565,   479,   191, 10384,  3528,   103],\n",
      "        [  102,  4150,  3533,   111,  5411,  3512,   198,  5726,  2697,  1017,\n",
      "          1578,  2449,   300,  2100,  2599,  2987,  3277,   422,  4808,  1775,\n",
      "          3492,  4346,   205,   185,  3768,   539,   111,  2141,   131, 14577,\n",
      "           191,  5518,  1187,   137,  3405,   300,  6049,   443,   217,  2186,\n",
      "         21537,  1049,   214, 16906,  4408,  6543,   121,   106,  1135,   579,\n",
      "          4781,   120,  2599,  2987,  7178,   147, 28094,  4220,   205,  8274,\n",
      "          1213,  5881, 18360, 19435,  8715,   106,  1441,  1535,   121, 18267,\n",
      "          5335,  9723,   198,  4541,   119,   533,   531,   422,   334, 11742,\n",
      "           690,  4408,  6543,   467,   533,   531,   137, 14572,   120, 25347,\n",
      "          3234,   833, 19363, 19885,   205,  3380,  1265,   131, 25347,  3234,\n",
      "          6728, 12151,  1482,   147,  2465,   131, 12483,   137,  1168,  2687,\n",
      "           422,   190,   111,   254,  4268, 17649, 15770,  1001,  1265,   603,\n",
      "          8930, 10730, 12336, 24445,   119,   214,  5881,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([0, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.2441,  0.3958],\n",
      "        [ 0.2256,  0.0305]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.2441,  0.3958],\n",
      "        [ 0.2256,  0.0305]], device='cuda:0')\n",
      "Loss: 0.8319011926651001, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.3958, 0.2256], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  2740,   256,   165,  7261,  5168,   198,  4631,  8034, 30110,\n",
      "          9872, 14233,   603,   106,  2529,  2505,   112,  3026,  7006,   165,\n",
      "         24344,   191,  2773,   106,  8034, 30110,  6166,  3490,   506,   111,\n",
      "         17589,   131,   111, 18225,  2505,   112, 26907,  1688,   422,   137,\n",
      "           198, 26907,  1688, 14233,  1661,   579,  3490, 17589, 30113,   923,\n",
      "          2374,   190,  3490, 17589, 30113,   300,   831,   475,  1593, 24876,\n",
      "           263, 17912,   205,   106,  2151,   437,  1402,   198,   422,   121,\n",
      "           111,  1735,   131, 26907,  1688,   190,  1113,   137,  2001, 17589,\n",
      "         30113,   198,  2899,  3955,  6543,   422, 17260,   140,  2529,  1578,\n",
      "           300,  5540,   303,   121,  8034, 30110,   579,  6166,  3826,   422,\n",
      "           923,   238,  2348,   111,  4079,   131, 13149, 13092,   198, 24662,\n",
      "           191,   304,   579,  1154, 17912,   205,  4964,  1352,  6060,  2116,\n",
      "           185,   360,  3956,   111,   437,   147,   527,   103],\n",
      "        [  102,  3350,  1045,   147,  3120, 10886,  7675,  1865,   969,  4443,\n",
      "           111,   626,   131,  2828, 19006,   422,   555,   188,  3157,   602,\n",
      "           422,   220,  7484,  2764,   205,   111, 17487,   131,  9491,   579,\n",
      "          6224,  5726,  2697,   145,  5178,  1465, 30113,   546,   422,   121,\n",
      "           334, 19038, 30113,  9676,   547,  1689,   121,  1278,   147,   693,\n",
      "          9190,   145,   139,   205,   159,   205,   422, 22068, 30113,   137,\n",
      "           494,  6317,  4470, 30113,   546,   147,  2946, 19885,  1265,   422,\n",
      "           552,   195,   106,  1263,  2691,   205,   121,   238,   527,   422,\n",
      "           185,  2733,   111,   907,   131,  5178,  1465, 30113,   131,   502,\n",
      "         17093,  4129,  1578,   422,  1443, 16356, 12119,   192,   337,   829,\n",
      "          4078, 19371,   137, 10366,  2218,   903, 13599,  4614,   200,   422,\n",
      "           191,   111,  5478,   335, 29633,  3993,   131,  1866,  6481, 17324,\n",
      "          2219,   145,  6332, 24969,   862,  1094,   417,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 1], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[ 0.6094, -0.2750],\n",
      "        [-0.6357,  0.7537]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[ 0.6094, -0.2750],\n",
      "        [-0.6357,  0.7537]], device='cuda:0')\n",
      "Loss: 0.7263206243515015, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.6094, 0.7537], device='cuda:0')\n",
      "\ttensor([0, 1], device='cuda:0')\n",
      "Input IDs: tensor([[  102,  5575, 15716,  6422,   153, 11678, 30109,   137, 15107, 29203,\n",
      "          5509, 16141, 17000,   422,   502,  1578,   131, 14432, 29203,   173,\n",
      "         29370, 30113,   198,   220,  4276,   501,   168,   111,   602,   131,\n",
      "           952,  1639,  3224, 19038, 30113,   422,   267,   797,   147,   304,\n",
      "           579,  1259,   191,  6123, 19363, 18354,   121,  5448, 24079, 19123,\n",
      "           205,   185,  3003,   111,  4047,   131,  4743,  4268,   780, 19885,\n",
      "           145,  2648, 30121,   546,   467,   106,   205, 11678, 30109,   137,\n",
      "           146,   205, 16141, 17000,   147,  5610,   111,  2697,   137, 23653,\n",
      "           131,   407,   502,  1578,   205, 19885,   137,  5478,   335, 29633,\n",
      "           131,   111,   502, 19759,   191, 24693,  9705, 27233,   267,  1649,\n",
      "           137,  1031,   190, 13588,  9560,   255,   153,  8957,  6167,   234,\n",
      "         19811, 30110, 13149,   188,  2599,   422,   234,  1319,  3350,  2599,\n",
      "           205,   111,  3380,  1013,   131,   146,   205,   103],\n",
      "        [  102,  4940,  1001,   993,  2697,   145,  4559,   129,   546,   360,\n",
      "           528,  2995,   147, 16898,  6555,  8384,  5904,   205,   694,   422,\n",
      "           547,  1447,   121,  7732,  1578, 23653,   263,   111,  5211,   131,\n",
      "          5901, 23653,  1983,   165,   302,  1721,   205,  1530,   422,   487,\n",
      "          5957,  7259,  3776,   579,  2593, 25806, 30110,   437,   422,   185,\n",
      "          7004,   106,  1196,  3346,   168,  1578, 23653, 12088,   214,  4559,\n",
      "           129,   205,   185,   405,   198,   582, 11281,  1578,  2697,  1871,\n",
      "           147,  6241,  1578, 23653,   121,  2340,   131,  7424,  7684,  1595,\n",
      "           422,  1980,  4559,   129,   198, 14733,  2674, 11281,  6543,   422,\n",
      "           694,   422,   300,  6241, 23653,  1966,   198,  4559,   129, 10469,\n",
      "         27152,  9705,  6543,   475,   506,  7367,  9705,  6543,   205,   121,\n",
      "          2144,   422,  1532,  4559,   129,   198, 19893, 11281,  6543,   300,\n",
      "         16898, 23653,  2186,   106,  3668,  1493,   131,   103]],\n",
      "       device='cuda:0')\n",
      "Input IDs Shape: torch.Size([2, 128])\n",
      "Attention Mask: tensor([[1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1],\n",
      "        [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1,\n",
      "         1, 1, 1, 1, 1, 1, 1, 1]], device='cuda:0')\n",
      "Attention Mask Shape: torch.Size([2, 128])\n",
      "Labels: tensor([1, 0], device='cuda:0')\n",
      "Labels Shape: torch.Size([2])\n",
      "Pooled Output Shape: torch.Size([2, 768])\n",
      "Dropout Layer's Output Shape: torch.Size([2, 768])\n",
      "Logits: tensor([[-0.0424,  0.4550],\n",
      "        [ 0.4972, -0.3601]], device='cuda:0')\n",
      "Logits Shape: torch.Size([2, 2])\n",
      "Outputs: tensor([[-0.0424,  0.4550],\n",
      "        [ 0.4972, -0.3601]], device='cuda:0')\n",
      "Loss: 0.4143746495246887, <class 'torch.Tensor'>\n",
      "Predictions:\n",
      "\ttensor([0.4550, 0.4972], device='cuda:0')\n",
      "\ttensor([1, 0], device='cuda:0')\n",
      "Losses: [0.7378907203674316, 0.5655165910720825, 0.8319011926651001, 0.7263206243515015, 0.4143746495246887]\n",
      "Validation Loss: 0.66\n",
      "Validation Accuracy: 60.00%\n",
      "\n",
      "\n"
     ]
    }
   ],
   "source": [
    "model = BERTClassifier().to(device)\n",
    "\n",
    "optimizer = AdamW(model.parameters(), lr=LEARNING_RATE, no_deprecation_warning=True)\n",
    "scheduler = get_linear_schedule_with_warmup(optimizer, num_warmup_steps=0, num_training_steps=len(train_data_loader) * NUM_EPOCHS)\n",
    "early_stopping = EarlyStopping(patience=3, min_delta=10)\n",
    "\n",
    "# Train the Model\n",
    "for epoch in range(NUM_EPOCHS):\n",
    "    print(f\"Epoch {epoch + 1}/{NUM_EPOCHS}\")\n",
    "\n",
    "    # Train\n",
    "    train_performance = train(model, train_data_loader, optimizer, scheduler, device, verbose=False)\n",
    "    print(f\"Training Accuracy: {train_performance['accuracy']:.2f}%\")\n",
    "\n",
    "    # Validate\n",
    "    val_performance = evaluate(model, val_data_loader, device, verbose=False)\n",
    "    print(f\"Validation Loss: {val_performance['loss']:.2f}\")\n",
    "    print(f\"Validation Accuracy: {val_performance['accuracy']:.2f}%\\n\")\n",
    "\n",
    "    # Early Stop\n",
    "    if early_stopping.early_stop(val_performance['loss']):\n",
    "        print(\"Early Stopping\")\n",
    "        break\n",
    "\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "b7958770-4e79-47a4-bcd6-431d7a478203",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Moving beyond linear food chains: trait-mediated indirect interactions in a rocky intertidal food web\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Keep Your Eggs Away: Ant Presence Reduces Ceratitis capitata Oviposition Behaviour through Trait-Mediated Indirect Interactions\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Higher Order Interactions in Ecological Communities: What Are They and How Can They be Detected?\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Competition Between Aquatic Insects and Vertebrates: Interaction Strength and Higher Order Interactions\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "The mechanistic basis for higher-order interactions and non-additivity in competitive communities\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Higher order interactions and species coexistence\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Coexistence in diverse communities with higher-order interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Coexistence in diverse communities with higher-order interactions\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Variable Virulence and Efficacy of BCG Vaccine Strains in Mice and Correlation With Genome Polymorphisms\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Insect-mediated apparent competition between mammals in a boreal food web\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Global Warming Could Magnify Insect-Driven Apparent Competition Between Native and Introduced Host Plants in Sub-Antarctic Islands\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Refuge-mediated apparent competition in a tallgrass prairie?\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Data from: Density-dependent indirect effects: apparent mutualism and apparent competition coexist in a two-prey system\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Resource Competition Triggers the Co-Evolution of Long Tongues and Deep Corolla Tubes\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Intraguild Predation of Beneficial Arthropods by Red Imported Fire Ants in Cotton\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Facultative Intraguild Predation by Larval Cerambycidae (Coleoptera) on Bark Beetle Larvae (Coleoptera: Scolytidae): Fig. 1.\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "The roles of habitat and intraguild predation by coyotes on the spatial dynamics of kit foxes\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Top predators and habitat complexity alter an intraguild predation module in pond communities\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Temperature dependency of intraguild predation between native and invasive crabs\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Does nitrogen limitation promote intraguild predation in an aphidophagous ladybird?\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Competition and intraguild predation between the braconid parasitoid<i>Bracon hylobii</i>and the entomopathogenic nematode<i>Heterorhabditis downesi</i>, natural enemies of the large pine weevil,<i>Hylobius abietis</i>\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Competitive Plant-Mediated and Intraguild Predation Interactions of the Invasive Spodoptera frugiperda and Resident Stemborers Busseola fusca and Chilo partellus in Maize Cropping Systems in Kenya\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Diet type and prey preference of predators affect intraguild predation between Amblyseius andersoni and Neoseiulus barkeri\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Impact of intraspecific and intraguild predation on predator invasion and coexistence. Can exotic ladybeetles displace native species\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Slow-Release Sachets of Neoseiulus cucumeris Predatory Mites Reduce Intraguild Predation by Dalotia coriaria in Greenhouse Biological Control Systems\n",
      "\tPredicted: 'Example of TMII'\n",
      "\n",
      "Toxicity of CeO<sub>2</sub>nanoparticles on a freshwater experimental trophic chain: A study in environmentally relevant conditions through the use of mesocosms\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "The effect of copper stress on inter-trophic relationships in a model tri-trophic food chain.\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n",
      "Data from: Density-dependent indirect effects: apparent mutualism and apparent competition coexist in a two-prey system\n",
      "\tPredicted: 'No Example of TMII'\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# # Try It Out\n",
    "# df = pd.read_csv(\"../../Datasets/Baseline-1.csv\")\n",
    "# # texts = []\n",
    "\n",
    "# for i, row in df.iterrows():\n",
    "#     is_example = predict(row['Abstract'], model, tokenizer, device)\n",
    "#     print(row['Title'])\n",
    "#     print(f\"\\tPredicted: '{is_example}'\")\n",
    "#     print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "54d0b6fb-03e8-4bd2-a395-eef0f050c39f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(name, verbose=False):\n",
    "    # Load Dataset\n",
    "    data = load_preprocessed_dataset(name)\n",
    "\n",
    "    if data.shape[0] == 0:\n",
    "        print(\"Nothing to Score\")\n",
    "        return\n",
    "    \n",
    "    # Run Model\n",
    "    data['Score'] = data['Abstract'].apply(lambda abstract: predict(abstract, model, tokenizer, device, return_integer=True))\n",
    "    data.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "1c64ed6f-f712-4779-8306-4670d3045dbb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (4, 4)\n",
      "Data Shape: (28, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (150, 4)\n",
      "Data Shape: (3, 4)\n",
      "Data Shape: (6, 4)\n",
      "Data Shape: (4, 4)\n",
      "Data Shape: (153, 4)\n",
      "Data Shape: (52, 4)\n"
     ]
    }
   ],
   "source": [
    "dataset_names = [\"Examples\", \"Baseline-1\", \"SubA\", \"SubAFiltered\", \"SubB\", \"SubBFiltered\", \"C\", \"CFiltered\", \"D\", \"DFiltered\"]\n",
    "for name in dataset_names:\n",
    "    scored_data = score_dataset(name)\n",
    "    store_scored_dataset(scored_data, name, version='')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "6a96c2fd-dda5-4a4e-8bed-7265015611bb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 85.19%\n"
     ]
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAfIAAAG2CAYAAACEWASqAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjMsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvZiW1igAAAAlwSFlzAAAPYQAAD2EBqD+naQAAKhZJREFUeJzt3Xt8FfW57/HvJJiVAFnhoiREwq0oF8GgoGy0KmwRREUox7K1uBtBba0gCKJAu8NVjHcpSkHxAvSA4lFhK7V2UwSBgpcQ8UiL4RYxXAJ6IoQEc2HNnD8iq40BycrMylqz5vN+veZV18yamSc1L588z+83vzEsy7IEAABcKS7SAQAAgPojkQMA4GIkcgAAXIxEDgCAi5HIAQBwMRI5AAAuRiIHAMDFSOQAALgYiRwAABcjkQMA4GIkcgAAwmDDhg0aMmSI0tPTZRiGVq1aFTxWVVWlyZMnq0ePHmrSpInS09P1y1/+UgcPHgz5PiRyAADCoKysTJmZmZo/f36tYydOnFBeXp6ys7OVl5ent956S/n5+br55ptDvo/BS1MAAAgvwzC0cuVKDRs27Izf+eSTT3T55Zdr3759atu2bZ2v3ciB+CLGNE0dPHhQycnJMgwj0uEAAEJkWZaOHz+u9PR0xcWFr0lcXl6uyspK29exLKtWvvH5fPL5fLavfezYMRmGoWbNmoV0nqsT+cGDB5WRkRHpMAAANhUWFqpNmzZhuXZ5ebk6tGuqoiMB29dq2rSpSktLa+ybPn26ZsyYYeu65eXlmjx5sm677Tb5/f6QznV1Ik9OTpYk7ctrL39ThvsRm4Zm/SLSIQBhc/JkhTZ/8kTwv+fhUFlZqaIjAe3b2l7+5PrnipLjptr1+lKFhYU1kq3daryqqkojRoyQZVlasGBByOe7OpGfam/4m8bZ+pcDRLNGjRIjHQIQdg0xPNo02VDT5Prfx9T3OcfvD7lqPpNTSXzfvn16//3363VdVydyAADqKmCZCtiY3h2wTOeC0T+T+K5du7Ru3Tq1bNmyXtchkQMAPMGUJVP1z+ShnltaWqrdu3cHPxcUFGjbtm1q0aKFWrdurVtuuUV5eXlavXq1AoGAioqKJEktWrRQQkJCne9DIgcAIAxyc3PVv3//4OeJEydKkrKysjRjxgy9/fbbkqSePXvWOG/dunXq169fne9DIgcAeIIpU3aa46Ge3a9fP/3YUi1OLeNCIgcAeELAshSwkTztnBtOTPUGAMDFqMgBAJ7Q0JPdGgqJHADgCaYsBWIwkdNaBwDAxajIAQCeQGsdAAAXY9Y6AACIOlTkAABPML/f7JwfjUjkAABPCNictW7n3HAikQMAPCFgyebbz5yLxUmMkQMA4GJU5AAAT2CMHAAAFzNlKCDD1vnRiNY6AAAuRkUOAPAE06re7JwfjUjkAABPCNhsrds5N5xorQMA4GJU5AAAT4jVipxEDgDwBNMyZFo2Zq3bODecaK0DAOBiVOQAAE+gtQ4AgIsFFKeAjUZ0wMFYnEQiBwB4gmVzjNxijBwAADiNihwA4AmMkQMA4GIBK04By8YYeZQu0UprHQAAF6MiBwB4gilDpo361VR0luQkcgCAJ8TqGDmtdQAAXIyKHADgCfYnu9FaBwAgYqrHyG28NIXWOgAAcBoVOQDAE0yba60zax0AgAhijBwAABczFReTz5EzRg4AgItRkQMAPCFgGQrYeBWpnXPDiUQOAPCEgM3JbgFa6wAAwGlU5AAATzCtOJk2Zq2bzFoHACByaK0DAICoQ0UOAPAEU/ZmnpvOheIoEjkAwBPsLwgTnU3s6IwKAADUCRU5AMAT7K+1Hp21L4kcAOAJsfo+chI5AMATYrUij86oAABAnVCRAwA8wf6CMNFZ+5LIAQCeYFqGTDvPkUfp28+i888LAABQJ1TkAABPMG221qN1QRgSOQDAE+y//Sw6E3l0RgUAgMtt2LBBQ4YMUXp6ugzD0KpVq2octyxL06ZNU+vWrZWUlKQBAwZo165dId+HRA4A8ISADNtbKMrKypSZman58+ef9vjjjz+uefPmaeHChfroo4/UpEkTDRo0SOXl5SHdh9Y6AMATGrq1PnjwYA0ePPi0xyzL0ty5c/Vf//VfGjp0qCRp6dKlSk1N1apVq3TrrbfW+T5U5AAAhKCkpKTGVlFREfI1CgoKVFRUpAEDBgT3paSkqE+fPtqyZUtI1yKRAwA8ISC77fVqGRkZSklJCW45OTkhx1JUVCRJSk1NrbE/NTU1eKyuaK0DADzBqdZ6YWGh/H5/cL/P57Mdmx0kcgCAJzj10hS/318jkddHWlqaJOnw4cNq3bp1cP/hw4fVs2fPkK5Fax0AgAbWoUMHpaWlae3atcF9JSUl+uijj9S3b9+QrkVFDgDwBMvm+8itEM8tLS3V7t27g58LCgq0bds2tWjRQm3bttX999+vhx9+WBdccIE6dOig7Oxspaena9iwYSHdh0QOAPCEhn4feW5urvr37x/8PHHiRElSVlaWFi9erIceekhlZWX61a9+paNHj+qnP/2p3nvvPSUmJoZ0HxI5AABh0K9fP1mWdcbjhmFo1qxZmjVrlq37kMgBAJ4Qq68xJZEDADwhYPPtZ3bODafojAoAANQJFTkAwBNorQMA4GKm4mTaaETbOTecojMqAABQJ1TkAABPCFiGAjba43bODScSOQDAExgjBwDAxSybbz+zbJwbTtEZFQAAqBMqcgCAJwRkKGDjpSl2zg0nEjkAwBNMy944t3nmZdMjitY6AAAuRkWOWj7/sIn+zx9aadfnjVV8+BxNf6lAVww+Jkk6WSUtfqy1Pnnfr0P7EtTEb+qSq47rzt8eVMu0kxGOHKifm677QkMG7lTqeaWSpH37m+l/v3GxPtnWJsKRwUmmzcluds4Np6iIav78+Wrfvr0SExPVp08fffzxx5EOydPKT8Sp40Xfaewj+2sdq/guTrs/b6xf3H9Y8/+yU9NeLND+PT5Nv6NjBCIFnPFNcRO9tPxSjZlyk8ZMvVHbtqdp5kPr1K7Nt5EODQ4yZdjeolHEK/IVK1Zo4sSJWrhwofr06aO5c+dq0KBBys/PV6tWrSIdnidd9u/Hddm/Hz/tsSZ+U4+u2FNj35g5+zXuhs46sv8ctWpT1RAhAo76cGtGjc+vvHapbhqYr64XfKN9+5tHKCqgbiJekT/99NO6++67NWrUKHXr1k0LFy5U48aN9fLLL0c6NNRRWUm8DMNSk5RApEMBbIszTPW7okCJvpP6x87zIh0OHHRqZTc7WzSKaEVeWVmprVu3aurUqcF9cXFxGjBggLZs2RLByFBXleWGXpqTrn7DvlWTZDPS4QD11j7jW82b864Szgnou/JGmvlkf311oFmkw4KDYnWMPKKJ/JtvvlEgEFBqamqN/ampqfriiy9qfb+iokIVFRXBzyUlJWGPEWd2skqa8+v2kiXd92jt8XTATfYf9OueB4eoSeMqXfVvX+rBMZv0wPTrSeaIetH558UZ5OTkKCUlJbhlZGSc/SSExakkfvhAgnJe20M1Dtc7GYjXwcN+7SpoqZdf7aW9X7bQz27YEemw4CBTRnC99XptUTrZLaKJ/Nxzz1V8fLwOHz5cY//hw4eVlpZW6/tTp07VsWPHglthYWFDhYp/cSqJHyjw6dEVu+Vvwdg4Yo8RZynhHH63Y4llc8a6RSKvLSEhQb169dLatWuD+0zT1Nq1a9W3b99a3/f5fPL7/TU2OO+7sjjt2Z6kPduTJElFhQnasz1JR/afo5NV0uy7O2jnZ401+bl9MgOGio80UvGRRqqqjM5fcuBsRt+2VT26Fin1vFK1z/hWo2/bqsxuRVq7kccqY4mtatzmm9PCKeKPn02cOFFZWVnq3bu3Lr/8cs2dO1dlZWUaNWpUpEPzrJ2fNdZDt3QKfn5+xvmSpOtGFOv2B4r04f+kSJLuva5LjfMef2O3Mq8obbhAAYc0SynXQ2M2qUXz71R2IkEF+5pr6pzrlPd5eqRDA84q4on8P/7jP/T1119r2rRpKioqUs+ePfXee+/VmgCHhpN5Ran+cnDbGY//2DHAjZ5eeGWkQ0ADYNZ6GI0dO1Zjx46NdBgAgBhmtz0era316PzzAgAA1ElUVOQAAISb3fXSo/XxMxI5AMATaK0DAICoQ0UOAPCEWK3ISeQAAE+I1UROax0AABejIgcAeEKsVuQkcgCAJ1iy9wiZ5VwojiKRAwA8IVYrcsbIAQBwMSpyAIAnxGpFTiIHAHhCrCZyWusAALgYFTkAwBNitSInkQMAPMGyDFk2krGdc8OJ1joAAC5GRQ4A8ATeRw4AgIvF6hg5rXUAAFyMihwA4AmxOtmNRA4A8IRYba2TyAEAnhCrFTlj5AAAuBgVOQDAEyybrfVorchJ5AAAT7AkWZa986MRrXUAAFyMihwA4AmmDBms7AYAgDsxax0AAEQdKnIAgCeYliEjBheEoSIHAHiCZdnfQhEIBJSdna0OHTooKSlJP/nJTzR79mxZdqbOnwYVOQAAYfDYY49pwYIFWrJkiS666CLl5uZq1KhRSklJ0bhx4xy7D4kcAOAJDT3ZbfPmzRo6dKhuvPFGSVL79u316quv6uOPP653DKdDax0A4AmnErmdLRRXXHGF1q5dq507d0qSPvvsM23atEmDBw929OeiIgcAeIJTk91KSkpq7Pf5fPL5fLW+P2XKFJWUlKhLly6Kj49XIBDQnDlzNHLkyHrHcDpU5AAAhCAjI0MpKSnBLScn57Tfe/3117Vs2TItX75ceXl5WrJkiZ588kktWbLE0XioyAEAnlCfmec/PF+SCgsL5ff7g/tPV41L0oMPPqgpU6bo1ltvlST16NFD+/btU05OjrKysuofyA+QyAEAnlCdyO1Mdqv+X7/fXyORn8mJEycUF1ez8R0fHy/TNOsdw+mQyAEACIMhQ4Zozpw5atu2rS666CJ9+umnevrppzV69GhH70MiBwB4QkM/fvbss88qOztb9957r44cOaL09HT9+te/1rRp0+odw+mQyAEAnmDJ3jvFQz03OTlZc+fO1dy5c23c9eyYtQ4AgItRkQMAPCFWX2NKIgcAeEND99YbCIkcAOANNityRWlFzhg5AAAuRkUOAPAEp1Z2izYkcgCAJ8TqZDda6wAAuBgVOQDAGyzD3oS1KK3ISeQAAE+I1TFyWusAALgYFTkAwBu8vCDM22+/XecL3nzzzfUOBgCAcInVWet1SuTDhg2r08UMw1AgELATDwAACEGdErlpmuGOAwCA8IvS9rgdtsbIy8vLlZiY6FQsAACETay21kOetR4IBDR79mydf/75atq0qfbu3StJys7O1ksvveR4gAAAOMJyYItCISfyOXPmaPHixXr88ceVkJAQ3N+9e3e9+OKLjgYHAAB+XMiJfOnSpXrhhRc0cuRIxcfHB/dnZmbqiy++cDQ4AACcYziwRZ+Qx8gPHDigTp061dpvmqaqqqocCQoAAMfF6HPkIVfk3bp108aNG2vtf+ONN3TJJZc4EhQAAKibkCvyadOmKSsrSwcOHJBpmnrrrbeUn5+vpUuXavXq1eGIEQAA+6jIqw0dOlTvvPOO/vrXv6pJkyaaNm2aduzYoXfeeUfXXXddOGIEAMC+U28/s7NFoXo9R37VVVdpzZo1TscCAABCVO8FYXJzc7Vjxw5J1ePmvXr1ciwoAACcFquvMQ05ke/fv1+33Xab/va3v6lZs2aSpKNHj+qKK67Qa6+9pjZt2jgdIwAA9jFGXu2uu+5SVVWVduzYoeLiYhUXF2vHjh0yTVN33XVXOGIEAABnEHJF/sEHH2jz5s3q3LlzcF/nzp317LPP6qqrrnI0OAAAHGN3wlqsTHbLyMg47cIvgUBA6enpjgQFAIDTDKt6s3N+NAq5tf7EE0/ovvvuU25ubnBfbm6uxo8fryeffNLR4AAAcEyMvjSlThV58+bNZRj/bCmUlZWpT58+atSo+vSTJ0+qUaNGGj16tIYNGxaWQAEAQG11SuRz584NcxgAAISZl8fIs7Kywh0HAADhFaOPn9V7QRhJKi8vV2VlZY19fr/fVkAAAKDuQp7sVlZWprFjx6pVq1Zq0qSJmjdvXmMDACAqxehkt5AT+UMPPaT3339fCxYskM/n04svvqiZM2cqPT1dS5cuDUeMAADYF6OJPOTW+jvvvKOlS5eqX79+GjVqlK666ip16tRJ7dq107JlyzRy5MhwxAkAAE4j5Iq8uLhYHTt2lFQ9Hl5cXCxJ+ulPf6oNGzY4Gx0AAE6J0deYhpzIO3bsqIKCAklSly5d9Prrr0uqrtRPvUQFAIBoc2plNztbNAo5kY8aNUqfffaZJGnKlCmaP3++EhMTNWHCBD344IOOBwgAAM4s5DHyCRMmBP95wIAB+uKLL7R161Z16tRJF198saPBAQDgGJ4jP7127dqpXbt2TsQCAABCVKdEPm/evDpfcNy4cfUOBgCAcDFk8+1njkXirDol8meeeaZOFzMMg0QOAEADqlMiPzVLPVr97MIeamScE+kwgLCYsfflSIcAhE3ZcVMbGmp6lZdfmgIAgOvF6GS3kB8/AwAA0YOKHADgDTFakZPIAQCeYHd1tphZ2Q0AAESPeiXyjRs36vbbb1ffvn114MABSdIf//hHbdq0ydHgAABwTIy+xjTkRP7mm29q0KBBSkpK0qeffqqKigpJ0rFjx/TII484HiAAAI4gkVd7+OGHtXDhQi1atEjnnPPPZ7evvPJK5eXlORocAAD4cSFPdsvPz9fVV19da39KSoqOHj3qREwAADiOyW7fS0tL0+7du2vt37Rpkzp27OhIUAAAOO7Uym52tigUciK/++67NX78eH300UcyDEMHDx7UsmXLNGnSJP3mN78JR4wAANgXo2PkIbfWp0yZItM0de211+rEiRO6+uqr5fP5NGnSJN13333hiBEAAJxByBW5YRj63e9+p+LiYm3fvl0ffvihvv76a82ePTsc8QEA4IhTY+R2tlAdOHBAt99+u1q2bKmkpCT16NFDubm5jv5c9V7ZLSEhQd26dXMyFgAAwqeBl2j99ttvdeWVV6p///7685//rPPOO0+7du1S8+bNbQRRW8iJvH///jKMMw/4v//++7YCAgAgFjz22GPKyMjQK6+8EtzXoUMHx+8Tcmu9Z8+eyszMDG7dunVTZWWl8vLy1KNHD8cDBADAEXbb6t9X5CUlJTW2Uwuj/dDbb7+t3r176+c//7latWqlSy65RIsWLXL8xwq5In/mmWdOu3/GjBkqLS21HRAAAGHhUGs9IyOjxu7p06drxowZtb6+d+9eLViwQBMnTtRvf/tbffLJJxo3bpwSEhKUlZVlI5CaHHv72e23367LL79cTz75pFOXBAAg6hQWFsrv9wc/+3y+037PNE317t07uHz5JZdcou3bt2vhwoWOJnLH3n62ZcsWJSYmOnU5AACc5dBz5H6/v8Z2pkTeunXrWpPCu3btqq+++srRHyvkinz48OE1PluWpUOHDik3N1fZ2dmOBQYAgJMaeonWK6+8Uvn5+TX27dy5U+3atat/EKcRciJPSUmp8TkuLk6dO3fWrFmzNHDgQMcCAwDAzSZMmKArrrhCjzzyiEaMGKGPP/5YL7zwgl544QVH7xNSIg8EAho1apR69Ojh+HNwAADEkssuu0wrV67U1KlTNWvWLHXo0EFz587VyJEjHb1PSIk8Pj5eAwcO1I4dO0jkAAB3aeAFYSTppptu0k033WTjpmcX8mS37t27a+/eveGIBQCAsInEEq0NIeRE/vDDD2vSpElavXq1Dh06VOvBeAAA0HDq3FqfNWuWHnjgAd1www2SpJtvvrnGUq2WZckwDAUCAeejBADACVFaVdtR50Q+c+ZM3XPPPVq3bl044wEAIDwiMEbeEOqcyC2r+ie45pprwhYMAAAITUiz1n/srWcAAESzhl4QpqGElMgvvPDCsybz4uJiWwEBABAWXm+tS9Xj5D9c2Q0AAEROSIn81ltvVatWrcIVCwAAYeP51jrj4wAAV4vR1nqdF4Q5NWsdAABEjzpX5KZphjMOAADCK0Yr8pBfYwoAgBt5fowcAABXi9GKPOSXpgAAgOhBRQ4A8IYYrchJ5AAAT4jVMXJa6wAAuBgVOQDAG2itAwDgXrTWAQBA1KEiBwB4A611AABcLEYTOa11AABcjIocAOAJxvebnfOjEYkcAOANMdpaJ5EDADyBx88AAEDUoSIHAHgDrXUAAFwuSpOxHbTWAQBwMSpyAIAnxOpkNxI5AMAbYnSMnNY6AAAuRkUOAPAEWusAALgZrXUAABBtqMgBAJ5Aax0AADeL0dY6iRwA4A0xmsgZIwcAwMWoyAEAnsAYOQAAbkZrHQAARBsqcgCAJxiWJcOqf1lt59xwIpEDALyB1joAAIg2VOQAAE9g1joAAG5Gax0AAEQbKnIAgCfQWgcAwM1itLVOIgcAeEKsVuSMkQMA4GJU5AAAb6C1DgCAu0Vre9wOWusAAITZo48+KsMwdP/99zt+bSpyAIA3WFb1Zuf8evjkk0/0/PPP6+KLL67/vX8EFTkAwBNOzVq3s4WqtLRUI0eO1KJFi9S8eXPnfyiRyAEACElJSUmNraKi4ozfHTNmjG688UYNGDAgbPGQyAEA3mA5sEnKyMhQSkpKcMvJyTnt7V577TXl5eWd8bhTGCMHAHiCYVZvds6XpMLCQvn9/uB+n89X67uFhYUaP3681qxZo8TExPrftA5I5AAAhMDv99dI5KezdetWHTlyRJdeemlwXyAQ0IYNG/Tcc8+poqJC8fHxjsRDIkeddO9Tqp/f+7Uu6HFCLdNOasbo9tryXkqkwwLqZd/HTbX5hVQd2p6k0iMJGrFwj7oMPBY8vuO9Ztq6/Fwd2t5Y3x1tpF+t3qG0bt9FMGI4ogEXhLn22mv1+eef19g3atQodenSRZMnT3YsiUsRHiPfsGGDhgwZovT0dBmGoVWrVkUyHPyIxMam9v49Uc/9tk2kQwFsqzwRp9SuJ3TDzMLTHq/6Lk4ZvUt17eQDDRwZwqkhZ60nJyere/fuNbYmTZqoZcuW6t69u6M/V0Qr8rKyMmVmZmr06NEaPnx4JEPBWeSu8yt33Y+3kgC3uKBfiS7oV3LG4xf/rFiSdHR/QkOFhIYQoefIwy2iiXzw4MEaPHhwJEMAAKBBrF+/PizXddUYeUVFRY3n9UpKzvwXNQAA/4rXmEaBnJycGs/uZWRkRDokAIBbOPQcebRxVSKfOnWqjh07FtwKC08/UQUAAK9wVWvd5/Od9sF7AADOJlZb665K5IicxMYBpXeoDH5Oy6hUx4u+0/Gj8fr6ADN74S6VZXEq3vfPouBooU9F/0hSUspJpZxfpe+OxuvYwQQdP3yOJOn/7a1emavpeVVqet7JiMQMBzBr3XmlpaXavXt38HNBQYG2bdumFi1aqG3bthGMDD90YeZ3euLNPcHP98w8KEn6nxXN9dQE/l3BXQ5+3lhLf3Fh8PP/zKleHyHzf/0/DX1in/L/mqK3H2ofPP7muA6SpKvHHVK/+w81aKzA2UQ0kefm5qp///7BzxMnTpQkZWVlafHixRGKCqfzf7c01aD0zEiHATii/b+VatrevDMe73lLsXreUtyAEaEh0FoPg379+smK0lYFACDGNOASrQ3JVbPWAQBATUx2AwB4Aq11AADczLSqNzvnRyESOQDAGxgjBwAA0YaKHADgCYZsjpE7FomzSOQAAG+I0ZXdaK0DAOBiVOQAAE/g8TMAANyMWesAACDaUJEDADzBsCwZNias2Tk3nEjkAABvML/f7JwfhWitAwDgYlTkAABPoLUOAICbxeisdRI5AMAbWNkNAABEGypyAIAnsLIbAABuRmsdAABEGypyAIAnGGb1Zuf8aEQiBwB4A611AAAQbajIAQDewIIwAAC4V6wu0UprHQAAF6MiBwB4Q4xOdiORAwC8wZK9d4pHZx4nkQMAvIExcgAAEHWoyAEA3mDJ5hi5Y5E4ikQOAPCGGJ3sRmsdAAAXoyIHAHiDKcmweX4UIpEDADyBWesAACDqUJEDALwhRie7kcgBAN4Qo4mc1joAAC5GRQ4A8IYYrchJ5AAAb+DxMwAA3IvHzwAAQNShIgcAeANj5AAAuJhpSYaNZGxGZyKntQ4AgItRkQMAvCFGW+tU5AAAj7D+mczrsym0RJ6Tk6PLLrtMycnJatWqlYYNG6b8/HzHfyoSOQAAYfDBBx9ozJgx+vDDD7VmzRpVVVVp4MCBKisrc/Q+tNYBAN7QwK319957r8bnxYsXq1WrVtq6dauuvvrq+sfxAyRyAIA3mKG3x2ufL5WUlNTY7fP55PP5znr6sWPHJEktWrSofwynQWsdAIAQZGRkKCUlJbjl5OSc9RzTNHX//ffryiuvVPfu3R2Nh4ocAOANllm92TlfUmFhofx+f3B3XarxMWPGaPv27dq0aVP9738GJHIAgDc4NEbu9/trJPKzGTt2rFavXq0NGzaoTZs29b//GZDIAQDe4NAYeV1ZlqX77rtPK1eu1Pr169WhQ4f63/tHkMgBAAiDMWPGaPny5frv//5vJScnq6ioSJKUkpKipKQkx+7DZDcAgDfYWQymHm35BQsW6NixY+rXr59at24d3FasWOHoj0VFDgDwBks2x8hD/HoDLelKRQ4AgItRkQMAvCFGX5pCIgcAeINpSrLxHLlp49wworUOAICLUZEDALyB1joAAC4Wo4mc1joAAC5GRQ4A8IYGXqK1oZDIAQCeYFmmLBtvP7NzbjiRyAEA3mBZ9qpqxsgBAIDTqMgBAN5g2Rwjj9KKnEQOAPAG05QMG+PcUTpGTmsdAAAXoyIHAHgDrXUAANzLMk1ZNlrr0fr4Ga11AABcjIocAOANtNYBAHAx05KM2EvktNYBAHAxKnIAgDdYliQ7z5FHZ0VOIgcAeIJlWrJstNYtEjkAABFkmbJXkfP4GQAAcBgVOQDAE2itAwDgZjHaWnd1Ij/119FJVdl6xh+IZmXHo/M/HoATykqrf78botq1mytOqsq5YBzk6kR+/PhxSdImvRvhSIDwWX9xpCMAwu/48eNKSUkJy7UTEhKUlpamTUX2c0VaWpoSEhIciMo5hhWtTf86ME1TBw8eVHJysgzDiHQ4nlBSUqKMjAwVFhbK7/dHOhzAUfx+NzzLsnT8+HGlp6crLi5886/Ly8tVWVlp+zoJCQlKTEx0ICLnuLoij4uLU5s2bSIdhif5/X7+Q4eYxe93wwpXJf6vEhMToy4BO4XHzwAAcDESOQAALkYiR0h8Pp+mT58un88X6VAAx/H7DTdy9WQ3AAC8joocAAAXI5EDAOBiJHIAAFyMRA4AgIuRyFFn8+fPV/v27ZWYmKg+ffro448/jnRIgCM2bNigIUOGKD09XYZhaNWqVZEOCagzEjnqZMWKFZo4caKmT5+uvLw8ZWZmatCgQTpy5EikQwNsKysrU2ZmpubPnx/pUICQ8fgZ6qRPnz667LLL9Nxzz0mqXuc+IyND9913n6ZMmRLh6ADnGIahlStXatiwYZEOBagTKnKcVWVlpbZu3aoBAwYE98XFxWnAgAHasmVLBCMDAJDIcVbffPONAoGAUlNTa+xPTU1VUVFRhKICAEgkcgAAXI1EjrM699xzFR8fr8OHD9fYf/jwYaWlpUUoKgCARCJHHSQkJKhXr15au3ZtcJ9pmlq7dq369u0bwcgAAI0iHQDcYeLEicrKylLv3r11+eWXa+7cuSorK9OoUaMiHRpgW2lpqXbv3h38XFBQoG3btqlFixZq27ZtBCMDzo7Hz1Bnzz33nJ544gkVFRWpZ8+emjdvnvr06RPpsADb1q9fr/79+9fan5WVpcWLFzd8QEAISOQAALgYY+QAALgYiRwAABcjkQMA4GIkcgAAXIxEDgCAi5HIAQBwMRI5AAAuRiIHbLrjjjtqvLu6X79+uv/++xs8jvXr18swDB09evSM3zEMQ6tWrarzNWfMmKGePXvaiuvLL7+UYRjatm2bresAOD0SOWLSHXfcIcMwZBiGEhIS1KlTJ82aNUsnT54M+73feustzZ49u07frUvyBYAfw1rriFnXX3+9XnnlFVVUVOjdd9/VmDFjdM4552jq1Km1vltZWamEhARH7tuiRQtHrgMAdUFFjpjl8/mUlpamdu3a6Te/+Y0GDBigt99+W9I/2+Fz5sxRenq6OnfuLEkqLCzUiBEj1KxZM7Vo0UJDhw7Vl19+GbxmIBDQxIkT1axZM7Vs2VIPPfSQfrjK8Q9b6xUVFZo8ebIyMjLk8/nUqVMnvfTSS/ryyy+D63s3b95chmHojjvukFT9drmcnBx16NBBSUlJyszM1BtvvFHjPu+++64uvPBCJSUlqX///jXirKvJkyfrwgsvVOPGjdWxY0dlZ2erqqqq1veef/55ZWRkqHHjxhoxYoSOHTtW4/iLL76orl27KjExUV26dNEf/vCHkGMBUD8kcnhGUlKSKisrg5/Xrl2r/Px8rVmzRqtXr1ZVVZUGDRqk5ORkbdy4UX/729/UtGlTXX/99cHznnrqKS1evFgvv/yyNm3apOLiYq1cufJH7/vLX/5Sr776qubNm6cdO3bo+eefV9OmTZWRkaE333xTkpSfn69Dhw7p97//vSQpJydHS5cu1cKFC/X3v/9dEyZM0O23364PPvhAUvUfHMOHD9eQIUO0bds23XXXXZoyZUrI/58kJydr8eLF+sc//qHf//73WrRokZ555pka39m9e7def/11vfPOO3rvvff06aef6t577w0eX7ZsmaZNm6Y5c+Zox44deuSRR5Sdna0lS5aEHA+AerCAGJSVlWUNHTrUsizLMk3TWrNmjeXz+axJkyYFj6emploVFRXBc/74xz9anTt3tkzTDO6rqKiwkpKSrL/85S+WZVlW69atrccffzx4vKqqymrTpk3wXpZlWddcc401fvx4y7IsKz8/35JkrVmz5rRxrlu3zpJkffvtt8F95eXlVuPGja3NmzfX+O6dd95p3XbbbZZlWdbUqVOtbt261Tg+efLkWtf6IUnWypUrz3j8iSeesHr16hX8PH36dCs+Pt7av39/cN+f//xnKy4uzjp06JBlWZb1k5/8xFq+fHmN68yePdvq27evZVmWVVBQYEmyPv300zPeF0D9MUaOmLV69Wo1bdpUVVVVMk1Tv/jFLzRjxozg8R49etQYF//ss8+0e/duJScn17hOeXm59uzZo2PHjunQoUM1Xt3aqFEj9e7du1Z7/ZRt27YpPj5e11xzTZ3j3r17t06cOKHrrruuxv7KykpdcsklkqQdO3bUeoVs375963yPU1asWKF58+Zpz549Ki0t1cmTJ+X3+2t8p23btjr//PNr3Mc0TeXn5ys5OVl79uzRnXfeqbvvvjv4nZMnTyolJSXkeACEjkSOmNW/f38tWLBACQkJSk9PV6NGNX/dmzRpUuNzaWmpevXqpWXLltW61nnnnVevGJKSkkI+p7S0VJL0pz/9qUYClarH/Z2yZcsWjRw5UjNnztSgQYOUkpKi1157TU899VTIsS5atKjWHxbx8fGOxQrgzEjkiFlNmjRRp06d6vz9Sy+9VCtWrFCrVq1qVaWntG7dWh999JGuvvpqSdWV59atW3XppZee9vs9evSQaZr64IMPNGDAgFrHT3UEAoFAcF+3bt3k8/n01VdfnbGS79q1a3Di3ikffvjh2X/If7F582a1a9dOv/vd74L79u3bV+t7X331lQ4ePKj09PTgfeLi4tS5c2elpqYqPT1de/fu1ciRI0O6PwBnMNkN+N7IkSN17rnnaujQodq4caMKCgq0fv16jRs3Tvv375ckjR8/Xo8++qhWrVqlL774Qvfee++PPgPevn17ZWVlafTo0Vq1alXwmq+//rokqV27djIMQ6tXr9bXX3+t0tJSJScna9KkSZowYYKWLFmiPXv2KC8vT88++2xwAtk999yjXbt26cEHH1R+fr6WL1+uxYsXh/TzXnDBBfrqq6/02muvac+ePZo3b95pJ+4lJiYqKytLn332mTZu3Khx48ZpxIgRSktLkyTNnDlTOTk5mjdvnnbu3KnPP/9cr7zyip5++umQ4gFQPyRy4HuNGzfWhg0b1LZtWw0fPlxdu3bVnXfeqfLy8mCF/sADD+g///M/lZWVpb59+yo5OVk/+9nPfvS6CxYs0C233KJ7771XXbp00d13362ysjJJ0vnnn6+ZM2dqypQpSk1N1dixYyVJs2fPVnZ2tnJyctS1a1ddf/31+tOf/qQOHTpIqh63fvPNN7Vq1SplZmZq4cKFeuSRR0L6eW+++WZNmDBBY8eOVc+ePbV582ZlZ2fX+l6nTp00fPhw3XDDDRo4cKAuvvjiGo+X3XXXXXrxxRf1yiuvqEePHrrmmmu0ePHiYKwAwsuwzjRLBwAARD0qcgAAXIxEDgCAi5HIAQBwMRI5AAAuRiIHAMDFSOQAALgYiRwAABcjkQMA4GIkcgAAXIxEDgCAi5HIAQBwMRI5AAAu9v8BvJb11fEntsIAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "measurements = measure_method_by_class(\n",
    "    output_fp=\"./ScoredBaseline-1.csv\",\n",
    "    target_threshold=TARGET_THRESHOLD,\n",
    "    verbose=False\n",
    ")\n",
    "\n",
    "print(f\"Accuracy: {measurements['accuracy'] * 100:.2f}%\")\n",
    "cm = ConfusionMatrixDisplay(confusion_matrix=measurements['confusion_matrix'])\n",
    "cm.plot()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
