{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "7c1ee796-e7a4-4a73-a1e8-113c6d4956e0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import re\n",
    "import csv\n",
    "import sys\n",
    "import time\n",
    "import spacy\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import random\n",
    "import pickle\n",
    "from fastcoref import FCoref, LingMessCoref\n",
    "from taxonerd import TaxoNERD\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.matcher import DependencyMatcher, PhraseMatcher\n",
    "from spacy.language import Language\n",
    "from IPython.display import clear_output\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "%run -i \"../utils.py\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1439c540-4646-4079-8c86-7576d6718bba",
   "metadata": {},
   "outputs": [],
   "source": [
    "VERBOSE_LEVEL = 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "834c33d0-ab0f-4715-a886-7b8013477317",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Base:\n",
    "    # There is not a defined conversion method for these words.\n",
    "    # This is the default list of irregular nouns. It maps the\n",
    "    # the singular version to the plural version (SP).\n",
    "    IRREGULAR_NOUNS_SP = {\n",
    "        \"ox\": \"oxen\",\n",
    "        \"goose\": \"geese\",\n",
    "        \"mouse\": \"mice\",\n",
    "        \"bacterium\": \"bacteria\"\n",
    "    }\n",
    "\n",
    "    # This is the reversed version of the dictionary above, meaning \n",
    "    # that the plural version is mapped to the singular version \n",
    "    # (PS).\n",
    "    IRREGULAR_NOUNS_PS = {v: k for k, v in IRREGULAR_NOUNS_SP.items()}\n",
    "    \n",
    "    # The singular and plural versions of these words are the same. \n",
    "    # This is the default list of zero plural nouns.\n",
    "    ZERO_PLURAL_NOUNS = [\n",
    "        \"species\", \n",
    "        \"deer\", \n",
    "        \"fish\", \n",
    "        \"moose\", \n",
    "        \"sheep\", \n",
    "        \"swine\", \n",
    "        \"buffalo\", \n",
    "        \"trout\", \n",
    "        \"cattle\"\n",
    "    ]\n",
    "\n",
    "    # These pairs of characters define symbols that enclose other\n",
    "    # information in a text.\n",
    "    ENCLOSURES = {\n",
    "        \"(\": \")\",\n",
    "        \"[\": \"]\",\n",
    "        \"{\": \"}\"\n",
    "    }\n",
    "\n",
    "    LAX_ENCLOSURES = {\n",
    "        \"(\": \")\",\n",
    "        \"[\": \"]\",\n",
    "        \"{\": \"}\",\n",
    "        \"—\": \"—\"\n",
    "    }\n",
    "\n",
    "\n",
    "    \n",
    "    def __init__(self, main, irregular_nouns_sp=IRREGULAR_NOUNS_SP, irregular_nouns_ps=IRREGULAR_NOUNS_PS, zero_plural_nouns=ZERO_PLURAL_NOUNS):\n",
    "        self.main = main\n",
    "        self.zero_plural_nouns = zero_plural_nouns\n",
    "        self.irregular_nouns_sp = irregular_nouns_sp\n",
    "        self.irregular_nouns_ps = irregular_nouns_ps\n",
    "        self.irregular_plural_nouns = list(self.irregular_nouns_sp.values())\n",
    "        self.irregular_singular_nouns = list(self.irregular_nouns_sp.keys())\n",
    "\n",
    "\n",
    "\n",
    "    def delete_extra_whitespace(self, string):\n",
    "        # Duplicate spaces, spaces before punctuation marks,\n",
    "        # and outside spaces are removed.\n",
    "        string = re.sub(r\"\\s+\", \" \", string)\n",
    "        string = re.sub(r\"\\s+([?.!,])\", r\"\\1\", string)\n",
    "        string = string.strip()\n",
    "        return string\n",
    "\n",
    "\n",
    "\n",
    "    def delete_outer_non_alnum(self, string):\n",
    "        while string:\n",
    "            start_len = len(string)\n",
    "            # Remove Leading Non-Alphanumeric Character\n",
    "            if string and not string[0].isalnum():\n",
    "                string = string[1:]\n",
    "            # Remove Trailing Non-Alphanumeric Character\n",
    "            if string and not string[-1].isalnum():\n",
    "                string = string[:-1]\n",
    "            # No Changes Made\n",
    "            if start_len == len(string):\n",
    "                break\n",
    "        return string\n",
    "\n",
    "\n",
    "\n",
    "    def get_parentheticals(self, text, enclosures=ENCLOSURES, flatten=False):\n",
    "        # The parenthetical would be the content inside of a pair\n",
    "        # of matching parentheses, brackets, or braces.\n",
    "        parentheticals = []\n",
    "        \n",
    "        # This contains the text that's not inside of any\n",
    "        # enclosure.\n",
    "        base_text = []\n",
    "        \n",
    "        # This is used for building groups, which often has a \n",
    "        # nested structure.\n",
    "        stacks = []\n",
    "        \n",
    "        # These are the pairs of characters that we recognize\n",
    "        # as defining the parenthetical.\n",
    "        openers = list(enclosures.keys())\n",
    "        closers = list(enclosures.values())\n",
    "        \n",
    "        # This contains the opening characters of the groups \n",
    "        # that are currently open (e.g. '(', '['). We use it \n",
    "        # so that we know whether to open or close a group.\n",
    "        opened = []\n",
    "        \n",
    "        for i, char in enumerate(text):\n",
    "            # Open Group\n",
    "            if char in openers:\n",
    "                stacks.append([])\n",
    "                opened.append(char)\n",
    "            # Close Group\n",
    "            elif opened and char == enclosures.get(opened[-1], \"\"):\n",
    "                parentheticals.append(stacks.pop())\n",
    "                opened.pop()\n",
    "            # Add to Group\n",
    "            elif opened:\n",
    "                stacks[-1].append(i)\n",
    "            # Add to Base Text\n",
    "            else:\n",
    "                base_text.append(i)\n",
    "        \n",
    "        # We close the remaining groups that have not\n",
    "        # been closed.\n",
    "        while stacks:\n",
    "            parentheticals.append(stacks.pop())\n",
    "            \n",
    "        # Cluster Groups' Indices\n",
    "        # A list in the lists of indices (where each list represents a group of text) could have \n",
    "        # an interruption (e.g. [0, 1, 2, 10 15]) because of a parenthetical. So, we cluster the\n",
    "        # indices in each list to make the output more useful (e.g. [(0, 3), (10, 16)]).\n",
    "        lists_of_indices = [*parentheticals, base_text]        \n",
    "        lists_of_clustered_indices = []\n",
    "\n",
    "        for list_of_indices in lists_of_indices:\n",
    "            if not list_of_indices:\n",
    "                continue\n",
    "\n",
    "            # We start off with a single cluster that is made up of the\n",
    "            # first index. If the next index follows the first index, \n",
    "            # we continue the cluster. If it doesn't, we create a new cluster.\n",
    "            clustered_indices = [[list_of_indices[0], list_of_indices[0] + 1]]\n",
    "            \n",
    "            for index in list_of_indices[1:]:\n",
    "                if clustered_indices[-1][1] == index:\n",
    "                    clustered_indices[-1][1] = index + 1\n",
    "                else:\n",
    "                    clustered_indices.append([index, index + 1])\n",
    "\n",
    "            # Add Clustered Indices\n",
    "            lists_of_clustered_indices.append(clustered_indices)\n",
    "            \n",
    "        if flatten:\n",
    "            flattened_clusters = []\n",
    "            # We are placing each cluster of indices into one list.\n",
    "            # This removes the context of the larger parenthetical,\n",
    "            # but the context may be cumbersome instead of useful.\n",
    "            for list_of_clustered_indices in lists_of_clustered_indices:\n",
    "                for clustered_indices in list_of_clustered_indices:\n",
    "                    flattened_clusters.append(clustered_indices)\n",
    "            lists_of_clustered_indices = flattened_clusters\n",
    "        \n",
    "        return lists_of_clustered_indices\n",
    "\n",
    "\n",
    "\n",
    "    def separate_span_by_parenthetical(self, span):\n",
    "        span_parentheticals = []\n",
    "        \n",
    "        # The clusters of the span represented with tuples of char indices\n",
    "        # (e.g. [(0, 1), (1, 5), (5, 10)]. This is a list of clustered\n",
    "        # indices (like above).\n",
    "        text_clusters = self.get_parentheticals(span.text, flatten=True)\n",
    "        \n",
    "        for cluster in text_clusters:\n",
    "            if span.text[cluster[0]:cluster[1]].isspace():\n",
    "                continue\n",
    "\n",
    "            l_char_index = span[0].idx + cluster[0]\n",
    "            r_char_index = span[0].idx + cluster[1] - 1\n",
    "\n",
    "            # Instead of having a tuple dictating the start and end of a cluster,\n",
    "            # we can use a span -- it's much simpler.\n",
    "            cluster_as_span = self.get_span_at_indices(l_char_index, r_char_index)\n",
    "            if not cluster_as_span:\n",
    "                continue\n",
    "            \n",
    "            span_parentheticals.append(cluster_as_span)\n",
    "\n",
    "        return span_parentheticals\n",
    "\n",
    "\n",
    "\n",
    "    def separate_spans_by_parenthetical(self, spans):\n",
    "        all_span_parentheticals = []\n",
    "        for span in spans:\n",
    "            all_span_parentheticals.extend(self.separate_span_by_parenthetical(span))\n",
    "        return all_span_parentheticals\n",
    "\n",
    "    \n",
    " \n",
    "    def singularize(self, string):\n",
    "        string = string.lower()\n",
    "        \n",
    "        # The string to singularize should not have any\n",
    "        # non-alphanumeric characters at the end, or else\n",
    "        # the algorithm will not work.\n",
    "        words = re.split(r\" \", string)\n",
    "\n",
    "        if not words:\n",
    "            return [string]\n",
    "\n",
    "        # If the last word in the string is a zero plural\n",
    "        # or a singular irregular noun, there's no changes\n",
    "        # to make. For example, \"red sheep\" and \"ox\" are \n",
    "        # already singular.\n",
    "        if (\n",
    "            words[-1] in self.zero_plural_nouns or \n",
    "            words[-1] in self.irregular_singular_nouns\n",
    "        ):\n",
    "            return [string]\n",
    "\n",
    "        # If the last word in the string is an irregular\n",
    "        # plural noun, we rely on a dictionary with the\n",
    "        # corresponding mapping.\n",
    "        if words[-1] in self.irregular_plural_nouns:\n",
    "            words[-1] = self.irregular_nouns_ps[words[-1]]\n",
    "            singulars = [self.delete_extra_whitespace(\" \".join(words))]\n",
    "            return singulars\n",
    "        \n",
    "        # We take the singular form of the last word and\n",
    "        # add it back in to the other words. As there could\n",
    "        # be multiple forms (due to uncertainty), we need to\n",
    "        # include all possible versions.\n",
    "        singulars = []\n",
    "        singular_endings = self.get_singular(words[-1])\n",
    "\n",
    "        if not singular_endings:\n",
    "            return [string]\n",
    "        \n",
    "        for singular_ending in singular_endings:\n",
    "            singular = self.delete_extra_whitespace(\" \".join([*words[:-1], singular_ending]))\n",
    "            singulars.append(singular)\n",
    "            \n",
    "        return singulars\n",
    "\n",
    "\n",
    "\n",
    "    def get_singular(self, string):\n",
    "        versions = []\n",
    "\n",
    "        # Replace -ies with -y\n",
    "        if re.fullmatch(r\".*ies$\", string):\n",
    "            versions.append(f'{string[:-3]}y')\n",
    "            return versions\n",
    "\n",
    "        # Replace -ves with -f and -fe\n",
    "        if re.fullmatch(r\".*ves$\", string):\n",
    "            versions.append(f'{string[:-3]}f')\n",
    "            versions.append(f'{string[:-3]}fe')\n",
    "            return versions\n",
    "\n",
    "        # Delete -es \n",
    "        if re.fullmatch(r\".*es$\", string):\n",
    "            versions.append(f'{string[:-2]}')\n",
    "            return versions\n",
    "\n",
    "        # Replace -i with -us\n",
    "        if re.fullmatch(r\".*i$\", string):\n",
    "            versions.append(f'{string[:-1]}us')\n",
    "            return versions\n",
    "\n",
    "        # Delete -s\n",
    "        if re.fullmatch(r\".*s$\", string):\n",
    "            versions.append(f'{string[:-1]}')\n",
    "            return versions\n",
    "\n",
    "        return versions\n",
    "\n",
    "\n",
    "    \n",
    "    def pluralize(self, string):\n",
    "        string = string.lower()\n",
    "        \n",
    "        # The string to pluralize should not have any\n",
    "        # non-alphanumeric characters at the end, or else\n",
    "        # the algorithm will not work.\n",
    "        words = re.split(r\" \", string)\n",
    "\n",
    "        if not words:\n",
    "            return [string]\n",
    "\n",
    "        # If the last word in the string is a zero plural\n",
    "        # or a plural irregular noun, there's no changes\n",
    "        # to make. For example, \"red sheep\" and \"oxen\" are \n",
    "        # already singular.\n",
    "        if (\n",
    "            words[-1] in self.zero_plural_nouns or \n",
    "            words[-1] in self.irregular_plural_nouns\n",
    "        ):\n",
    "            return [string]\n",
    "\n",
    "        # If the last word in the string is an irregular\n",
    "        # singular noun, we rely on a dictionary with the\n",
    "        # corresponding mapping.\n",
    "        if words[-1] in self.irregular_singular_nouns:\n",
    "            words[-1] = self.irregular_nouns_sp[words[-1]]\n",
    "            return [self.delete_extra_whitespace(\" \".join(words))]\n",
    "        \n",
    "        # We take the singular form of the last word and\n",
    "        # add it back in to the other words. As there could\n",
    "        # be multiple forms (due to error), we need to\n",
    "        # handle them all.\n",
    "        plurals = []\n",
    "        plural_endings = self.get_plural(words[-1])\n",
    "\n",
    "        if not plural_endings:\n",
    "            return [string]\n",
    "            \n",
    "        for plural_ending in plural_endings:\n",
    "            plural = self.delete_extra_whitespace(\" \".join([*words[:-1], plural_ending]))\n",
    "            plurals.append(plural)\n",
    "            \n",
    "        return plurals\n",
    "\n",
    "    \n",
    "  \n",
    "    def get_plural(self, string):\n",
    "        versions = []\n",
    "\n",
    "        # Words that end with -us often have\n",
    "        # two different plural versions: -es and -i.\n",
    "        # For example, the plural version of cactus \n",
    "        # can be cactuses or cacti.\n",
    "        if re.fullmatch(r\".*us$\", string):\n",
    "            versions.append(f'{string}es')\n",
    "            versions.append(f'{string[:-2]}i')\n",
    "            return versions\n",
    "\n",
    "        # The -es ending is added to the words below.\n",
    "        if re.fullmatch(r\".*([^l]s|sh|ch|x|z)$\", string):\n",
    "            versions.append(f'{string}es')\n",
    "            return versions\n",
    "\n",
    "        # Words that end with a consonant followed by 'y'\n",
    "        # are made plural by replacing the 'y' with -ies.\n",
    "        # For example, the plural version of canary is\n",
    "        # canaries.\n",
    "        if re.fullmatch(r\".*([^aeiou])(y)$\", string):\n",
    "            versions.append(f'{string[:-1]}ies')\n",
    "            return versions\n",
    "            \n",
    "        # The plural version of words ending with -f\n",
    "        # and -fe aren't clear. To be safe, I will add\n",
    "        # both versions.\n",
    "        if (re.fullmatch(r\".*(f)(e?)$\", string) and not re.fullmatch(r\".*ff$\", string)):\n",
    "            last_clean = re.sub(r\"(f)(e?)$\", \"\", string)\n",
    "            versions.append(f'{last_clean}fs')\n",
    "            versions.append(f'{last_clean}ves')\n",
    "            return versions\n",
    "\n",
    "        # People add -s or -es to words that end with 'o'.\n",
    "        # To be safe, both versions are added.\n",
    "        if re.fullmatch(r\".*([^aeiou])o$\", string):\n",
    "            versions.append(f'{string}s')\n",
    "            versions.append(f'{string}es')\n",
    "            return versions\n",
    "\n",
    "        # If there's no -s at the end of the string and\n",
    "        # the other cases didn't run, we add an -s.\n",
    "        if re.fullmatch(r\".*[^s]$\", string):\n",
    "            versions.append(f'{string}s')\n",
    "        \n",
    "        return versions\n",
    "\n",
    "\n",
    " \n",
    "    def expand_unit(self, *, il_unit, ir_unit, il_boundary, ir_boundary, speech=[], literals=[], include=True, direction='BOTH', verbose=False):\n",
    "        UNIT = self.main.sp_doc[il_unit:ir_unit+1]\n",
    "        \n",
    "        if il_unit > ir_unit:\n",
    "            print(f\"Error: il_unit of {il_unit} greater than ir_unit of {ir_unit}\")\n",
    "            return None\n",
    "        \n",
    "        if direction in ['BOTH', 'LEFT'] and il_boundary > il_unit:\n",
    "            print(f\"Error: il_unit of {il_unit} less than il_boundary of {il_boundary}\")\n",
    "            return None\n",
    "        \n",
    "        if direction in ['BOTH', 'RIGHT'] and ir_boundary < ir_unit:\n",
    "            print(f\"Error: ir_unit of {ir_unit} greater than ir_boundary of {ir_boundary}\")\n",
    "            return None\n",
    "        \n",
    "        # Move Left\n",
    "        if direction in ['BOTH', 'LEFT']:\n",
    "            # The indices are inclusive, therefore, when \n",
    "            # the condition fails, il_unit will be equal\n",
    "            # to il_boundary.\n",
    "            while il_unit > il_boundary:\n",
    "                # We assume that the current token is allowed,\n",
    "                # and look to the token to the left.\n",
    "                l_token = self.main.sp_doc[il_unit-1]\n",
    "\n",
    "                # If the token is invalid, we stop expanding.\n",
    "                in_set = l_token.pos_ in speech or l_token.lower_ in literals\n",
    "\n",
    "                # Case 1: include=False, in_set=True\n",
    "                # If we're not meant to include the defined tokens, and the\n",
    "                # current token is in that set, we stop expanding.\n",
    "                # Case 2: include=True, in_set=False\n",
    "                # If we're meant to include the defined tokens, and the current\n",
    "                # token is not in that set, we stop expanding.\n",
    "                # Case 3: include=in_set\n",
    "                # If we're meant to include the defined tokens, and the current\n",
    "                # token is in that set, we continue expanding. If we're not meant\n",
    "                # to include the defined tokens, and the current token is not\n",
    "                # in that set, we continue expanding.\n",
    "                if include ^ in_set:\n",
    "                    break\n",
    "                \n",
    "                # Else, the left token is valid, and\n",
    "                # we continue to expand.\n",
    "                il_unit -= 1\n",
    "\n",
    "        # Move Right\n",
    "        if direction in ['BOTH', 'RIGHT']:\n",
    "            # Likewise, when the condition fails,\n",
    "            # ir_unit will be equal to the ir_boundary.\n",
    "            # The ir_boundary is also inclusive.\n",
    "            while ir_unit < ir_boundary:\n",
    "                # Assuming that the current token is valid,\n",
    "                # we look to the right to see if we can\n",
    "                # expand.\n",
    "                r_token = self.main.sp_doc[ir_unit+1]\n",
    "\n",
    "                # If the token is invalid, we stop expanding.\n",
    "                in_set = r_token.pos_ in speech or r_token.lower_ in literals\n",
    "                if include ^ in_set:\n",
    "                    break\n",
    "\n",
    "                # Else, the token is valid and\n",
    "                # we continue.\n",
    "                ir_unit += 1\n",
    "\n",
    "        assert il_unit >= il_boundary and ir_unit <= ir_boundary\n",
    "        \n",
    "        expanded_unit = self.main.sp_doc[il_unit:ir_unit+1]\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Expanded Unit of '{UNIT}': {expanded_unit}\")\n",
    "        \n",
    "        return expanded_unit\n",
    "\n",
    "\n",
    "    \n",
    "    def contract_unit(self, *, il_unit, ir_unit, speech=[], literals=[], include=True, direction='BOTH', verbose=False):\n",
    "        UNIT = self.main.sp_doc[il_unit:ir_unit+1]\n",
    "        \n",
    "        if il_unit > ir_unit:\n",
    "            print(f\"Error: il_unit of {il_unit} greater than ir_unit of {ir_unit}\")\n",
    "            return None\n",
    "        \n",
    "        # Move Right\n",
    "        if direction in ['BOTH', 'LEFT']:\n",
    "            while il_unit < ir_unit:\n",
    "                # We must check if the current token is not allowed. If it's\n",
    "                # not allowed, we contract (remove).\n",
    "                token = self.main.sp_doc[il_unit]\n",
    "\n",
    "                # include = True means that we want the tokens that match\n",
    "                # the speech and/or literals in the contracted unit.\n",
    "                \n",
    "                # include = False means that we don't want the tokens that\n",
    "                # match the speech and/or literals in the contracted unit.\n",
    "                \n",
    "                # Case 1: include = True, in_set = True\n",
    "                # We have a token that's meant to be included in the set.\n",
    "                # However, we're contracting, which means we would end up\n",
    "                # removing the token if we continue. Therefore, we break.\n",
    "                \n",
    "                # Case 2: include = False, in_set = False\n",
    "                # We have a token that's not in the set which defines the\n",
    "                # tokens that aren't meant to be included. Therefore, we \n",
    "                # have a token that is meant to be included. If we continue,\n",
    "                # we would end up removing this token. Therefore, we break.\n",
    "                \n",
    "                # Default:\n",
    "                # If we have a token that's in the set (in_set=True) of\n",
    "                # tokens we're not supposed to include in the contracted \n",
    "                # unit (include=False), we need to remove it. Likewise, if\n",
    "                # we have a token that's not in the set (in_set=False) of\n",
    "                # tokens to include in the contracted unit (include=True),\n",
    "                # we need to remove it.\n",
    "                \n",
    "                in_set = token.pos_ in speech or token.lower_ in literals\n",
    "                if include == in_set:\n",
    "                    break\n",
    "\n",
    "                # The token is valid, thus we continue.\n",
    "                il_unit += 1\n",
    "\n",
    "        # Move Left      \n",
    "        if direction in ['BOTH', 'RIGHT']:\n",
    "            while ir_unit > il_unit:\n",
    "                token = self.main.sp_doc[ir_unit]\n",
    "\n",
    "                # The token is invalid and we\n",
    "                # stop contracting.\n",
    "                in_set = token.pos_ in speech or token.lower_ in literals\n",
    "                if include == in_set:\n",
    "                    break\n",
    "\n",
    "                # The token is valid and we continue.\n",
    "                ir_unit -= 1\n",
    "\n",
    "        assert il_unit <= ir_unit\n",
    "        \n",
    "        contracted_unit = self.main.sp_doc[il_unit:ir_unit+1]\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Contracted Unit of '{UNIT}': {contracted_unit}\")\n",
    "        \n",
    "        return contracted_unit\n",
    "\n",
    "\n",
    "    \n",
    "    def find_unit_context(self, *, il_unit, ir_unit, il_boundary, ir_boundary, speech=[\"ADJ\", \"NOUN\", \"ADP\", \"ADV\", \"PART\", \"PROPN\", \"VERB\", \"PRON\", \"DET\", \"AUX\", \"PART\", \"SCONJ\"], literals=[], include=True, enclosures=LAX_ENCLOSURES, comma_encloses=False, verbose=False):\n",
    "        UNIT = self.main.sp_doc[il_unit:ir_unit+1]\n",
    "        \n",
    "        if il_unit > ir_unit:\n",
    "            print(f\"Error: il_unit of {il_unit} greater than ir_unit of {ir_unit}\")\n",
    "            return None\n",
    "        \n",
    "        if il_boundary > il_unit:\n",
    "            print(f\"Error: il_unit of {il_unit} less than il_boundary of {il_boundary}\")\n",
    "            return None\n",
    "        \n",
    "        if ir_boundary < ir_unit:\n",
    "            print(f\"Error: ir_unit of {ir_unit} greater than ir_boundary of {ir_boundary}\")\n",
    "            return None\n",
    "        \n",
    "        # Caveat: Parentheticals\n",
    "        # The context of a unit inside a set of enclosures should\n",
    "        # not go farther than the boundaries of those enclosures.\n",
    "        # However, we need to manually determine whether the unit\n",
    "        # is in parentheses (or any set of the matching symbols\n",
    "        # below).\n",
    "        openers = list(enclosures.keys())\n",
    "        closers = list(enclosures.values())\n",
    "        enclosing_chars = [*closers, *openers]\n",
    "\n",
    "        # Look for Group Punctuation on the Left\n",
    "        i = il_unit\n",
    "        opener = None\n",
    "        while i > il_boundary:\n",
    "            token = self.main.sp_doc[i]\n",
    "            if token.lower_ in enclosing_chars and token.lower_ != \",\":\n",
    "                opener = token\n",
    "                break\n",
    "            i -= 1\n",
    "\n",
    "        # Look for Group Punctuation on the Right\n",
    "        i = ir_unit\n",
    "        closer = None\n",
    "        while i < ir_boundary:\n",
    "            token = self.main.sp_doc[i]\n",
    "            if token.lower_ in enclosing_chars and token.lower_ != \",\":\n",
    "                closer = token\n",
    "                break\n",
    "            i += 1\n",
    "\n",
    "        # If there's a group punctuation on the left\n",
    "        # and right, and they match each other (e.g. '(' and ')'),\n",
    "        # we return the text between the punctuations.\n",
    "        parenthetical = opener and closer and enclosures.get(opener.lower_) == closer.text\n",
    "        if parenthetical:\n",
    "            context = [t for t in self.main.sp_doc[opener.i:closer.i+1]]\n",
    "            \n",
    "            if verbose and VERBOSE_LEVEL >= 1:\n",
    "                print(f\"Parenthetical - Unit Context of '{UNIT}': {context}\")\n",
    "            \n",
    "            return context\n",
    "\n",
    "        # We can also check whether the unit it enclosed\n",
    "        # in a comma or two, only if a comma can enclose.\n",
    "        if comma_encloses:\n",
    "            i = il_unit\n",
    "            while i > il_boundary:\n",
    "                i_token = self.main.sp_doc[i]\n",
    "                if i_token.lower_ in [\",\", \";\", \"—\"]:\n",
    "                    break\n",
    "                i -= 1\n",
    "\n",
    "            j = ir_unit\n",
    "            while j < ir_boundary:\n",
    "                j_token = self.main.sp_doc[j]\n",
    "                if j_token.lower_ in [\",\", \";\", \"—\"]:\n",
    "                    break\n",
    "                j += 1\n",
    "\n",
    "            if i_token.lower_ == \",\" or j_token.lower_ == \",\":\n",
    "                context = [t for t in self.main.sp_doc[i:j+1]]\n",
    "            \n",
    "                if verbose and VERBOSE_LEVEL >= 1:\n",
    "                    print(f\"Comma - Unit Context of '{UNIT}': {context}\")\n",
    "                    \n",
    "                return context\n",
    "            \n",
    "        # As the unit is not a parenthetical, we will expand\n",
    "        # outwards until we run into a stopping token. The exclude\n",
    "        # list contains tokens that should be excluded from the\n",
    "        # context. Currently, it will contain any parentheticals\n",
    "        # that we run into.\n",
    "        exclude = []\n",
    "\n",
    "        # We can modify the enclosures after handling the parenthetical\n",
    "        # situation to make the code easier.\n",
    "        if comma_encloses:\n",
    "            enclosures[\",\"] : \",\"\n",
    "        \n",
    "        # Expand Left\n",
    "        while il_unit > il_boundary:\n",
    "            # Assuming that the current token is fine,\n",
    "            # we look to the left.\n",
    "            l_token = self.main.sp_doc[il_unit-1]\n",
    "\n",
    "            if l_token.lower_ not in closers:\n",
    "                in_set = l_token.pos_ in speech or l_token.lower_ in literals\n",
    "                if in_set ^ include:\n",
    "                    break\n",
    "                il_unit -= 1\n",
    "            # If it's a closing enclosure (e.g. ')', ']'),\n",
    "            # we need to skip over whatever is contained in\n",
    "            # that punctuation.\n",
    "            else:\n",
    "                i = il_unit - 1\n",
    "                \n",
    "                token = self.main.sp_doc[i]\n",
    "                exclude.append(token)\n",
    "\n",
    "                # We continue until we reach the boundary or\n",
    "                # we find the matching opening character.\n",
    "                closed = []\n",
    "                \n",
    "                while i > il_boundary:\n",
    "                    token = self.main.sp_doc[i]\n",
    "                    # Found Closer\n",
    "                    if token.lower_ in closers:\n",
    "                        exclude.append(token)\n",
    "                        closed.append(token.lower_)\n",
    "                    # Currently Closed\n",
    "                    elif closed:\n",
    "                        exclude.append(token)\n",
    "                        # Found Opener\n",
    "                        if token.lower_ == enclosures.get(closed[-1]):\n",
    "                            closed.pop()\n",
    "                    else:\n",
    "                        break\n",
    "                    i -= 1\n",
    "                \n",
    "                il_unit = i\n",
    "\n",
    "        # Expand Right\n",
    "        while ir_unit < ir_boundary:\n",
    "            # We're checking the token to the right\n",
    "            # to see if we can expand or not.\n",
    "            r_token = self.main.sp_doc[ir_unit+1]\n",
    "\n",
    "            if r_token.lower_ not in openers:\n",
    "                in_set = r_token.pos_ in speech or r_token.lower_ in literals\n",
    "                if in_set ^ include:\n",
    "                    break\n",
    "                ir_unit += 1\n",
    "            # If the token to the right is an opener (e.g. '(', '['), we must skip\n",
    "            # it, the parenthetical inside, and the closer.\n",
    "            else:\n",
    "                i = ir_unit + 1\n",
    "                \n",
    "                token = self.main.sp_doc[i]\n",
    "                exclude.append(token)\n",
    "\n",
    "                # We continue until we reach the boundary or\n",
    "                # we find all the closers for the openers.\n",
    "                opened = []\n",
    "                \n",
    "                while i < ir_boundary:\n",
    "                    token = self.main.sp_doc[i]\n",
    "                    # Found Opener\n",
    "                    if token.lower_ in openers:\n",
    "                        exclude.append(token)\n",
    "                        opened.append(token.lower_)\n",
    "                    # Currently Opened\n",
    "                    elif opened:\n",
    "                        exclude.append(token)\n",
    "                        # Found Closer\n",
    "                        if token.lower_ == enclosures.get(opened[-1]):\n",
    "                            opened.pop()\n",
    "                    else:\n",
    "                        break\n",
    "                    i += 1\n",
    "                \n",
    "                ir_unit = i\n",
    "        \n",
    "        # We remove the excluded tokens and return the context.\n",
    "        context = [t for t in self.main.sp_doc[il_unit:ir_unit+1] if t not in exclude]\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Unit Context of '{UNIT}': {context}\")\n",
    "        \n",
    "        return context\n",
    "\n",
    "\n",
    "    \n",
    "    def get_span_at_indices(self, l_index, r_index):\n",
    "        text = self.main.sp_doc.text.lower()\n",
    "\n",
    "        while text[l_index].isspace():\n",
    "            l_index += 1\n",
    "\n",
    "        while text[r_index].isspace():\n",
    "            r_index -= 1\n",
    "\n",
    "        if l_index > r_index:\n",
    "            print(f\"Error: l_index of {l_index} greater than r_index of {r_index}\")\n",
    "            return None\n",
    "            \n",
    "        l_token_i = self.main.token_at_char(l_index).i\n",
    "        r_token_i = self.main.token_at_char(r_index).i\n",
    "        \n",
    "        return self.main.sp_doc[l_token_i:r_token_i+1]\n",
    "\n",
    "\n",
    "    \n",
    "    def get_base_nouns(self, span, return_tokens=False, immediate_stop=False):\n",
    "        ending_nouns = []\n",
    "        \n",
    "        reversed_span = [t for t in span]\n",
    "        reversed_span.reverse()\n",
    "        \n",
    "        for token in reversed_span:\n",
    "            if token.pos_ in [\"NOUN\", \"PROPN\"]:\n",
    "                ending_nouns.append(token if return_tokens else self.main.sp_doc[token.i:token.i+1])\n",
    "                if immediate_stop:\n",
    "                    break\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        return ending_nouns\n",
    "\n",
    "\n",
    "\n",
    "    def flatten(self, arr):\n",
    "        flat_arr = []\n",
    "\n",
    "        if not isinstance(arr, list):\n",
    "            return [arr]\n",
    "\n",
    "        for element in arr:\n",
    "            flat_arr.extend(self.flatten(element))\n",
    "\n",
    "        return flat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "49a954dc-05f6-4e70-a974-f71c5976d92c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Species:\n",
    "    def __init__(self, main):\n",
    "        # Tools\n",
    "        self.main = main\n",
    "        self.tn_nlp = TaxoNERD(prefer_gpu=False).load(model=\"en_ner_eco_biobert\", exclude=[\"tagger\", \"parser\", \"attribute_ruler\"])\n",
    "        self.tn_doc = None\n",
    "        \n",
    "        # Contains any spans that have been identified\n",
    "        # as a species.\n",
    "        self.spans = None\n",
    "        self.span_starts = None\n",
    "        \n",
    "        # Contains any tokens that have been identified\n",
    "        # as a species or being a part of a species.\n",
    "        self.tokens = None\n",
    "        \n",
    "        # Used to quickly access the span that a token\n",
    "        # belongs to.\n",
    "        self.token_to_span = None\n",
    "        \n",
    "        # Maps a string to an array of strings wherein\n",
    "        # the strings involved in the key-value pair \n",
    "        # have been identified as an alternate name of each other.\n",
    "        self.alternate_names = None\n",
    "        \n",
    "        # Includes words that (1) are to be identified as species; and\n",
    "        # (2) are sometimes not identified as species, more or less.\n",
    "        self.dictionary = [\"juvenile\", \"juveniles\", \"adult\", \"prey\", \"predator\", \"predators\", \"species\", \"tree\", \"cat\", \"dog\", \"fly\", \"flies\", \"plant\", \"plants\"]\n",
    "\n",
    "\n",
    "\n",
    "    def update(self, text, verbose=False):\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "        self.tn_doc = self.tn_nlp(text)\n",
    "        self.spans, self.tokens, self.token_to_span, self.span_starts = self.load_species(verbose=verbose)\n",
    "        self.alternate_names = self.load_alternate_names(self.spans)\n",
    "\n",
    "\n",
    "\n",
    "    def convert_tn_spans_to_sp_spans(self, tn_spans):\n",
    "        sp_spans = []\n",
    "\n",
    "        for tn_span in tn_spans:\n",
    "            l_char_index = self.tn_doc[tn_span.start].idx\n",
    "            r_char_index = l_char_index + len(tn_span.text) - 1\n",
    "\n",
    "            try:\n",
    "                l_sp_token_i = self.main.token_at_char(l_char_index).i\n",
    "                r_sp_token_i = self.main.token_at_char(r_char_index).i\n",
    "            except Exception as e:\n",
    "                print(f\"Error: Couldn't find token at character index of {l_char_index} and token index of {l_sp_token_i}.\")\n",
    "                print(f\"Error: Couldn't find token at character index of {r_char_index} and token index of {r_sp_token_i}.\")\n",
    "                print(e)\n",
    "                continue\n",
    "\n",
    "            sp_span = self.main.sp_doc[l_sp_token_i:r_sp_token_i+1]\n",
    "            if sp_span.text != tn_span:\n",
    "                print(f\"Error: SpaCy span does not match TaxoNerd span.\")\n",
    "                continue\n",
    "            \n",
    "            sp_spans.append(sp_span)\n",
    "\n",
    "        return sp_spans\n",
    "\n",
    "\n",
    "\n",
    "    def load_search_strings(self, verbose=False):\n",
    "        search_strings = [*self.dictionary]\n",
    "        \n",
    "        # Creating a Broad Set of Species\n",
    "        spans = self.convert_tn_spans_to_sp_spans(self.tn_doc.ents)\n",
    "        spans = self.main.separate_spans_by_parenthetical(spans)\n",
    "\n",
    "        # Add Ending Nouns to Set\n",
    "        all_nouns = []\n",
    "        for span in spans:\n",
    "            nouns = self.main.get_base_nouns(span)\n",
    "            if nouns:\n",
    "                all_nouns.extend(nouns)\n",
    "        spans.extend(all_nouns)\n",
    "\n",
    "        # Adding Plural and Singular Versions of Spans\n",
    "        for span in spans:\n",
    "            text = span.text.lower()\n",
    "            text = self.main.delete_extra_whitespace(self.main.delete_outer_non_alnum(text))\n",
    "\n",
    "            # Blank Text or No Letters\n",
    "            if not text or not [c for c in text if c.isalpha()]:\n",
    "                continue\n",
    "\n",
    "            search_strings.append(text)\n",
    "\n",
    "            # Add Plural Version\n",
    "            singular = span[-1].pos_ == \"NOUN\" and span[-1].tag_ == \"NN\"\n",
    "            if singular:\n",
    "                plural_version = self.main.pluralize(text)\n",
    "                search_strings.extend(plural_version)\n",
    "\n",
    "            # Add Singular Version\n",
    "            plural = span[-1].pos_ == \"NOUN\" and span[-1].tag_ == \"NNS\"\n",
    "            if plural:\n",
    "                singular_version = self.main.singularize(text)\n",
    "                search_strings.extend(singular_version)\n",
    "\n",
    "        # Remove Duplicates\n",
    "        search_strings = list(set(search_strings))\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Search Strings: {search_strings}\")\n",
    "        \n",
    "        return search_strings\n",
    "\n",
    "\n",
    "\n",
    "    def load_alternate_names(self, spans, verbose=False):\n",
    "        spans.sort(key=lambda span: span.start)\n",
    "\n",
    "        # It's useful to know if a different name refers to a\n",
    "        # species we have already seen. For example, in\n",
    "        # \"predatory crab (Carcinus maenas)\", \"predatory crab\"\n",
    "        # is an alternative name for \"Carcinus maenas\" and\n",
    "        # vice versa. This is used so that the species can be\n",
    "        # properly tracked and redundant points are less\n",
    "        # likely to be given.\n",
    "        alternate_names = {}\n",
    "        \n",
    "        # Finding and Storing Alternative Names\n",
    "        for i, species_span in enumerate(spans):\n",
    "            # There's not a next species to\n",
    "            # evaluate.\n",
    "            if i + 1 >= len(spans):\n",
    "                break\n",
    "            \n",
    "            next_species_span = spans[i+1]\n",
    "            \n",
    "            # If there's one token between the species and the next species,\n",
    "            # we check if the next species is surrounded by punctuation.\n",
    "            if next_species_span.start - species_span.end == 1:\n",
    "                # Token Before and After the Next Species\n",
    "                before_next = self.main.sp_doc[next_species_span.start-1]\n",
    "                after_next = self.main.sp_doc[next_species_span.end]\n",
    "\n",
    "                if before_next.pos_ in [\"PUNCT\", \"SYM\"] and after_next.pos_ in [\"PUNCT\", \"SYM\"]:\n",
    "                    sp_1_text = species_span.text.lower()\n",
    "                    sp_2_text = next_species_span.text.lower()\n",
    "                    \n",
    "                    if sp_1_text not in alternate_names:\n",
    "                        alternate_names[sp_1_text] = []\n",
    "                    \n",
    "                    if sp_2_text not in alternate_names:\n",
    "                        alternate_names[sp_2_text] = []\n",
    "                    \n",
    "                    alternate_names[sp_1_text].append(sp_2_text)\n",
    "                    alternate_names[sp_2_text].append(sp_1_text)\n",
    "            # If there's no token between the species and the next,\n",
    "            # species we assume that they refer to the same species.\n",
    "            elif next_species_span.start - species_span.end == 0:\n",
    "                sp_1_text = species_span.text.lower()\n",
    "                sp_2_text = next_species_span.text.lower()\n",
    "                \n",
    "                if sp_1_text not in alternate_names:\n",
    "                    alternate_names[sp_1_text] = []\n",
    "                \n",
    "                if sp_2_text not in alternate_names:\n",
    "                    alternate_names[sp_2_text] = []\n",
    "\n",
    "                alternate_names[sp_1_text].append(sp_2_text)\n",
    "                alternate_names[sp_2_text].append(sp_1_text)\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Alternate Names: {alternate_names}\")\n",
    "\n",
    "        return alternate_names\n",
    "\n",
    "\n",
    "\n",
    "    def load_species(self, verbose=False):\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        # Load Search Strings from Species Spans\n",
    "        search_strings = self.load_search_strings(verbose=verbose)\n",
    "\n",
    "        # Search for Species\n",
    "        # The results are stored in different \n",
    "        # forms below.\n",
    "        spans = []\n",
    "        tokens = []\n",
    "        token_to_span = {}\n",
    "\n",
    "        # Where we're searching for species.\n",
    "        text = self.main.sp_doc.text.lower()\n",
    "\n",
    "        for string in search_strings:\n",
    "            matches = re.finditer(re.escape(string), text, re.IGNORECASE)\n",
    "\n",
    "            for l_char_index, r_char_index, matched_text in [(match.start(), match.end(), match.group()) for match in matches]:    \n",
    "                # The full word must match, not just a substring inside of it.\n",
    "                # So, if the species we're looking for is \"ant\", only \"ant\"\n",
    "                # will match -- not \"pants\" or \"antebellum\". Therefore, the\n",
    "                # characters to the left and right of the matched string cannot\n",
    "                # be letters.\n",
    "                l_char_is_letter = l_char_index > 0 and text[l_char_index-1].isalpha()\n",
    "                r_char_is_letter = r_char_index < len(text) and text[r_char_index].isalpha()\n",
    "                \n",
    "                if l_char_is_letter or r_char_is_letter or not matched_text:\n",
    "                    continue\n",
    "\n",
    "                try:\n",
    "                    l_token_i = self.main.token_at_char(l_char_index).i\n",
    "                    r_token_i = self.main.token_at_char(r_char_index-1).i\n",
    "                except Exception as e:\n",
    "                    print(f\"Error: Unable to find token at index of {l_char_index}.\")\n",
    "                    print(f\"Error: Unable to find token at index of {r_char_index}.\")\n",
    "                    print(f\"\\tMatched: '{matched_text}'\")\n",
    "                    print(e)\n",
    "                    continue\n",
    "\n",
    "                # This is the matched substring (which would be\n",
    "                # a species) as a span in the parent document.\n",
    "                span = self.main.sp_doc[l_token_i:r_token_i+1]\n",
    "                \n",
    "                # Expand Species\n",
    "                # Let's say there's a word like \"squirrel\". That's a bit ambiguous. \n",
    "                # Is it a brown squirrel, a bonobo? If the species is possibly missing\n",
    "                # information (like an adjective to the left of it), we should expand\n",
    "                # in order to get a full picture of the species.\n",
    "                unclear_1 = len(span) == 1 and span[0].pos_ == \"NOUN\"\n",
    "                unclear_2 = span.start > 0 and self.main.sp_doc[span.start-1].pos_ in [\"ADJ\"]\n",
    "                \n",
    "                if unclear_1 or unclear_2:\n",
    "                    span = self.main.expand_unit(\n",
    "                        il_unit=span.start, \n",
    "                        ir_unit=span.end-1,\n",
    "                        il_boundary=0,\n",
    "                        ir_boundary=len(self.main.sp_doc),\n",
    "                        speech=[\"ADJ\", \"PROPN\"],\n",
    "                        literals=[\"-\"],\n",
    "                        include=True,\n",
    "                        direction=\"LEFT\",\n",
    "                        verbose=verbose\n",
    "                    )\n",
    "                \n",
    "                # Remove Outer Symbols\n",
    "                # There are times where a species is identified with a parenthesis\n",
    "                # nearby. Here, we remove that parenthesis (and any other symbols).\n",
    "                span = self.main.contract_unit(\n",
    "                    il_unit=span.start, \n",
    "                    ir_unit=span.end-1, \n",
    "                    speech=[\"PUNCT\", \"SYM\", \"DET\", \"PART\"],\n",
    "                    include=False,\n",
    "                    verbose=verbose\n",
    "                )\n",
    "\n",
    "                if not span:\n",
    "                    print(f\"Error: Span does not exist; left character index {l_char_index}.\")\n",
    "                    print(f\"\\tMatched: '{matched_text}'\")\n",
    "                    continue\n",
    "            \n",
    "                # A species must have a noun or a\n",
    "                # proper noun. This may help discard\n",
    "                # bad results.\n",
    "                letter_found = False\n",
    "                for token in span:\n",
    "                    if token.pos_ in [\"NOUN\", \"PROPN\"] or token.lower_ in self.dictionary:\n",
    "                        letter_found = True\n",
    "                        break\n",
    "\n",
    "                if not letter_found:\n",
    "                    continue\n",
    "\n",
    "                # Adding Species\n",
    "                spans.append(span)\n",
    "                for token in span:\n",
    "                    if token in tokens or token.pos_ in [\"PUNCT\", \"SYM\", \"DET\", \"PART\"]:\n",
    "                        continue\n",
    "                    tokens.append(token)\n",
    "                    token_to_span[token] = span\n",
    "        \n",
    "        spans = list({span.start: span for span in spans}.values())\n",
    "        spans.sort(key=lambda span: span.start)\n",
    "        \n",
    "        span_starts = [span[0] for span in spans]\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(\"Output of load_species:\")\n",
    "            print(f\"Spans: {spans}\")\n",
    "            print(f\"Tokens: {tokens}\")\n",
    "            print(f\"Mapped Tokens: {token_to_span}\")\n",
    "            print(f\"Span Starts: {span_starts}\")\n",
    "        \n",
    "        return (spans, tokens, token_to_span, span_starts)\n",
    "\n",
    "\n",
    "\n",
    "    def is_alternate(self, sp_a, sp_b):\n",
    "        sp_b_text = sp_b.text.lower()\n",
    "        sp_a_text = sp_a.text.lower()\n",
    "            \n",
    "        # Species B is an alternate name for Species A\n",
    "        if sp_b_text in self.alternate_names.get(sp_a_text, []):\n",
    "            return True\n",
    "        \n",
    "        # Species A is an alternate name for Species B\n",
    "        if sp_a_text in self.alternate_names.get(sp_b_text, []):\n",
    "            return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    def is_same_text(self, sp_a, sp_b):\n",
    "        sp_b_text = sp_b.text.lower()\n",
    "        sp_a_text = sp_a.text.lower()\n",
    "\n",
    "        if sp_a_text == sp_b_text:\n",
    "            return True\n",
    "            \n",
    "        sp_a_singular_texts = [sp_a_text] if sp_a[-1].tag_ in [\"NN\", \"NNP\"] else self.main.singularize(sp_a_text)\n",
    "        sp_b_singular_texts = [sp_b_text] if sp_b[-1].tag_ in [\"NN\", \"NNP\"] else self.main.singularize(sp_b_text)\n",
    "\n",
    "        if set(sp_a_singular_texts).intersection(sp_b_singular_texts):\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    def has_same_base_nouns(self, sp_a, sp_b):\n",
    "        sp_b_text = sp_b.text.lower()\n",
    "        sp_b_0_text = sp_b[0].lower_\n",
    "        sp_b_0_is_noun = sp_b[0].pos_ in [\"NOUN\", \"PROPN\"]\n",
    "        \n",
    "        sp_b_nouns = []\n",
    "        sp_b_num_adjectives = 0\n",
    "        \n",
    "        for token in sp_b:\n",
    "            if not sp_b_nouns and token.pos_ == \"ADJ\":\n",
    "                sp_b_num_adjectives += 1\n",
    "            elif token.pos_ in [\"PROPN\", \"NOUN\"]:\n",
    "                sp_b_nouns.append(token)\n",
    "\n",
    "        if not sp_b_nouns:\n",
    "            return False\n",
    "\n",
    "        sp_b_nouns_text = [noun.lower_ for noun in sp_b_nouns]\n",
    "        sp_b_singular_texts = [\" \".join(sp_b_nouns_text)] if sp_b_nouns[-1].tag_ in [\"NN\", \"NNP\"] else self.main.singularize(\" \".join(sp_b_nouns_text))\n",
    "\n",
    "        sp_a_text = sp_a.text.lower()\n",
    "        sp_a_0_text = sp_a[0].lower_\n",
    "        sp_a_0_is_noun = sp_a[0].pos_ in [\"NOUN\", \"PROPN\"]\n",
    "\n",
    "        # Case Example: 'Hyla' v. 'Hyla tadpoles'\n",
    "        if sp_a_0_text == sp_b_0_text and (sp_a_0_is_noun or sp_b_0_is_noun):\n",
    "            if sp_a_text in sp_b_text or sp_b_text in sp_a_text:\n",
    "                return True\n",
    "        \n",
    "        # Case Example: 'dogs' v. 'red dogs'\n",
    "        sp_a_nouns = []\n",
    "        sp_a_num_adjectives = 0\n",
    "        for token in sp_a:\n",
    "            if not sp_a_nouns and token.pos_ == \"ADJ\":\n",
    "                sp_a_num_adjectives += 1\n",
    "            elif token.pos_ in [\"PROPN\", \"NOUN\"]:\n",
    "                sp_a_nouns.append(token)\n",
    "        \n",
    "        if not sp_a_nouns:\n",
    "            return False\n",
    "        \n",
    "        sp_a_nouns_text = [noun.lower_ for noun in sp_a_nouns]\n",
    "        \n",
    "        if sp_a_nouns and sp_b_nouns and (\n",
    "            (sp_a_num_adjectives == 1 and sp_b_num_adjectives == 0) or \n",
    "            (sp_b_num_adjectives == 1 and sp_a_num_adjectives == 0)\n",
    "        ):\n",
    "            sp_a_singular_texts = [\" \".join(sp_a_nouns_text)] if sp_a_nouns[-1].tag_ in [\"NN\", \"NNP\"] else self.main.singularize(\" \".join(sp_a_nouns_text))\n",
    "            if set(sp_a_singular_texts).intersection(sp_b_singular_texts):\n",
    "                return True\n",
    "\n",
    "        return False\n",
    "\n",
    "\n",
    "\n",
    "    def find_same_species(self, sp_A, sp_b, verbose=False):\n",
    "        # METHOD 1: Check for Literal Matches\n",
    "        for sp_a in sp_A:\n",
    "            if self.is_same_text(sp_a, sp_b):\n",
    "                if verbose and VERBOSE_LEVEL >= 1:\n",
    "                    print(f\"Method 1: Match Between '{sp_a}' and '{sp_b}'\")\n",
    "                return sp_a\n",
    "\n",
    "        # METHOD 2: Check Alternate Names\n",
    "        for sp_a in sp_A:\n",
    "            if self.is_alternate(sp_a, sp_b):\n",
    "                if verbose and VERBOSE_LEVEL >= 1:\n",
    "                    print(f\"Method 2: Match Between '{sp_a}' and '{sp_b}'\")\n",
    "                return sp_a\n",
    "        \n",
    "        # METHOD 3: Check Nouns\n",
    "        # This is used if one or none of the species being compared\n",
    "        # has 1 adjective.\n",
    "        for sp_a in sp_A:\n",
    "            if self.has_same_base_nouns(sp_a, sp_b):\n",
    "                if verbose and VERBOSE_LEVEL >= 1:\n",
    "                    print(f\"Method 3: Match Between '{sp_a}' and '{sp_b}'\")\n",
    "                return sp_a\n",
    "\n",
    "        # METHOD 4: Last Ditch Effort\n",
    "        # If there's been no matches, we just look for one string inside of\n",
    "        # another.\n",
    "        for sp_a in sp_A:\n",
    "            sp_a_text = sp_a.text.lower()\n",
    "            sp_b_text = sp_b.text.lower()\n",
    "            \n",
    "            r_sp_a_text = re.compile(f\"(\\s|^){sp_a_text}(\\s|$)\", re.IGNORECASE)\n",
    "            r_sp_b_text = re.compile(f\"(\\s|^){sp_b_text}(\\s|$)\", re.IGNORECASE)\n",
    "            \n",
    "            if re.match(r_sp_a_text, sp_b_text) or re.match(r_sp_b_text, sp_a_text):\n",
    "                if verbose and VERBOSE_LEVEL >= 1:\n",
    "                    print(f\"Method 4: Match Between '{sp_a}' and '{sp_b}'\")\n",
    "                return sp_a\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"No Matches Between {sp_A} and {sp_b}\")\n",
    "        \n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "    def span_at_token(self, token):\n",
    "        if token in self.token_to_span:\n",
    "            return self.token_to_span[token]\n",
    "        return None\n",
    "\n",
    "\n",
    "\n",
    "    def is_species(self, token):\n",
    "        return token in self.tokens\n",
    "\n",
    "\n",
    "\n",
    "    def has_species(self, tokens, verbose=False):\n",
    "        for token in tokens:\n",
    "            if token in self.tokens:\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tToken '{token}' is Species\")\n",
    "                return True\n",
    "        return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "c50028be-77a2-452c-9808-0a9ebad62620",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Keywords:\n",
    "    REGEX = \"regex\"\n",
    "    VOCAB = \"vocab\"\n",
    "    RULES = \"rules\"\n",
    "\n",
    "\n",
    "\n",
    "    def __init__(self, main, *, regexes=[], vocab=[], patterns=[], def_pos=[], def_tag=[], def_threshold=0.7, def_weight=1.0):\n",
    "        self.main = main\n",
    "\n",
    "        # Constraints\n",
    "        self.def_threshold = def_threshold\n",
    "        self.def_tag = def_tag\n",
    "        self.def_pos = def_pos\n",
    "        self.def_weight = def_weight\n",
    "        \n",
    "        # Three Types of Matching\n",
    "        self.vocab, self.vocab_data = self.load_vocab(vocab)\n",
    "        self.regex, self.regex_data = self.load_regex(regexes)\n",
    "        self.rules, self.rules_data = self.load_rules(patterns)\n",
    "\n",
    "        # Quick Lookup\n",
    "        self.match_type_to_data= {\n",
    "            Keywords.REGEX: self.regex_data,\n",
    "            Keywords.VOCAB: self.vocab_data,\n",
    "            Keywords.RULES: self.rules_data\n",
    "        }\n",
    "\n",
    "    \n",
    "\n",
    "    def update(self, verbose=False):\n",
    "        # SpaCy Doc DNE or Indexing Map DNE\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "        # Matched Tokens in Different Forms\n",
    "        self.token_data, self.mapped_token_data, self.tokens = self.match_tokens(verbose=verbose)\n",
    "\n",
    "\n",
    "\n",
    "    def load_regex(self, regexes):\n",
    "        r = []\n",
    "        r_data = {}\n",
    "\n",
    "        for unit in regexes:\n",
    "            if isinstance(unit, str):\n",
    "                r.append(unit)\n",
    "            else:\n",
    "                regex = unit[\"regex\"]\n",
    "                r.append(regex)\n",
    "                r_data[regex] = {\n",
    "                    \"types\": unit.get(\"types\", []),\n",
    "                    \"weight\": unit.get(\"weight\", self.def_weight)\n",
    "                }\n",
    "\n",
    "        return r, r_data\n",
    "\n",
    "\n",
    "\n",
    "    def load_vocab(self, vocab):\n",
    "        v = []\n",
    "        v_data = {}\n",
    "        \n",
    "        for unit in vocab:\n",
    "            if isinstance(unit, str):\n",
    "                doc = self.main.sp_nlp(unit)\n",
    "                v.append({\n",
    "                    \"doc\": doc,\n",
    "                    \"lemma\": \" \".join([t.lemma_ for t in doc])\n",
    "                })\n",
    "            else:\n",
    "                doc = self.main.sp_nlp(unit[\"word\"])\n",
    "                v.append({\n",
    "                    \"doc\": doc,\n",
    "                    \"tag\": unit.get(\"tag\", self.def_tag),\n",
    "                    \"pos\": unit.get(\"pos\", self.def_pos),\n",
    "                    \"threshold\": unit.get(\"threshold\", self.def_threshold),\n",
    "                    \"lemma\": \" \".join([t.lemma_ for t in doc])\n",
    "                })\n",
    "                v_data[unit[\"word\"]] = {\n",
    "                    \"types\": unit.get(\"types\") or [],\n",
    "                    \"weight\": unit.get(\"weight\", self.def_weight),\n",
    "                }\n",
    "        \n",
    "        return v, v_data\n",
    "\n",
    "\n",
    "\n",
    "    def load_rules(self, patterns):\n",
    "        r = Matcher(self.main.sp_nlp.vocab)\n",
    "        r_data = {}\n",
    "        \n",
    "        for i, unit in enumerate(patterns):\n",
    "            if isinstance(unit, list):\n",
    "                r.add(f\"{i}\", unit)\n",
    "            else:\n",
    "                r.add(unit[\"name\"], unit[\"pattern\"])\n",
    "                r_data[unit[\"name\"]] = {\n",
    "                    \"types\": unit.get(\"types\") or [],\n",
    "                    \"weight\": unit.get(\"weight\", self.def_weight),\n",
    "                }\n",
    "\n",
    "        return r, r_data\n",
    "\n",
    "\n",
    "\n",
    "    def get_match_data(self, token, match_id, match_type):\n",
    "        match_type_data = self.match_type_to_data[match_type]\n",
    "        \n",
    "        if match_id in match_type_data:\n",
    "            return {\n",
    "                \"token\": token,\n",
    "                \"types\": match_type_data[match_id].get(\"types\", []),\n",
    "                \"weight\": match_type_data[match_id].get(\"weight\", self.def_weight)\n",
    "            }\n",
    "        else:\n",
    "            return {\n",
    "                \"token\": token,\n",
    "                \"types\": [],\n",
    "                \"weight\": self.def_weight\n",
    "            }\n",
    "\n",
    "\n",
    "\n",
    "    def bad_pos(self, pos):\n",
    "        return self.def_pos and pos not in self.def_pos\n",
    "\n",
    "\n",
    "\n",
    "    def bad_tag(self, tag):\n",
    "        return self.def_tag and tag not in self.def_tag\n",
    "\n",
    "\n",
    "\n",
    "    def bad_token(self, token):\n",
    "        return self.bad_pos(token.pos_) or self.bad_tag(token.tag_)\n",
    "\n",
    "\n",
    "\n",
    "    def match_tokens(self, verbose=False):\n",
    "        # SpaCy Doc DNE or Indexing Map DNE\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "        \n",
    "        matched_data = []\n",
    "        matched_tokens = []\n",
    "\n",
    "        # Match by Regex\n",
    "        text = self.main.sp_doc.text.lower()\n",
    "        \n",
    "        for regex in self.regex:\n",
    "            matches = [(match.start(), match.end()) for match in re.finditer(regex, text, re.IGNORECASE)]\n",
    "            \n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\t'{regex}' Regex Matches: {matches}\")\n",
    "            \n",
    "            for l_char_index, r_char_index in matches:\n",
    "                span = self.main.get_span_at_indices(l_char_index, r_char_index - 1)\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 3:\n",
    "                    print(f\"\\t\\tSpan Matched: {span}\")\n",
    "\n",
    "                for token in span:\n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\tPossible Regex Match for Token '{token}' (Position: {token.pos_} and Tag: {token.tag_})\")\n",
    "                        \n",
    "                    if self.bad_token(token):\n",
    "                        continue\n",
    "                    \n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\tRegex Matched Token '{token}'\")\n",
    "                        \n",
    "                    matched_tokens.append(token)\n",
    "                    matched_data.append(self.get_match_data(token, regex, Keywords.REGEX))\n",
    "\n",
    "        # Match by Rules\n",
    "        matches = self.rules(self.main.sp_doc)\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 2:\n",
    "            print(f\"\\tRule Matches: {matches}\")\n",
    "        \n",
    "        for match_id, start, end in matches:\n",
    "            span = self.main.sp_doc[start:end]\n",
    "            name = self.main.sp_nlp.vocab.strings[match_id]\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tPattern '{name}' Matched Span: {span}\")\n",
    "            \n",
    "            for token in span:\n",
    "                if verbose and VERBOSE_LEVEL >= 3:\n",
    "                    print(f\"\\t\\tPossible Rule Match for Token '{token}' (Position: {token.pos_} and Tag: {token.tag_})\")\n",
    "                    \n",
    "                if self.bad_token(token):\n",
    "                    continue\n",
    "                \n",
    "                if verbose and VERBOSE_LEVEL >= 3:\n",
    "                    print(f\"\\t\\tRule Matched Token '{token}'\")\n",
    "\n",
    "                matched_tokens.append(token)\n",
    "                matched_data.append(self.get_match_data(token, name, Keywords.RULES))\n",
    "\n",
    "        # Match by Vocab\n",
    "        for token in self.main.sp_doc:\n",
    "            if verbose and VERBOSE_LEVEL >= 3:\n",
    "                    print(f\"\\t\\tPossible Vocab Match for Token '{token}' (Position: {token.pos_} and Tag: {token.tag_})\")\n",
    "                    \n",
    "            if self.bad_token(token) or token in matched_tokens:\n",
    "                continue\n",
    "\n",
    "            token_doc = self.main.sp_nlp(token.lower_)\n",
    "            token_lemma = \" \".join([t.lemma_ for t in token_doc])\n",
    "            \n",
    "            for vocab_word in self.vocab:\n",
    "                # Ensure Correct Tag\n",
    "                if vocab_word.get(\"tag\"):\n",
    "                    if not [t for t in token_doc if t.tag_ in vocab_word.get(\"tag\")]:\n",
    "                        if verbose and VERBOSE_LEVEL >= 4:\n",
    "                            print(f\"\\t\\t\\tToken '{token_doc}' not in Vocab Word '{vocab_word['doc']}' Tags ({vocab_word.get('tag')})\")\n",
    "                        continue\n",
    "                \n",
    "                # Ensure Correct PoS\n",
    "                if vocab_word.get(\"pos\"):\n",
    "                    if not [t for t in token_doc if t.pos_ in vocab_word.get(\"pos\")]:\n",
    "                        if verbose and VERBOSE_LEVEL >= 4:\n",
    "                            print(f\"\\t\\t\\tToken '{token_doc}' not in Vocab Word '{vocab_word['doc']}' Speech ({vocab_word.get('pos')})\")\n",
    "                        continue\n",
    "\n",
    "                # Check Lemma\n",
    "                if verbose and VERBOSE_LEVEL >= 4:\n",
    "                    print(f\"\\t\\t\\t{token_doc} Lemma ({token_lemma}) and {vocab_word['doc']} Lemma ({vocab_word['lemma']})\")\n",
    "                    \n",
    "                if token_lemma == vocab_word[\"lemma\"]:\n",
    "                    matched_tokens.append(token)\n",
    "                    matched_data.append(self.get_match_data(token, vocab_word[\"doc\"].text, Keywords.VOCAB))\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\tVocab (Lemma) Matched Token '{token}'\")\n",
    "                    \n",
    "                    break\n",
    "\n",
    "                # Check Similarity\n",
    "                similarity = vocab_word[\"doc\"].similarity(token_doc)\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 4:\n",
    "                    print(f\"\\t\\t\\t{token_doc} and {vocab_word['doc']} Similarity: {similarity}\")\n",
    "                    \n",
    "                if similarity >= vocab_word.get(\"threshold\", self.def_threshold):\n",
    "                    matched_tokens.append(token)\n",
    "                    matched_data.append(self.get_match_data(token, vocab_word[\"doc\"].text, Keywords.VOCAB))\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\tVocab Matched Token '{token}'\")\n",
    "                        \n",
    "                    break\n",
    "\n",
    "        # Mapping Match(ed Token) Data\n",
    "        mapped_matched_data = {}\n",
    "        for matched_token_data in matched_data:\n",
    "            mapped_matched_data[matched_token_data[\"token\"]] = matched_token_data\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(\"Output of match_tokens\")\n",
    "            print(f\"Token Data: {matched_data}\")\n",
    "            print(f\"Mapped Token Data: {mapped_matched_data}\")\n",
    "            print(f\"Token: {matched_tokens}\")\n",
    "        \n",
    "        return matched_data, mapped_matched_data, matched_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "83658627-3be1-4c6f-9b7e-37ad93ceb57b",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ExperimentKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            vocab=[\n",
    "                \"study\", \n",
    "                \"hypothesis\", \n",
    "                \"experiment\", \n",
    "                \"found\", \n",
    "                \"discover\", \n",
    "                \"compare\", \n",
    "                \"finding\", \n",
    "                \"result\", \n",
    "                \"test\", \n",
    "                \"examine\", \n",
    "                \"model\",\n",
    "                \"measure\",\n",
    "                \"manipulate\",\n",
    "                \"assess\",\n",
    "                \"conduct\",\n",
    "                \"data\",\n",
    "                \"analyze\",\n",
    "                \"sample\",\n",
    "                \"observe\",\n",
    "                \"observation\",\n",
    "                \"predict\",\n",
    "                \"suggest\",\n",
    "                \"method\",\n",
    "                \"investigation\",\n",
    "                \"trial\",\n",
    "                \"experimental\",\n",
    "                \"evidence\",\n",
    "                \"demonstrate\",\n",
    "                \"analysis\",\n",
    "                \"show\",\n",
    "                \"compare\",\n",
    "                \"comparable\",\n",
    "                \"control group\", \n",
    "                \"independent\",\n",
    "                \"dependent\",\n",
    "                \"applied\",\n",
    "                \"treatment\",\n",
    "                \"survery\",\n",
    "                \"evaluate\",\n",
    "            ],\n",
    "            def_pos=[\"VERB\", \"NOUN\", \"ADJ\"], \n",
    "            def_threshold=0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "924641b9-9216-4b44-9cb9-0fa1bb303b43",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeExperimentKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            vocab=[\n",
    "                \"theory\",\n",
    "                \"review\",\n",
    "                \"analysis\",\n",
    "                \"meta-analysis\"\n",
    "            ],\n",
    "            def_pos=[\"VERB\", \"NOUN\", \"ADJ\"], \n",
    "            def_threshold=0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "7a6c38cf-af1d-40b4-9cec-62c644855534",
   "metadata": {},
   "outputs": [],
   "source": [
    "class NegativeTopicKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            regexes=[\n",
    "                r\"co-?evolution\",\n",
    "                r\"evolution\",\n",
    "            ],\n",
    "            def_pos=[\"VERB\", \"NOUN\", \"ADJ\"], \n",
    "            def_threshold=0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "b474d22b-6eb4-4df7-9d90-28424dea1636",
   "metadata": {},
   "outputs": [],
   "source": [
    "class CauseKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            vocab=[\n",
    "                \"increase\", \n",
    "                \"decrease\", \n",
    "                \"change\", \n",
    "                \"shift\", \n",
    "                \"cause\", \n",
    "                \"produce\", \n",
    "                \"trigger\", \n",
    "                \"suppress\", \n",
    "                \"inhibit\",\n",
    "                \"encourage\",\n",
    "                \"allow\",\n",
    "                \"influence\",\n",
    "                \"affect\",\n",
    "                \"alter\",\n",
    "                \"induce\",\n",
    "                \"produce\",\n",
    "                \"result in\",\n",
    "                # \"associated with\",\n",
    "                # \"correlated with\",\n",
    "                \"contribute\",\n",
    "                \"impact\",\n",
    "                \"deter\",\n",
    "                \"depressed\",\n",
    "                \"when\",\n",
    "                \"because\",\n",
    "                # \"reduce\",\n",
    "                # \"killed\",\n",
    "                # \"supported\"\n",
    "            ],\n",
    "            def_pos=[\"VERB\", \"SCONJ\", \"NOUN\"],\n",
    "            # def_tag=[\"VB\", \"VBD\", \"WRB\", \"IN\", \"VBG\"],\n",
    "            # def_threshold=0.75\n",
    "            def_threshold=0.8\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    def update(self, verbose=False):\n",
    "        Keywords.update(self, verbose)\n",
    "        self.tokens = self.filter_tokens(self.tokens, verbose)\n",
    "\n",
    "\n",
    "    \n",
    "    def filter_tokens(self, tokens, verbose=False):\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        filtered = []\n",
    "        for token in tokens:\n",
    "            # I'm not sure what cause words should be filtered out, because\n",
    "            # I haven't seen everything, but this word should be filtered out,\n",
    "            # it's not really reflective the changes that we're looking for. But,\n",
    "            # sometimes it is, so it's up in the air. However, I feel like the\n",
    "            # writer would use more clear language like \"decrease\" or something.\n",
    "            if token.lemma_ in [\"kill\"]:\n",
    "                continue\n",
    "            filtered.append(token)\n",
    "            \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "0a586e5f-2dcb-42c4-ac6f-575febea3079",
   "metadata": {},
   "outputs": [],
   "source": [
    "class ChangeKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            vocab=[\n",
    "                \"few\", \n",
    "                \"more\", \n",
    "                \"increase\", \n",
    "                \"decrease\", \n",
    "                \"less\", \n",
    "                \"short\", \n",
    "                \"long\", \n",
    "                \"greater\"\n",
    "                \"shift\",\n",
    "                \"fluctuate\",\n",
    "                \"adapt\",\n",
    "                \"grow\",\n",
    "                \"rise\"\n",
    "                \"surge\",\n",
    "                \"intensify\",\n",
    "                \"amplify\",\n",
    "                \"multiply\",\n",
    "                \"decline\",\n",
    "                \"reduce\",\n",
    "                \"drop\",\n",
    "                \"diminish\",\n",
    "                \"fall\",\n",
    "                \"lessen\",\n",
    "                \"doubled\",\n",
    "                \"tripled\",\n",
    "                \"lower\",\n",
    "            ],\n",
    "            regexes=[\n",
    "                # Match Examples:\n",
    "                # 1. \"one... as...\"\n",
    "                # 2. \"2x than...\"\n",
    "                r\"(one|two|three|four|five|six|seven|eight|nine|ten|twice|thrice|([0-9]+|[0-9]+.[0-9]+)(x|%))[\\s-]+[^\\s]*[\\s-]+(as|more|than|likely)([\\s-]+|$)\"\n",
    "            ],\n",
    "            def_pos=[\"NOUN\", \"ADJ\", \"ADV\"],\n",
    "            def_threshold=0.75\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    def update(self, verbose=False):\n",
    "        Keywords.update(self, verbose=verbose)\n",
    "        self.tokens = self.filter_tokens(self.tokens, verbose)\n",
    "\n",
    "\n",
    "    \n",
    "    def filter_tokens(self, tokens, verbose=False):\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        filtered = []\n",
    "        for token in self.main.sp_doc:\n",
    "            # Already Matched\n",
    "            if token in tokens:\n",
    "                filtered.append(token)\n",
    "            \n",
    "            # Comparative Adjective\n",
    "            # Looking for words like \"bigger\" and \"better\".\n",
    "            elif token.pos_ == \"ADJ\" and token.tag_ == \"JJR\":\n",
    "                filtered.append(token)\n",
    "                continue\n",
    "            \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "bf8be9de-1c7a-4246-a104-e9dd18e00d63",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TraitKeywords(Keywords):\n",
    "    FOOD = \"Food\"\n",
    "    NOT_APPLICABLE = \"N/A\"\n",
    "    \n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main, \n",
    "            regexes=[\n",
    "                r\"behaviou?r\", \n",
    "                r\"[^A-Za-z]+rate\", \n",
    "                \"colou?r\",\n",
    "                \"biomass\",\n",
    "                r\"[^A-Za-z]+mass\", \n",
    "                r\"[^A-Za-z]+size\",\n",
    "                \"number\",\n",
    "                \"length\", \n",
    "                \"pattern\", \n",
    "                \"weight\",\n",
    "                \"shape\", \n",
    "                \"efficiency\", \n",
    "                \"trait\",\n",
    "                \"phenotype\",\n",
    "                \"demography\",\n",
    "                \"scent\",\n",
    "                \"population (structure|mechanic)s?\",\n",
    "                \"ability\", \n",
    "                \"capacity\", \n",
    "                \"height\", \n",
    "                \"width\", \n",
    "                \"[A-Za-z]+span\",\n",
    "                {\"regex\": \"diet\", \"types\": [TraitKeywords.FOOD]},\n",
    "                {\"regex\": \"food\", \"types\": [TraitKeywords.FOOD, TraitKeywords.NOT_APPLICABLE]},\n",
    "                {\"regex\": \"feeding\", \"types\": [TraitKeywords.FOOD]},\n",
    "                \"nest\",\n",
    "                \"substrate\",\n",
    "                \"breeding\",\n",
    "                r\"[^A-Za-z]+age[^A-Za-z]+\",\n",
    "                \"lifespan\",\n",
    "                \"development\",\n",
    "                \"output\",\n",
    "                \"time\",\n",
    "                \"period\"\n",
    "                # \"mating\",\n",
    "                # \"[^A-Za-z]+fur\",\n",
    "                # \"feathers\",\n",
    "                # \"scales\",\n",
    "                # \"skin\",\n",
    "                # \"limb\",\n",
    "                \"level\",\n",
    "                \"configuration\",\n",
    "                \"dimorphism\",\n",
    "                \"capability\",\n",
    "                # \"appendages\",\n",
    "                # \"blood\",\n",
    "                \"regulation\",\n",
    "                \"excretion\",\n",
    "                \"luminescence\",\n",
    "                r\"[^A-Za-z]+role\",\n",
    "                # \"reproduction\",\n",
    "                # \"courtship\",\n",
    "                # \"pollination\",\n",
    "                # \"mechanism\",\n",
    "                \"sensitivity\",\n",
    "                \"resistance\",\n",
    "                r\"(un|(^|\\s)[A-Za-z]*-)infected\",\n",
    "                \"temperature\",\n",
    "                # \"fecundity\",\n",
    "                \"density\"\n",
    "            ],\n",
    "            def_pos=[\"NOUN\"]\n",
    "        )\n",
    "\n",
    "\n",
    "    \n",
    "    def update(self, verbose=False):\n",
    "        Keywords.update(self, verbose)\n",
    "        self.tokens = self.filter_tokens(self.tokens, verbose)\n",
    "\n",
    "\n",
    "    \n",
    "    def filter_tokens(self, tokens, verbose=False):\n",
    "        if not self.main.sp_doc or not self.main.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Unfiltered Trait Tokens: {tokens}\")\n",
    "        \n",
    "        filtered = []\n",
    "        for token in tokens:\n",
    "            expanded_token = self.main.expand_unit(\n",
    "                il_unit=token.i, \n",
    "                ir_unit=token.i, \n",
    "                il_boundary=token.sent.start, \n",
    "                ir_boundary=token.sent.end-1, \n",
    "                speech=[\"PUNCT\"],\n",
    "                include=False,\n",
    "                verbose=verbose\n",
    "            )\n",
    "\n",
    "            if self.main.species.has_species(expanded_token, verbose=verbose):\n",
    "                filtered.append(token)\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Filtered Trait Tokens: {filtered}\")\n",
    "        \n",
    "        return filtered"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "b2a68dbd-47ea-4396-a860-4ac6876b71bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "class TestKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main,\n",
    "            vocab=[\n",
    "                \"compare\",\n",
    "                \"examine\",\n",
    "                \"evaluate\",\n",
    "                \"assess\",\n",
    "            ],\n",
    "            def_pos=[\"VERB\", \"NOUN\"], \n",
    "            def_threshold=0.8\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "6b5dd3fe-54f9-4376-b381-1bb35a1d0424",
   "metadata": {},
   "outputs": [],
   "source": [
    "class VariabilityKeywords(Keywords):\n",
    "    def __init__(self, main):\n",
    "        super().__init__(\n",
    "            main,\n",
    "            vocab=[\n",
    "                {\"word\": \"different\", \"pos\": [\"ADJ\", \"NOUN\"]},\n",
    "                {\"word\": \"vary\", \"pos\": [\"VERB\", \"NOUN\"]},\n",
    "                {\"word\": \"varied\", \"pos\": [\"VERB\", \"NOUN\"]}\n",
    "            ],\n",
    "            regexes=[\n",
    "                r\"between\",\n",
    "                r\"against\",\n",
    "                r\"independen(t|ts|tly|cy)\",\n",
    "                r\"dependen(t|ts|tly|cy)\",\n",
    "                r\"treatments?\",\n",
    "                r\"effect\",\n",
    "                r\"control\",\n",
    "                r\"(with|without)[A-Za-z]*(with|without)\",\n",
    "                r\"(^| )(un|not)[-| ]?([A-Za-z]+) [^!;?.\\n]* \\3\",\n",
    "                r\"([A-Za-z]+) [^!;?.\\n]* (un|not)[-| ]?\\1( |$)\",\n",
    "                \n",
    "            ],\n",
    "            patterns=[\n",
    "                [[{\"LOWER\": {\"IN\": [\"neither\", \"either\", \"both\"]}}, {\"OP\": \"*\", \"TAG\": {\"NOT_IN\": [\".\"]}}, {\"LOWER\": {\"IN\": [\"or\", \"and\"]}}]],\n",
    "                [[{\"LOWER\": {\"IN\": [\"with\", \"without\"]}}, {\"OP\": \"*\", \"TAG\": {\"NOT_IN\": [\".\"]}}, {\"LOWER\": {\"IN\": [\"with\", \"without\"]}}]],\n",
    "                [[{\"LOWER\": {\"IN\": [\"at\"]}}, {\"POS\": \"NUM\"}]],\n",
    "                [[{\"LOWER\": {\"IN\": [\"at\"]}}, {\"LOWER\": {\"IN\": [\"several\", \"unique\", \"multiple\", \"different\"]}}]],\n",
    "            ],\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "79ff77d7-be07-41b5-aa7d-8ea134dda6ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Main(Base):\n",
    "    def __init__(self):\n",
    "        # Tools\n",
    "        self.sp_nlp = spacy.load(\"en_core_web_lg\")\n",
    "        self.fcoref = FCoref(enable_progress_bar=False, device='cpu')\n",
    "        self.sp_doc = None\n",
    "\n",
    "        # Maps Character Position to Token in Document\n",
    "        # Used to handle differences between different\n",
    "        # pipelines and tools.\n",
    "        self.index_map = None\n",
    "    \n",
    "        # Parsers\n",
    "        self.species = Species(self)\n",
    "        self.trait = TraitKeywords(self)\n",
    "        self.cause = CauseKeywords(self)\n",
    "        self.change = ChangeKeywords(self)\n",
    "        self.experiment = ExperimentKeywords(self)\n",
    "        self.not_experiment = NegativeExperimentKeywords(self)\n",
    "        self.not_topic = NegativeTopicKeywords(self)\n",
    "        self.variability = VariabilityKeywords(self)\n",
    "        self.test = TestKeywords(self)\n",
    "\n",
    "        # Helper\n",
    "        super().__init__(self)\n",
    "\n",
    "\n",
    "    \n",
    "    def update_doc(self, doc, verbose=False):\n",
    "        self.sp_doc = doc\n",
    "        self.index_map = self.load_index_map()\n",
    "        self.species.update(doc.text, verbose=False)\n",
    "        self.trait.update(verbose=verbose)\n",
    "        self.cause.update(verbose=False)\n",
    "        self.change.update(verbose=False)\n",
    "        self.experiment.update(verbose=False)\n",
    "        self.not_experiment.update(verbose=False)\n",
    "        self.not_topic.update(verbose=False)\n",
    "        self.variability.update(verbose=False)\n",
    "        self.test.update(verbose=False)\n",
    "\n",
    "\n",
    "        \n",
    "    def update_text(self, text, verbose=False):\n",
    "        self.sp_doc = self.sp_nlp(text)\n",
    "        self.update_doc(self.sp_doc, verbose=verbose)\n",
    "\n",
    "\n",
    "        \n",
    "    def token_at_char(self, char_index):\n",
    "        # SpaCy Doc or Indexing Map Not Found\n",
    "        if not self.sp_doc or not self.index_map:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        if char_index in self.index_map:\n",
    "            return self.index_map[char_index]\n",
    "\n",
    "        raise Exception(f\"Token at Index {char_index} Not Found\")\n",
    "\n",
    "\n",
    "        \n",
    "    def load_index_map(self):\n",
    "        # SpaCy Doc Not Found\n",
    "        if self.sp_doc is None:\n",
    "            raise Exception(\"DNE\")\n",
    "\n",
    "        # Map Character Index to Token\n",
    "        index_map = {}\n",
    "        for token in self.sp_doc:\n",
    "            l_char_index = token.idx\n",
    "            r_char_index = token.idx + len(token)\n",
    "\n",
    "            for i in range(l_char_index, r_char_index):\n",
    "                index_map[i] = token\n",
    "\n",
    "        return index_map\n",
    "\n",
    "\n",
    "        \n",
    "    def valid_trait_token(self, token, sent_cause_tokens, sent_change_tokens, verbose=False):\n",
    "        if token not in self.trait.tokens:\n",
    "            return 0\n",
    "\n",
    "        token_data = self.trait.mapped_token_data[token]\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Token '{token}' Types: {token_data['types']}\")\n",
    "            \n",
    "        if TraitKeywords.NOT_APPLICABLE in token_data[\"types\"]:\n",
    "            return 0\n",
    "\n",
    "        token_context = set(self.find_unit_context(\n",
    "            il_unit=token.i, \n",
    "            ir_unit=token.i, \n",
    "            il_boundary=token.sent.start, \n",
    "            ir_boundary=token.sent.end-1, \n",
    "            verbose=verbose)\n",
    "        )\n",
    "        \n",
    "        causes = set(sent_cause_tokens).intersection(token_context)\n",
    "        changes = set(sent_change_tokens).intersection(token_context)\n",
    "\n",
    "        if causes or changes:\n",
    "            return 1.0\n",
    "        else:\n",
    "            return 0.25\n",
    "\n",
    "\n",
    "    \n",
    "    def valid_species_token(self, token, sent_cause_tokens, sent_change_tokens, verbose=False):\n",
    "        if token not in self.species.tokens:\n",
    "            return 0\n",
    "        \n",
    "        token_context = set(self.find_unit_context(\n",
    "            il_unit=token.i, \n",
    "            ir_unit=token.i, \n",
    "            il_boundary=token.sent.start, \n",
    "            ir_boundary=token.sent.end-1, \n",
    "            verbose=verbose)\n",
    "        )\n",
    "        \n",
    "        causes = set(sent_cause_tokens).intersection(token_context)\n",
    "        changes = set(sent_change_tokens).intersection(token_context)\n",
    "\n",
    "        if causes or changes:\n",
    "            return 1\n",
    "        else:\n",
    "            return 0.25\n",
    "\n",
    "\n",
    "    \n",
    "    def update_seen_species(self, token, seen_species, sent_seen_species, sent_num_unique_species, verbose=False):\n",
    "        # Update Seen Species in Text\n",
    "        span = self.species.span_at_token(token)\n",
    "        past_visits = 0\n",
    "        prev_ref = self.species.find_same_species(seen_species.keys(), span, verbose=verbose)\n",
    "        \n",
    "        if prev_ref:\n",
    "            past_visits = seen_species[prev_ref]\n",
    "            seen_species[prev_ref] += 1\n",
    "        else:\n",
    "            seen_species[span] = 1\n",
    "\n",
    "        # Check Seen Species in Sentence\n",
    "        # We only add points if it's a species that has not been seen\n",
    "        # in the sentence. This is to avoid redundant points. \n",
    "        # Also, if it species has not been seen at all (is_new_species),\n",
    "        # then it cannot be a redundant species (we couldn't have seen it in the sentence\n",
    "        # either).\n",
    "        seen_in_sent = bool(self.species.find_same_species(sent_seen_species, span, verbose=verbose))        \n",
    "        sent_seen_species.append(span)\n",
    "\n",
    "        # Update Number of Unique Species in Sentence\n",
    "        if not seen_in_sent:\n",
    "            sent_num_unique_species += 1\n",
    "\n",
    "        return seen_species, sent_seen_species, seen_in_sent, sent_num_unique_species\n",
    "\n",
    "\n",
    "    \n",
    "    def valid_trait_variation(self, verbose=False):\n",
    "        max_trait_variation_points = 0\n",
    "        \n",
    "        sentences = list(self.sp_doc.sents)\n",
    "        num_sentences = len(sentences)\n",
    "\n",
    "        for i in range(num_sentences):\n",
    "            sent_i = sentences[i]\n",
    "            sent_i_tokens = set([token for token in sent_i])\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tSentence I: {sent_i}\")\n",
    "            \n",
    "            sent_i_test_tokens = sent_i_tokens.intersection(self.test.tokens)\n",
    "            sent_i_experiment_tokens = sent_i_tokens.intersection(self.experiment.tokens)\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tSentence I Test Tokens: {sent_i_test_tokens}\")\n",
    "                print(f\"\\tSentence I Experiment Tokens: {sent_i_experiment_tokens}\")\n",
    "\n",
    "            if not sent_i_test_tokens and not sent_i_experiment_tokens:\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tNo Experiment or Test Tokens in Sentence I\")\n",
    "                continue\n",
    "\n",
    "            trait_variation_points_i = 0\n",
    "\n",
    "            if sent_i_experiment_tokens:\n",
    "                trait_variation_points_i = 0.10\n",
    "            \n",
    "            if sent_i_test_tokens:\n",
    "                trait_variation_points_i = 0.25\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tTrait Variation Points for I: {trait_variation_points_i}\")\n",
    "\n",
    "            sent_i_trait_tokens = sent_i_tokens.intersection(self.trait.tokens)\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tSentence I Trait Tokens: {sent_i_trait_tokens}\")\n",
    "\n",
    "            if not sent_i_trait_tokens:\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tNo Trait Tokens in Sentence I\")\n",
    "                continue\n",
    "\n",
    "            variables = []\n",
    "            sent_i_variability_tokens = sent_i_tokens.intersection(self.variability.tokens)\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tSentence I Variability Tokens: {sent_i_variability_tokens}\")\n",
    "\n",
    "            deduct_points = not sent_i_variability_tokens\n",
    "            \n",
    "            if sent_i_variability_tokens:\n",
    "                for token in sent_i_variability_tokens:\n",
    "                    trait_in_context = set(self.find_unit_context(\n",
    "                        il_unit=token.i, \n",
    "                        ir_unit=token.i, \n",
    "                        il_boundary=token.sent.start,\n",
    "                        ir_boundary=token.sent.end-1, \n",
    "                        speech=[\"NOUN\", \"ADJ\", \"ADV\", \"PROPN\", \"ADP\", \"CCONJ\"],\n",
    "                        include=True,\n",
    "                        comma_encloses=True,\n",
    "                        verbose=verbose\n",
    "                    )).intersection(self.trait.tokens)\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\tVariability Token '{token}' Traits in Context: {trait_in_context}\") \n",
    "\n",
    "                    if not trait_in_context:\n",
    "                        if verbose and VERBOSE_LEVEL >= 3:\n",
    "                            print(f\"\\t\\tNo Traits in Variability Token '{token}' Context\")\n",
    "                        continue\n",
    "\n",
    "                    deduct_points = False\n",
    "                    variables.extend(trait_in_context)\n",
    "\n",
    "            variables = list(set(variables))\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tVariables: {variables}\")\n",
    "            \n",
    "            if variables:\n",
    "                trait_variation_points_i += 0.25\n",
    "            else:\n",
    "                trait_variation_points_i += 0.15\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tTrait Variation Points for I: {trait_variation_points_i}\")\n",
    "\n",
    "            assert trait_variation_points_i <= 0.5\n",
    "\n",
    "            for j in range(i, num_sentences):\n",
    "                sent_j = sentences[j]\n",
    "                sent_j_tokens = set([token for token in sent_j])\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tSentence J: {sent_j}\")\n",
    "\n",
    "                sent_j_cause_tokens = sent_j_tokens.intersection(self.cause.tokens)\n",
    "                sent_j_change_tokens = sent_j_tokens.intersection(self.change.tokens)\n",
    "                sent_j_species_tokens = sent_j_tokens.intersection(self.species.span_starts)\n",
    "                sent_j_trait_tokens = sent_j_tokens.intersection(self.trait.tokens)\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tSentence J Cause Tokens: {sent_j_cause_tokens}\")\n",
    "                    print(f\"\\tSentence J Change Tokens: {sent_j_change_tokens}\")\n",
    "                    print(f\"\\tSentence J Species Tokens: {sent_j_species_tokens}\")\n",
    "                    print(f\"\\tSentence J Trait Tokens: {sent_j_trait_tokens}\")\n",
    "                \n",
    "                if not sent_j_species_tokens or (not sent_j_cause_tokens and not sent_j_change_tokens):\n",
    "                    if verbose and VERBOSE_LEVEL >= 2:\n",
    "                        print(f\"\\tUnsatisfied Conditions for Sentence J\")\n",
    "                    continue\n",
    "\n",
    "                trait_variation_points_j = 0\n",
    "                \n",
    "                if not sent_j_trait_tokens or not variables:\n",
    "                    trait_variation_points_j += 0.25\n",
    "                elif i != j:\n",
    "                    # Check if Variable Referenced Again via Types\n",
    "                    variable_types = set(self.flatten([self.trait.mapped_token_data[token][\"types\"] for token in variables]))\n",
    "                    sent_j_trait_types = set(self.flatten([self.trait.mapped_token_data[token][\"types\"] for token in sent_j_trait_tokens]))\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 2:\n",
    "                        print(f\"\\tVariable Types: {variable_types}\")\n",
    "                        print(f\"\\tTrait Types in Sentence J: {sent_j_trait_types}\")\n",
    "                        \n",
    "                    # Check if Variable Referenced Again via Literals\n",
    "                    variable_strings = set([token.lower_ for token in variables])\n",
    "                    sent_j_trait_strings = set([token.lower_ for token in sent_j_trait_tokens])\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 2:\n",
    "                        print(f\"\\tVariable Trait (as Strings): {variable_strings}\")\n",
    "                        print(f\"\\tTrait (as Strings) in Sentence J: {sent_j_trait_strings}\")\n",
    "                    \n",
    "                    variable_referenced = bool(variable_types & sent_j_trait_types) or bool(variable_strings & sent_j_trait_strings)\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 2:\n",
    "                        print(f\"\\tVariable Referenced? {variable_referenced}\")\n",
    "                    \n",
    "                    if variable_referenced:\n",
    "                        trait_variation_points_j += 0.50\n",
    "                    else:\n",
    "                        trait_variation_points_j += 0.25\n",
    "                elif i == j:\n",
    "                    trait_variation_points_j += 0.25\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tTrait Variation Points for J: {trait_variation_points_j}\")\n",
    "\n",
    "                assert trait_variation_points_j <= 0.5\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\ti: {i}\")\n",
    "                    print(f\"\\tj: {j}\")\n",
    "\n",
    "                # Scale by Distance In-Between\n",
    "                if j == i:\n",
    "                    j_scale = 0.5\n",
    "                else:\n",
    "                    j_scale = (1 - ((j - i) / (num_sentences - 1)))\n",
    "                \n",
    "                assert j_scale <= 1\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tScale for Sentence J Points: {j_scale}\")\n",
    "                    \n",
    "                trait_variation_points = trait_variation_points_i + j_scale * trait_variation_points_j\n",
    "\n",
    "                # Scale by Distance from Top\n",
    "                if num_sentences == 1:\n",
    "                    i_scale = 1\n",
    "                else:\n",
    "                    i_scale = (1 - i/(num_sentences - 1))\n",
    "                    \n",
    "                assert i_scale <= 1\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tScale for Sentence I Points: {i_scale}\")\n",
    "                \n",
    "                trait_variation_points *= i_scale\n",
    "\n",
    "                if deduct_points:\n",
    "                    trait_variation_points *= 0.6375\n",
    "                \n",
    "                if verbose and VERBOSE_LEVEL >= 2:\n",
    "                    print(f\"\\tTrait Variation Points: {trait_variation_points}\")\n",
    "                \n",
    "                max_trait_variation_points = max(max_trait_variation_points, trait_variation_points)\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Max Trait Variation Points: {max_trait_variation_points}\")\n",
    "            \n",
    "        return max_trait_variation_points\n",
    "\n",
    "\n",
    "        \n",
    "    def score(self, verbose=False):\n",
    "        NUM_CATEGORIES = 6\n",
    "\n",
    "        TRAIT = 0\n",
    "        SPECIES = 1\n",
    "        EXPERIMENT = 2\n",
    "        INTERACTION = 3\n",
    "        NOT_TOPIC = 4\n",
    "        TRAIT_VARIATION = 5\n",
    "\n",
    "        # Max # of Points of Category per Sentence (MPC)\n",
    "        # A category can collect points from each sentence. However,\n",
    "        # there's a maximum number of points it can collect. This is\n",
    "        # determined by the MPC.\n",
    "        MPC = [1] * NUM_CATEGORIES\n",
    "    \n",
    "        # Points per Instance of Category (PIC)\n",
    "        # Each token is evaluated to check whether a category\n",
    "        # can be given points. The number of points given, if\n",
    "        # the token is determined to be satisfactory, is the PIC.\n",
    "        # The PIC is less than or equal to the MPC for the corresponding\n",
    "        # category. The idea behind the PIC and MPC is similar to how\n",
    "        # sets work in tennis: you're not immediately awarded the full points\n",
    "        # for the set (MPC) if your opponent fails to return the ball,\n",
    "        # instead you're given a smaller # of points (PIC) that allow you to\n",
    "        # incrementally win the set (category).\n",
    "        PIC = [0] * NUM_CATEGORIES\n",
    "        PIC[TRAIT] = MPC[TRAIT]*1.0\n",
    "        PIC[SPECIES] = MPC[SPECIES]/3.0\n",
    "        PIC[EXPERIMENT] = MPC[EXPERIMENT]*0.625\n",
    "        PIC[INTERACTION] = MPC[INTERACTION]/3.0\n",
    "        PIC[NOT_TOPIC] = MPC[NOT_TOPIC]*1.0\n",
    "\n",
    "        for i in range(NUM_CATEGORIES):\n",
    "            assert 0 <= PIC[i] <= MPC[i]\n",
    "\n",
    "        # Category Weights (CW)\n",
    "        # It may be helpful to weigh a certain category's fraction of total points\n",
    "        # more or less than another's. Thus, at the end, we'll take a\n",
    "        # weighted average of the category's FTP. The weights must add up to 1.\n",
    "        CW = [0] * NUM_CATEGORIES\n",
    "        CW[TRAIT] = 0.3\n",
    "        CW[SPECIES] = 0.1\n",
    "        CW[EXPERIMENT] = 0.1\n",
    "        CW[INTERACTION] = 0.1\n",
    "        CW[NOT_TOPIC] = 0.1\n",
    "        CW[TRAIT_VARIATION] = 0.3\n",
    "\n",
    "        assert round(np.sum(CW)) == 1\n",
    "\n",
    "        # Leniency\n",
    "        # There are certain categories that aren't going to be as frequent as others.\n",
    "        # For example, the trait category. You could try and decrease the influence\n",
    "        # of said category by lowering its MPC and/or increasing the PIC (so that it's\n",
    "        # easier to achieve the FTP). However, this could make it harder to meaningfully\n",
    "        # represent the category. The idea of leniency is to remove (some) sentences that had 0\n",
    "        # points from the scoring. This increases the FTP as, for example, instead of comparing\n",
    "        # 0.5 points to a total of 2.5 points, you can compare 0.5 to 2.0 points, and so on.\n",
    "        # A leniency of 1 means that all sentences that received 0 points will be removed from\n",
    "        # the scoring. A leniency of 0 means that all the sentences are included in the scoring.\n",
    "        LEN = [0] * NUM_CATEGORIES\n",
    "        LEN[TRAIT] = 0\n",
    "        LEN[SPECIES] = 0\n",
    "        LEN[EXPERIMENT] = 0\n",
    "        LEN[INTERACTION] = 0\n",
    "        LEN[NOT_TOPIC] = 0\n",
    "        \n",
    "        # Points\n",
    "        points = [0] * NUM_CATEGORIES\n",
    "        num_zero_pt_sents = [0] * NUM_CATEGORIES\n",
    "        seen_species = {}\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(\"Extracted Information\")\n",
    "            print(f\"Cause Tokens: {self.cause.tokens}\")\n",
    "            print(f\"Change Tokens: {self.change.tokens}\")\n",
    "            print(f\"Trait Tokens: {self.trait.tokens}\")\n",
    "            print(f\"Species Tokens: {self.species.tokens}\")\n",
    "            print(f\"Experiment Tokens: {self.experiment.tokens}\")\n",
    "            print(f\"Not-Experiment Tokens: {self.not_experiment.tokens}\")\n",
    "            print(f\"Not-Topic Tokens: {self.not_topic.tokens}\")\n",
    "            print(f\"Variability Tokens: {self.variability.tokens}\")\n",
    "            print(f\"Test Tokens: {self.test.tokens}\")\n",
    "            \n",
    "        for sent in self.sp_doc.sents:\n",
    "            # Current Points in Sentence\n",
    "            curr_points = [0] * NUM_CATEGORIES\n",
    "\n",
    "            # Sentence Local Info\n",
    "            sent_tokens = [token for token in sent]\n",
    "            sent_cause_tokens = set(sent_tokens).intersection(self.cause.tokens)\n",
    "            sent_change_tokens = set(sent_tokens).intersection(self.change.tokens)\n",
    "            sent_seen_species = []\n",
    "            sent_num_unique_species = 0\n",
    "\n",
    "            if verbose and VERBOSE_LEVEL >= 2:\n",
    "                print(f\"\\tSentence: {sent}\")\n",
    "                print(f\"\\tSentence Cause Tokens: {sent_cause_tokens}\")\n",
    "                print(f\"\\tSentence Change Tokens: {sent_change_tokens}\")\n",
    "\n",
    "            \n",
    "            for token in sent_tokens:\n",
    "                # If each category has reached their maximum number of points,\n",
    "                # we can end the loop early.\n",
    "                all_maxed = True\n",
    "                for i in range(NUM_CATEGORIES):\n",
    "                    if i == TRAIT_VARIATION:\n",
    "                        continue\n",
    "                    if curr_points[i] < MPC[i]:\n",
    "                        all_maxed = False\n",
    "\n",
    "                if all_maxed:\n",
    "                    break\n",
    "\n",
    "                if verbose and VERBOSE_LEVEL >= 3:\n",
    "                    print(f\"\\t\\tToken in Sentence: {token}\")\n",
    "                \n",
    "                # Not Topic Points\n",
    "                if curr_points[NOT_TOPIC] < MPC[NOT_TOPIC]:\n",
    "                    if token in self.not_topic.tokens:\n",
    "                        curr_points[NOT_TOPIC] += PIC[NOT_TOPIC]\n",
    "\n",
    "                        if verbose and VERBOSE_LEVEL >= 3:\n",
    "                            print(f\"\\t\\t+ Points for Not-Topic\")\n",
    "\n",
    "                        \n",
    "                # Trait Points\n",
    "                if curr_points[TRAIT] < MPC[TRAIT]:\n",
    "                    if token in self.trait.tokens:\n",
    "                        scale = self.valid_trait_token(token, sent_cause_tokens, sent_change_tokens, verbose=verbose)\n",
    "                        curr_points[TRAIT] += scale * PIC[TRAIT]\n",
    "\n",
    "                        if verbose and VERBOSE_LEVEL >= 3 and scale:\n",
    "                            print(f\"\\t\\t+ Points for Trait\")\n",
    "\n",
    "                        \n",
    "                # Not Experiment Points\n",
    "                if token in self.not_experiment.tokens:\n",
    "                    curr_points[EXPERIMENT] -= 2 * PIC[EXPERIMENT]\n",
    "\n",
    "                    if verbose and VERBOSE_LEVEL >= 3:\n",
    "                        print(f\"\\t\\t- Points for Experiment\")\n",
    "\n",
    "                \n",
    "                # Experiment Points\n",
    "                elif curr_points[EXPERIMENT] < MPC[EXPERIMENT]:\n",
    "                    if token in self.experiment.tokens:\n",
    "                        curr_points[EXPERIMENT] += PIC[EXPERIMENT]\n",
    "\n",
    "                        if verbose and VERBOSE_LEVEL >= 3:\n",
    "                            print(f\"\\t\\t+ Points for Experiment\")\n",
    "\n",
    "                        \n",
    "                # Species and/or Interaction Points\n",
    "                if token in self.species.span_starts:\n",
    "                    # Update Species\n",
    "                    seen_species, sent_seen_species, seen_in_sent, sent_num_unique_species = self.update_seen_species(\n",
    "                        token, \n",
    "                        seen_species, \n",
    "                        sent_seen_species, \n",
    "                        sent_num_unique_species,\n",
    "                        verbose=verbose\n",
    "                    )\n",
    "                    \n",
    "                    if seen_in_sent:\n",
    "                        if verbose and VERBOSE_LEVEL >= 3:\n",
    "                            print(f\"\\t\\tAlready Seen Species '{token}' in Sentence\")\n",
    "                        continue\n",
    "\n",
    "                    \n",
    "                    # Interaction Points\n",
    "                    if curr_points[INTERACTION] < MPC[INTERACTION]:\n",
    "                        if sent_num_unique_species == 2:\n",
    "                            curr_points[INTERACTION] = 2.0 * PIC[INTERACTION]\n",
    "\n",
    "                            if verbose and VERBOSE_LEVEL >= 3:\n",
    "                                print(f\"\\t\\t+ Points for Interaction\")\n",
    "                            \n",
    "                        elif sent_num_unique_species > 2:\n",
    "                            curr_points[INTERACTION] += PIC[INTERACTION]\n",
    "\n",
    "                            if verbose and VERBOSE_LEVEL >= 3:\n",
    "                                print(f\"\\t\\t+ Points for Interaction\")\n",
    "\n",
    "\n",
    "                    # Species Points\n",
    "                    if curr_points[SPECIES] < MPC[SPECIES]:\n",
    "                        scale = self.valid_species_token(token, sent_cause_tokens, sent_change_tokens)\n",
    "                        curr_points[SPECIES] += scale * PIC[SPECIES]\n",
    "\n",
    "                        if verbose and VERBOSE_LEVEL >= 3 and scale:\n",
    "                            print(f\"\\t\\t+ Points for Species\")\n",
    "\n",
    "            \n",
    "            # Add Sentence Points to Total Points\n",
    "            for i in range(NUM_CATEGORIES):\n",
    "                if curr_points[i] <= 0:\n",
    "                    num_zero_pt_sents[i] += 1\n",
    "                points[i] += max(0, min(curr_points[i], MPC[i]))\n",
    "\n",
    "        \n",
    "        # Trait Variation Points\n",
    "        points[TRAIT_VARIATION] = self.valid_trait_variation(verbose=verbose)\n",
    "\n",
    "        \n",
    "        # Calculating Score            \n",
    "        NUM_SENTENCES = len(list(self.sp_doc.sents))\n",
    "        score = 0\n",
    "        \n",
    "        for i in range(NUM_CATEGORIES):\n",
    "            if i != TRAIT_VARIATION:\n",
    "                num_non_zero_pt_sents = NUM_SENTENCES - num_zero_pt_sents[i]\n",
    "                lenient_num_sentences = max(num_non_zero_pt_sents, (1 - LEN[i]) * NUM_SENTENCES)\n",
    "    \n",
    "                # Calculating FTP\n",
    "                points[i] = points[i] / (MPC[i] * lenient_num_sentences)\n",
    "    \n",
    "                # Take the Inverse for Not-Topic\n",
    "                if i == NOT_TOPIC:\n",
    "                    points[i] = 1 - points[i]\n",
    "    \n",
    "            # Add onto Score\n",
    "            score += max(0, min(points[i], 1)) * CW[i]\n",
    "\n",
    "        # Enforcing 3 or More Species            \n",
    "        if len(seen_species) < 3:\n",
    "            return 0, points\n",
    "            \n",
    "        assert 0.0 <= score <= 1.0\n",
    "\n",
    "        if verbose and VERBOSE_LEVEL >= 1:\n",
    "            print(f\"Score, Points: {score}, {points}\")\n",
    "    \n",
    "        return score, points"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "dfb67900-25f1-4d1a-b51f-74d5782b459b",
   "metadata": {},
   "outputs": [],
   "source": [
    "def score_dataset(name, save_output=False, version=\"\"):\n",
    "    # Redirect Print Statements\n",
    "    # https://stackoverflow.com/questions/7152762/how-to-redirect-print-output-to-a-file\n",
    "    if save_output:\n",
    "        initial_stdout = sys.stdout\n",
    "        f = open(f'./Print{name}{\"\" if not version else f\"-{version}\"}.txt', 'w')\n",
    "        sys.stdout = f\n",
    "        sys.stdout.reconfigure(encoding='utf-8')\n",
    "\n",
    "    # Load Dataset\n",
    "    data = load_preprocessed_dataset(name)\n",
    "\n",
    "    # We'll be running the points algorithm\n",
    "    # on the abstracts of these papers.\n",
    "    texts = list(data['Abstract'].to_numpy())\n",
    "    \n",
    "    # The scores for each paper will be stored here,\n",
    "    # we'll set this as a column of the dataframe.\n",
    "    scores = []\n",
    "    points = []\n",
    "    trait_points = []\n",
    "    species_points = []\n",
    "    experiment_points = []\n",
    "    interaction_points = []\n",
    "    neg_topic_points = []\n",
    "    trait_var_points = []\n",
    "    \n",
    "    # Scan and Evaluate Documents\n",
    "    main = Main()\n",
    "    for i, doc in enumerate(main.sp_nlp.pipe(texts)):\n",
    "        print(f\"{i+1}/{data.shape[0]} - {data.iloc[i]['Title']}\\n\")\n",
    "        main.update_doc(doc, verbose=save_output)\n",
    "\n",
    "        # Empty string literals cause errors, so it's\n",
    "        # being handled here.\n",
    "        if not main.sp_doc or not main.species.tn_doc:\n",
    "            scores.append(0)\n",
    "        else:\n",
    "            score, _points = main.score(verbose=save_output)\n",
    "            scores.append(score)\n",
    "            points.append(_points)\n",
    "            trait_points.append(_points[0])\n",
    "            species_points.append(_points[1])\n",
    "            experiment_points.append(_points[2])\n",
    "            interaction_points.append(_points[3])\n",
    "            neg_topic_points.append(_points[4])\n",
    "            trait_var_points.append(_points[5])\n",
    "\n",
    "        if not save_output:\n",
    "            clear_output(wait=True)\n",
    "\n",
    "    # Reset Standard Output\n",
    "    if save_output:\n",
    "        sys.stdout = initial_stdout\n",
    "        f.close()\n",
    "\n",
    "    data[\"Score\"] = scores\n",
    "    data[\"Trait Points\"] = trait_points\n",
    "    data[\"Species Points\"] = species_points\n",
    "    data[\"Experiment Points\"] = experiment_points\n",
    "    data[\"Interaction Points\"] = interaction_points\n",
    "    data[\"Negative Topic Points\"] = neg_topic_points\n",
    "    data[\"Trait Variation Points\"] = trait_var_points\n",
    "    data.sort_values(by='Score', ascending=False, inplace=True)\n",
    "    \n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "7571bf1c-4aba-4cf5-bf6f-b0e507f03af4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4/4 - Multiple predator effects result in risk reduction for prey across multiple prey densities\n",
      "\n"
     ]
    }
   ],
   "source": [
    "scored_data = score_dataset(\"Baseline-1\", save_output=False, version='')\n",
    "store_scored_dataset(scored_data, \"Baseline-3.1\", version='3')\n",
    "\n",
    "scored_data = score_dataset(\"Examples\", save_output=False, version='')\n",
    "store_scored_dataset(scored_data, \"Examples-3.1\", version='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4de511ab-cd2d-4763-abfc-64c8cef39699",
   "metadata": {},
   "outputs": [],
   "source": [
    "scored_data = score_dataset(\"DFiltered\", save_output=False, version='')\n",
    "store_scored_dataset(scored_data, \"DFiltered-3.1\", version='3')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "42259b57-e700-46ef-b881-b09bcc2b51c1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data Shape: (28, 4)\n"
     ]
    }
   ],
   "source": [
    "data = load_preprocessed_dataset(\"Baseline-1\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "62297597-793a-4e32-a9be-c7278975ceb4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Title</th>\n",
       "      <th>Abstract</th>\n",
       "      <th>DOI</th>\n",
       "      <th>Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>23</th>\n",
       "      <td>Impact of intraspecific and intraguild predati...</td>\n",
       "      <td>Exotic predators are more likely to replace re...</td>\n",
       "      <td>NaN</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                                Title  \\\n",
       "23  Impact of intraspecific and intraguild predati...   \n",
       "\n",
       "                                             Abstract  DOI  Score  \n",
       "23  Exotic predators are more likely to replace re...  NaN      0  "
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data.loc[data['Title'].str.contains('Impact of')]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d99fb0b2-68ef-4284-90d6-661555849208",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Title: Impact of intraspecific and intraguild predation on predator invasion and coexistence. Can exotic ladybeetles displace native species\n",
      "Abstract: Exotic predators are more likely to replace related native species when these species not only compete for similar prey species, but also predate on the offspring of the native predators. In several groups of arthropods, however, this intraguild predation (IGP) is not only mutual, but also co-occurs with intraspecific predation (ISP or cannibalism). These different processes may have counteracting effects on species invasion and coexistence. In this study, we derived simple rules that describe under which combinations of IGP and ISP a predator species is able to invade into a stable predator-prey system, and under which conditions an invasion will results in displacement or in coexistence. This theory is then applied to species pairs of exotic and native lady beetles, to test if differences in IGP and ISP may play a role in the establishment of introduced exotic ladybeetles species (Coleoptera: Coccinellidae) such as Harmonia axyridis in Europe and Coccinella septempunctata in North America. For an accurate estimation of the key processes we cannot rely on specific experimental data only, but take allometric relationships into account as well. For ladybeetles, IGP and ISP seem to be determined largely by size differences of the interacting larvae, thereby giving an overall advantage to the larger species. On the other hand, larger species generally have higher food requirements, which may give them a disadvantage in resource competition. The estimated levels of IGP, ISP and competitive ability of the interacting species can not fully explain the invasion by the two exotic ladybeetles species. _________________ Impact of Intraspecific and Intraguild Predation on Predator Invasion and Coexistence Second International Symposium on Biological Control of Arthropods 39 INTRODUCTION In recent years the invasive nature of two ladybeetles (Coleoptera: Coccinellidae) has drawn considerable attention in the scientific literature. The originally Eurasian Coccinella septempunctata L. established and spread through the whole of North-America in the 70s and 80s (Alyokhin and Sewell 2004; Elliott et al. 1996). Later, in the mid 90s, the originally Asian Harmonia axyridis (Pallas) became established in various parts of North-America and more recently in some parts of Western Europe as well (Adriaens et al. 2003). Simultaneous with their establishment in new habitats a population decline of native species was observed. The establishment of C. septempunctata in arable fields in North America was followed by a dramatic decline of several native ladybeetles (including Adalia bipunctata L.) in these fields (Alyokhin and Sewell 2004; Elliott et al. 1996; Evans 2004; Wheeler and Hoebeke 1995). C. septempunctata also became the dominant ladybeetle species in apple orchards, pushing A. bipunctata to a second position (Brown 2003; Brown and Miller 1998). The later establishment of H. axyridis in orchards resulted in a local decline of especially this other exotic C. septempunctata (Brown 2003), but this pattern is not yet apparent in arable fields (Nault and Kennedy 2003). In none of the cases the exotic species has resulted in the exclusion of native species. Resource competition for aphid prey is a possible explanation for the decline in native species following the establishment of the exotic one (Evans 2004). However, no evidence is yet provided that the exotic species are better resource competitors than the native ones. Intraguild predation (IGP) between the exotic and native ladybeetles is regarded as the most likely reason for the spread of the exotic species and the subsequent reduction of native or earlier-established species (Yasuda and Ohnuma 1999). Lab studies indeed show that the IGP by the exotic species on native species is generally bigger than the reverse predation (Snyder et al. 2004; Yasuda et al. 2004), and that IGP between the two exotic species is in favour of H. axyridis (Yasuda and Ohnuma 1999). A complicating factor is that these predators not only feed on the juveniles of other predator species, but also on those from their own species. This cannibalism or Intraspecific Predation (ISP) may partly reduce the effect of IGP on population dominance. In this study we therefore start with reviewing the theory on the combined impact of IGP and ISP on population dynamics. Then we show how the strength of the different interand intraspecific interaction may be calculated, and use these values to derive predictions on invasibility and species coexistence. In the second part we include resource competition in our theory. How will the various coccinelids differ in competitive ability, and how will this alter our conclusions. Finally, we will discuss the realism of our simplifying assumptions, indicate how spatial and temporal avoidance, resource partitioning and metapopulation dynamics may affect our conclusions.\n"
     ]
    }
   ],
   "source": [
    "index = 23\n",
    "\n",
    "title = data.iloc[index].Title\n",
    "abstract = data.iloc[index].Abstract\n",
    "\n",
    "print(f\"Title: {title}\")\n",
    "print(f\"Abstract: {abstract}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "96e08770-f7fe-4ea8-bf90-a627965ea078",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "06/30/2025 21:43:38 - INFO - \t missing_keys: []\n",
      "06/30/2025 21:43:38 - INFO - \t unexpected_keys: []\n",
      "06/30/2025 21:43:38 - INFO - \t mismatched_keys: []\n",
      "06/30/2025 21:43:38 - INFO - \t error_msgs: []\n",
      "06/30/2025 21:43:38 - INFO - \t Model Parameters: 90.5M, Transformer: 82.1M, Coref head: 8.4M\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\t'behaviou?r' Regex Matches: []\n",
      "\t'[^A-Za-z]+rate' Regex Matches: []\n",
      "\t'colou?r' Regex Matches: []\n",
      "\t'biomass' Regex Matches: []\n",
      "\t'[^A-Za-z]+mass' Regex Matches: []\n",
      "\t'[^A-Za-z]+size' Regex Matches: [(1223, 1228)]\n",
      "\t\tSpan Matched: size\n",
      "\t\tPossible Regex Match for Token 'size' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'size'\n",
      "\t'number' Regex Matches: []\n",
      "\t'length' Regex Matches: []\n",
      "\t'pattern' Regex Matches: [(3032, 3039)]\n",
      "\t\tSpan Matched: pattern\n",
      "\t\tPossible Regex Match for Token 'pattern' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'pattern'\n",
      "\t'weight' Regex Matches: []\n",
      "\t'shape' Regex Matches: []\n",
      "\t'efficiency' Regex Matches: []\n",
      "\t'trait' Regex Matches: []\n",
      "\t'phenotype' Regex Matches: []\n",
      "\t'demography' Regex Matches: []\n",
      "\t'scent' Regex Matches: []\n",
      "\t'population (structure|mechanic)s?' Regex Matches: []\n",
      "\t'ability' Regex Matches: [(1511, 1518), (4651, 4658)]\n",
      "\t\tSpan Matched: ability\n",
      "\t\tPossible Regex Match for Token 'ability' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'ability'\n",
      "\t\tSpan Matched: ability\n",
      "\t\tPossible Regex Match for Token 'ability' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'ability'\n",
      "\t'capacity' Regex Matches: []\n",
      "\t'height' Regex Matches: []\n",
      "\t'width' Regex Matches: []\n",
      "\t'[A-Za-z]+span' Regex Matches: []\n",
      "\t'diet' Regex Matches: []\n",
      "\t'food' Regex Matches: [(1383, 1387)]\n",
      "\t\tSpan Matched: food\n",
      "\t\tPossible Regex Match for Token 'food' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'food'\n",
      "\t'feeding' Regex Matches: []\n",
      "\t'nest' Regex Matches: []\n",
      "\t'substrate' Regex Matches: []\n",
      "\t'breeding' Regex Matches: []\n",
      "\t'[^A-Za-z]+age[^A-Za-z]+' Regex Matches: []\n",
      "\t'lifespan' Regex Matches: []\n",
      "\t'development' Regex Matches: []\n",
      "\t'output' Regex Matches: []\n",
      "\t'time' Regex Matches: []\n",
      "\t'periodlevel' Regex Matches: []\n",
      "\t'configuration' Regex Matches: []\n",
      "\t'dimorphism' Regex Matches: []\n",
      "\t'capability' Regex Matches: []\n",
      "\t'regulation' Regex Matches: []\n",
      "\t'excretion' Regex Matches: []\n",
      "\t'luminescence' Regex Matches: []\n",
      "\t'[^A-Za-z]+role' Regex Matches: [(827, 832)]\n",
      "\t\tSpan Matched: role\n",
      "\t\tPossible Regex Match for Token 'role' (Position: NOUN and Tag: NN)\n",
      "\t\tRegex Matched Token 'role'\n",
      "\t'sensitivity' Regex Matches: []\n",
      "\t'resistance' Regex Matches: []\n",
      "\t'(un|(^|\\s)[A-Za-z]*-)infected' Regex Matches: []\n",
      "\t'temperature' Regex Matches: []\n",
      "\t'density' Regex Matches: []\n",
      "\tRule Matches: []\n",
      "\t\tPossible Vocab Match for Token 'Exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predators' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'are' (Position: AUX and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'more' (Position: ADV and Tag: RBR)\n",
      "\t\tPossible Vocab Match for Token 'likely' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: PART and Tag: TO)\n",
      "\t\tPossible Vocab Match for Token 'replace' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'related' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'when' (Position: SCONJ and Tag: WRB)\n",
      "\t\tPossible Vocab Match for Token 'these' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'only' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'compete' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'for' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'similar' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'prey' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'but' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'also' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'predate' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'offspring' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predators' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'several' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'groups' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'arthropods' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'however' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'intraguild' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'predation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'only' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'mutual' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'but' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'also' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'co' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token '-' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'occurs' (Position: VERB and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'with' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'intraspecific' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'or' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'cannibalism' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'These' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'different' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'processes' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'have' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'counteracting' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'effects' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'invasion' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'coexistence' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'study' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'derived' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'simple' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'rules' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'that' (Position: PRON and Tag: WDT)\n",
      "\t\tPossible Vocab Match for Token 'describe' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'under' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'which' (Position: PRON and Tag: WDT)\n",
      "\t\tPossible Vocab Match for Token 'combinations' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'predator' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'able' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: PART and Tag: TO)\n",
      "\t\tPossible Vocab Match for Token 'invade' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'into' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'stable' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predator' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '-' (Position: PUNCT and Tag: HYPH)\n",
      "\t\tPossible Vocab Match for Token 'prey' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'system' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'under' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'which' (Position: DET and Tag: WDT)\n",
      "\t\tPossible Vocab Match for Token 'conditions' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'an' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'invasion' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'will' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'results' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'displacement' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'or' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'coexistence' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'This' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'theory' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'then' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'applied' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'pairs' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'lady' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'beetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: PART and Tag: TO)\n",
      "\t\tPossible Vocab Match for Token 'test' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'if' (Position: SCONJ and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'differences' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'play' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'role' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'establishment' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'introduced' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Coleoptera' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ':' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Coccinellidae' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'such' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'as' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Harmonia' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'axyridis' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Europe' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Coccinella' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'septempunctata' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'North' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'America' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'For' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'an' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'accurate' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'estimation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'key' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'processes' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'can' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'rely' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'specific' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'experimental' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'data' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'only' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'but' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'take' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'allometric' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'relationships' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'into' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'account' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'as' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'well' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'For' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'seem' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: PART and Tag: TO)\n",
      "\t\tPossible Vocab Match for Token 'be' (Position: AUX and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'determined' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'largely' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'by' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'size' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'differences' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'interacting' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'larvae' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'thereby' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'giving' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'an' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'overall' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'advantage' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'larger' (Position: ADJ and Tag: JJR)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'On' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'other' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'hand' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'larger' (Position: ADJ and Tag: JJR)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'generally' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'have' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'higher' (Position: ADJ and Tag: JJR)\n",
      "\t\tPossible Vocab Match for Token 'food' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'requirements' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'which' (Position: PRON and Tag: WDT)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'give' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'them' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'disadvantage' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'resource' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'competition' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'The' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'estimated' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'levels' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'competitive' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ability' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'interacting' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'can' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'fully' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'explain' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'invasion' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'by' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'two' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token '_' (Position: PUNCT and Tag: NFP)\n",
      "\t\tPossible Vocab Match for Token 'Impact' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Intraspecific' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Intraguild' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Predation' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Predator' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Invasion' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Coexistence' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Second' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'International' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Symposium' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Biological' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Control' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Arthropods' (Position: PROPN and Tag: NNPS)\n",
      "\t\tPossible Vocab Match for Token '39' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token 'INTRODUCTION' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'recent' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'years' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'invasive' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'nature' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'two' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Coleoptera' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ':' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Coccinellidae' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'has' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'drawn' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'considerable' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'attention' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'scientific' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'literature' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'The' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'originally' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'Eurasian' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'Coccinella' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'septempunctata' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'L.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'established' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'spread' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'through' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'whole' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'North' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '-' (Position: PUNCT and Tag: HYPH)\n",
      "\t\tPossible Vocab Match for Token 'America' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token '70s' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token '80s' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Alyokhin' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Sewell' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Elliott' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'et' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'al' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1996' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Later' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'mid' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token '90s' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'originally' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'Asian' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Harmonia' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'axyridis' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Pallas' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'became' (Position: AUX and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'established' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'various' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'parts' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'North' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '-' (Position: PUNCT and Tag: HYPH)\n",
      "\t\tPossible Vocab Match for Token 'America' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'more' (Position: ADV and Tag: RBR)\n",
      "\t\tPossible Vocab Match for Token 'recently' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'some' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'parts' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'Western' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Europe' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'as' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'well' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Adriaens' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'et' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'al' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2003' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Simultaneous' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'with' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'their' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'establishment' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'new' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'habitats' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'population' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'decline' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'was' (Position: AUX and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'observed' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'The' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'establishment' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'C.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'septempunctata' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'arable' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'fields' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'North' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'America' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'was' (Position: AUX and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'followed' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'by' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'dramatic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'decline' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'several' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'including' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'Adalia' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'bipunctata' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'L.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'these' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'fields' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Alyokhin' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Sewell' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Elliott' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'et' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'al' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1996' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Evans' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Wheeler' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Hoebeke' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1995' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'C.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'septempunctata' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'also' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'became' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'dominant' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetle' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'apple' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'orchards' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'pushing' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'A.' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'bipunctata' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'second' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'position' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Brown' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2003' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Brown' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Miller' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1998' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'The' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'later' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'establishment' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'H.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'axyridis' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'orchards' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'resulted' (Position: VERB and Tag: VBD)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'local' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'decline' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'especially' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'other' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'C.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'septempunctata' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Brown' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2003' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'but' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'pattern' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'yet' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'apparent' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'arable' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'fields' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Nault' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Kennedy' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2003' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'none' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'cases' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'has' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'resulted' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exclusion' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Resource' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'competition' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'for' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'aphid' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'prey' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'a' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'possible' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'explanation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'for' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'decline' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'following' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'establishment' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'one' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Evans' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'However' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'no' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'evidence' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'yet' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'provided' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'that' (Position: SCONJ and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'are' (Position: AUX and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'better' (Position: ADJ and Tag: JJR)\n",
      "\t\tPossible Vocab Match for Token 'resource' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'competitors' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'than' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ones' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Intraguild' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'predation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'between' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ladybeetles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'regarded' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'as' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'most' (Position: ADV and Tag: RBS)\n",
      "\t\tPossible Vocab Match for Token 'likely' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'reason' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'for' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'spread' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'subsequent' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'reduction' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'or' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'earlier' (Position: ADV and Tag: RBR)\n",
      "\t\tPossible Vocab Match for Token '-' (Position: PUNCT and Tag: HYPH)\n",
      "\t\tPossible Vocab Match for Token 'established' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Yasuda' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Ohnuma' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1999' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Lab' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'studies' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'indeed' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'show' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'that' (Position: SCONJ and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'by' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'native' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'generally' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'bigger' (Position: ADJ and Tag: JJR)\n",
      "\t\tPossible Vocab Match for Token 'than' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'reverse' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Snyder' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'et' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'al' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ';' (Position: PUNCT and Tag: :)\n",
      "\t\tPossible Vocab Match for Token 'Yasuda' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'et' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'al' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '2004' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'that' (Position: SCONJ and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'between' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'two' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token 'exotic' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'favour' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'H.' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'axyridis' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'Yasuda' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Ohnuma' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '1999' (Position: NUM and Tag: CD)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'A' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'complicating' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'factor' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'is' (Position: AUX and Tag: VBZ)\n",
      "\t\tPossible Vocab Match for Token 'that' (Position: SCONJ and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'these' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'predators' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'not' (Position: PART and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'only' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'feed' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'juveniles' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'other' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'predator' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'but' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'also' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'those' (Position: PRON and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'from' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'their' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'own' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'This' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'cannibalism' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'or' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'Intraspecific' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'Predation' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token '(' (Position: PUNCT and Tag: -LRB-)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ')' (Position: PUNCT and Tag: -RRB-)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'partly' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'reduce' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'effect' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'population' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'dominance' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'study' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'therefore' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'start' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'with' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'reviewing' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'theory' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'combined' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token 'impact' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'IGP' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'ISP' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'population' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'dynamics' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Then' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'show' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'how' (Position: SCONJ and Tag: WRB)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'strength' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'different' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'interand' (Position: PROPN and Tag: NNP)\n",
      "\t\tPossible Vocab Match for Token 'intraspecific' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'interaction' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'be' (Position: AUX and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'calculated' (Position: VERB and Tag: VBN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'use' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'these' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'values' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'to' (Position: PART and Tag: TO)\n",
      "\t\tPossible Vocab Match for Token 'derive' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'predictions' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'on' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'invasibility' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'species' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'coexistence' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'In' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'second' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'part' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'include' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'resource' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'competition' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'our' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'theory' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'How' (Position: SCONJ and Tag: WRB)\n",
      "\t\tPossible Vocab Match for Token 'will' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'various' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'coccinelids' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'differ' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'in' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'competitive' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'ability' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'how' (Position: SCONJ and Tag: WRB)\n",
      "\t\tPossible Vocab Match for Token 'will' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'this' (Position: PRON and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'alter' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'our' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'conclusions' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "\t\tPossible Vocab Match for Token 'Finally' (Position: ADV and Tag: RB)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'we' (Position: PRON and Tag: PRP)\n",
      "\t\tPossible Vocab Match for Token 'will' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'discuss' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'the' (Position: DET and Tag: DT)\n",
      "\t\tPossible Vocab Match for Token 'realism' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'of' (Position: ADP and Tag: IN)\n",
      "\t\tPossible Vocab Match for Token 'our' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'simplifying' (Position: VERB and Tag: VBG)\n",
      "\t\tPossible Vocab Match for Token 'assumptions' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'indicate' (Position: VERB and Tag: VBP)\n",
      "\t\tPossible Vocab Match for Token 'how' (Position: SCONJ and Tag: WRB)\n",
      "\t\tPossible Vocab Match for Token 'spatial' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'temporal' (Position: ADJ and Tag: JJ)\n",
      "\t\tPossible Vocab Match for Token 'avoidance' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token ',' (Position: PUNCT and Tag: ,)\n",
      "\t\tPossible Vocab Match for Token 'resource' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'partitioning' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'and' (Position: CCONJ and Tag: CC)\n",
      "\t\tPossible Vocab Match for Token 'metapopulation' (Position: NOUN and Tag: NN)\n",
      "\t\tPossible Vocab Match for Token 'dynamics' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token 'may' (Position: AUX and Tag: MD)\n",
      "\t\tPossible Vocab Match for Token 'affect' (Position: VERB and Tag: VB)\n",
      "\t\tPossible Vocab Match for Token 'our' (Position: PRON and Tag: PRP$)\n",
      "\t\tPossible Vocab Match for Token 'conclusions' (Position: NOUN and Tag: NNS)\n",
      "\t\tPossible Vocab Match for Token '.' (Position: PUNCT and Tag: .)\n",
      "Output of match_tokens\n",
      "Token Data: [{'token': size, 'types': [], 'weight': 1.0}, {'token': pattern, 'types': [], 'weight': 1.0}, {'token': ability, 'types': [], 'weight': 1.0}, {'token': ability, 'types': [], 'weight': 1.0}, {'token': food, 'types': ['Food', 'N/A'], 'weight': 1.0}, {'token': role, 'types': [], 'weight': 1.0}]\n",
      "Mapped Token Data: {size: {'token': size, 'types': [], 'weight': 1.0}, pattern: {'token': pattern, 'types': [], 'weight': 1.0}, ability: {'token': ability, 'types': [], 'weight': 1.0}, ability: {'token': ability, 'types': [], 'weight': 1.0}, food: {'token': food, 'types': ['Food', 'N/A'], 'weight': 1.0}, role: {'token': role, 'types': [], 'weight': 1.0}}\n",
      "Token: [size, pattern, ability, ability, food, role]\n",
      "Unfiltered Trait Tokens: [size, pattern, ability, ability, food, role]\n",
      "Expanded Unit of 'size': IGP and ISP seem to be determined largely by size differences of the interacting larvae\n",
      "\tToken 'larvae' is Species\n",
      "Expanded Unit of 'pattern': but this pattern is not yet apparent in arable fields\n",
      "Expanded Unit of 'ability': ISP and competitive ability of the interacting species can not fully explain the invasion by the two exotic ladybeetles species\n",
      "\tToken 'species' is Species\n",
      "Expanded Unit of 'ability': How will the various coccinelids differ in competitive ability\n",
      "Expanded Unit of 'food': larger species generally have higher food requirements\n",
      "\tToken 'larger' is Species\n",
      "Expanded Unit of 'role': to test if differences in IGP and ISP may play a role in the establishment of introduced exotic ladybeetles species\n",
      "\tToken 'exotic' is Species\n",
      "Filtered Trait Tokens: [size, ability, food, role]\n",
      "Extracted Information\n",
      "Cause Tokens: [when, Impact, reduction, reduce, impact, alter, affect]\n",
      "Change Tokens: [more, larger, larger, higher, more, decline, decline, decline, decline, better, reduction, bigger]\n",
      "Trait Tokens: [size, ability, food, role]\n",
      "Species Tokens: [arthropods, Arthropods, Harmonia, axyridis, Harmonia, axyridis, H., H., related, native, species, species, species, species, species, species, species, larger, species, larger, species, species, species, native, species, species, exotic, species, native, species, native, species, exotic, species, exotic, species, species, exotic, species, native, species, exotic, species, species, own, species, species, Eurasian, Coccinella, septempunctata, L., Coleoptera, Coleoptera, Adalia, bipunctata, L., native, lady, beetles, similar, prey, prey, prey, C., septempunctata, C., septempunctata, other, exotic, C., septempunctata, dominant, ladybeetle, Coccinella, septempunctata, Exotic, predators, native, predators, predators, predator, stable, predator, Predator, other, predator, juveniles, Coccinellidae, Coccinellidae, A., exotic, ladybeetles, exotic, ladybeetles, Asian, axyridis, axyridis, ladybeetles, ladybeetles, several, native, ladybeetles, native, ladybeetles, larvae, bipunctata]\n",
      "Experiment Tokens: [study, results, theory, applied, test, experimental, data, considerable, observed, resulted, resulted, evidence, studies, show, study, theory, show, theory]\n",
      "Not-Experiment Tokens: [theory, reviewing, theory, theory]\n",
      "Not-Topic Tokens: []\n",
      "Variability Tokens: [between, between, effects, effect, Control, under, which, combinations, of, IGP, and, ISP, a, predator, species, is, able, to, invade, into, a, stable, predator, -, prey, system, ,, and, under, similar, different, differences, specific, differences, other, various, other, other, different, various, differ]\n",
      "Test Tokens: []\n",
      "\tSentence: Exotic predators are more likely to replace related native species when these species not only compete for similar prey species, but also predate on the offspring of the native predators.\n",
      "\tSentence Cause Tokens: {when}\n",
      "\tSentence Change Tokens: {more}\n",
      "\t\tToken in Sentence: Exotic\n",
      "No Matches Between dict_keys([]) and Exotic predators\n",
      "No Matches Between [] and Exotic predators\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: predators\n",
      "\t\tToken in Sentence: are\n",
      "\t\tToken in Sentence: more\n",
      "\t\tToken in Sentence: likely\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: replace\n",
      "\t\tToken in Sentence: related\n",
      "No Matches Between dict_keys([Exotic predators]) and related native species\n",
      "No Matches Between [Exotic predators] and related native species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: native\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: when\n",
      "\t\tToken in Sentence: these\n",
      "\t\tToken in Sentence: species\n",
      "No Matches Between dict_keys([Exotic predators, related native species]) and species\n",
      "No Matches Between [Exotic predators, related native species] and species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: only\n",
      "\t\tToken in Sentence: compete\n",
      "\t\tToken in Sentence: for\n",
      "\t\tToken in Sentence: similar\n",
      "Method 2: Match Between 'species' and 'similar prey'\n",
      "Method 2: Match Between 'species' and 'similar prey'\n",
      "\t\tAlready Seen Species 'similar' in Sentence\n",
      "\t\tToken in Sentence: prey\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: but\n",
      "\t\tToken in Sentence: also\n",
      "\t\tToken in Sentence: predate\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: offspring\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: native\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species]) and native predators\n",
      "No Matches Between [Exotic predators, related native species, species, similar prey, species] and native predators\n",
      "\t\tToken in Sentence: predators\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: In several groups of arthropods, however, this intraguild predation (IGP) is not only mutual, but also co-occurs with intraspecific predation (ISP or cannibalism).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: several\n",
      "\t\tToken in Sentence: groups\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: arthropods\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators]) and arthropods\n",
      "No Matches Between [] and arthropods\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: however\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: intraguild\n",
      "\t\tToken in Sentence: predation\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: only\n",
      "\t\tToken in Sentence: mutual\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: but\n",
      "\t\tToken in Sentence: also\n",
      "\t\tToken in Sentence: co\n",
      "\t\tToken in Sentence: -\n",
      "\t\tToken in Sentence: occurs\n",
      "\t\tToken in Sentence: with\n",
      "\t\tToken in Sentence: intraspecific\n",
      "\t\tToken in Sentence: predation\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: or\n",
      "\t\tToken in Sentence: cannibalism\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: These different processes may have counteracting effects on species invasion and coexistence.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: These\n",
      "\t\tToken in Sentence: different\n",
      "\t\tToken in Sentence: processes\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: have\n",
      "\t\tToken in Sentence: counteracting\n",
      "\t\tToken in Sentence: effects\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "No Matches Between [] and species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: invasion\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: coexistence\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: In this study, we derived simple rules that describe under which combinations of IGP and ISP a predator species is able to invade into a stable predator-prey system, and under which conditions an invasion will results in displacement or in coexistence.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: study\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: derived\n",
      "\t\tToken in Sentence: simple\n",
      "\t\tToken in Sentence: rules\n",
      "\t\tToken in Sentence: that\n",
      "\t\tToken in Sentence: describe\n",
      "\t\tToken in Sentence: under\n",
      "\t\tToken in Sentence: which\n",
      "\t\tToken in Sentence: combinations\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: predator\n",
      "Method 2: Match Between 'species' and 'predator'\n",
      "No Matches Between [] and predator\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 2: Match Between 'predator' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: able\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: invade\n",
      "\t\tToken in Sentence: into\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: stable\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods]) and stable predator\n",
      "Method 3: Match Between 'predator' and 'stable predator'\n",
      "\t\tAlready Seen Species 'stable' in Sentence\n",
      "\t\tToken in Sentence: predator\n",
      "\t\tToken in Sentence: -\n",
      "\t\tToken in Sentence: prey\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator]) and prey\n",
      "No Matches Between [predator, species, stable predator] and prey\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: system\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: under\n",
      "\t\tToken in Sentence: which\n",
      "\t\tToken in Sentence: conditions\n",
      "\t\tToken in Sentence: an\n",
      "\t\tToken in Sentence: invasion\n",
      "\t\tToken in Sentence: will\n",
      "\t\tToken in Sentence: results\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: displacement\n",
      "\t\tToken in Sentence: or\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: coexistence\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: This theory is then applied to species pairs of exotic and native lady beetles, to test if differences in IGP and ISP may play a role in the establishment of introduced exotic ladybeetles species (Coleoptera: Coccinellidae) such as Harmonia axyridis in Europe and Coccinella septempunctata in North America.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: This\n",
      "\t\tToken in Sentence: theory\n",
      "\t\t- Points for Experiment\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: then\n",
      "\t\tToken in Sentence: applied\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "No Matches Between [] and species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: pairs\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: exotic\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: native\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey]) and native lady beetles\n",
      "No Matches Between [species] and native lady beetles\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: lady\n",
      "\t\tToken in Sentence: beetles\n",
      "Method 1: Match Between 'native lady beetles' and 'native lady beetles'\n",
      "Method 1: Match Between 'native lady beetles' and 'native lady beetles'\n",
      "\t\tAlready Seen Species 'beetles' in Sentence\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: test\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: if\n",
      "\t\tToken in Sentence: differences\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: play\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: role\n",
      "Token 'role' Types: []\n",
      "Unit Context of 'role': [ISP, may, play, a, role, in, the, establishment, of, introduced, exotic, ladybeetles, species, such, as, Harmonia, axyridis, in, Europe]\n",
      "\t\t+ Points for Trait\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: establishment\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: introduced\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 2: Match Between 'species' and 'exotic ladybeetles'\n",
      "Method 2: Match Between 'species' and 'exotic ladybeetles'\n",
      "\t\tAlready Seen Species 'exotic' in Sentence\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Coleoptera\n",
      "Method 2: Match Between 'species' and 'Coleoptera'\n",
      "Method 2: Match Between 'species' and 'Coleoptera'\n",
      "\t\tAlready Seen Species 'Coleoptera' in Sentence\n",
      "\t\tToken in Sentence: :\n",
      "\t\tToken in Sentence: Coccinellidae\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles]) and Coccinellidae\n",
      "Method 2: Match Between 'Coleoptera' and 'Coccinellidae'\n",
      "\t\tAlready Seen Species 'Coccinellidae' in Sentence\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: such\n",
      "\t\tToken in Sentence: as\n",
      "\t\tToken in Sentence: Harmonia\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae]) and Harmonia axyridis\n",
      "No Matches Between [species, native lady beetles, native lady beetles, exotic ladybeetles, species, Coleoptera, Coccinellidae] and Harmonia axyridis\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: axyridis\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: Europe\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Coccinella\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis]) and Coccinella septempunctata\n",
      "No Matches Between [species, native lady beetles, native lady beetles, exotic ladybeetles, species, Coleoptera, Coccinellidae, Harmonia axyridis] and Coccinella septempunctata\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: septempunctata\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: North\n",
      "\t\tToken in Sentence: America\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: For an accurate estimation of the key processes we cannot rely on specific experimental data only, but take allometric relationships into account as well.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: For\n",
      "\t\tToken in Sentence: an\n",
      "\t\tToken in Sentence: accurate\n",
      "\t\tToken in Sentence: estimation\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: key\n",
      "\t\tToken in Sentence: processes\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: can\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: rely\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: specific\n",
      "\t\tToken in Sentence: experimental\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: data\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: only\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: but\n",
      "\t\tToken in Sentence: take\n",
      "\t\tToken in Sentence: allometric\n",
      "\t\tToken in Sentence: relationships\n",
      "\t\tToken in Sentence: into\n",
      "\t\tToken in Sentence: account\n",
      "\t\tToken in Sentence: as\n",
      "\t\tToken in Sentence: well\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: For ladybeetles, IGP and ISP seem to be determined largely by size differences of the interacting larvae, thereby giving an overall advantage to the larger species.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {larger}\n",
      "\t\tToken in Sentence: For\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata]) and ladybeetles\n",
      "No Matches Between [] and ladybeetles\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: seem\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: be\n",
      "\t\tToken in Sentence: determined\n",
      "\t\tToken in Sentence: largely\n",
      "\t\tToken in Sentence: by\n",
      "\t\tToken in Sentence: size\n",
      "Token 'size' Types: []\n",
      "Unit Context of 'size': [ISP, seem, to, be, determined, largely, by, size, differences, of, the, interacting, larvae]\n",
      "\t\t+ Points for Trait\n",
      "\t\tToken in Sentence: differences\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: interacting\n",
      "\t\tToken in Sentence: larvae\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles]) and larvae\n",
      "No Matches Between [ladybeetles] and larvae\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: thereby\n",
      "\t\tToken in Sentence: giving\n",
      "\t\tToken in Sentence: an\n",
      "\t\tToken in Sentence: overall\n",
      "\t\tToken in Sentence: advantage\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: larger\n",
      "Method 3: Match Between 'species' and 'larger species'\n",
      "No Matches Between [ladybeetles, larvae] and larger species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: On the other hand, larger species generally have higher food requirements, which may give them a disadvantage in resource competition.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {higher, larger}\n",
      "\t\tToken in Sentence: On\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: other\n",
      "\t\tToken in Sentence: hand\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: larger\n",
      "Method 3: Match Between 'species' and 'larger species'\n",
      "No Matches Between [] and larger species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: generally\n",
      "\t\tToken in Sentence: have\n",
      "\t\tToken in Sentence: higher\n",
      "\t\tToken in Sentence: food\n",
      "Token 'food' Types: ['Food', 'N/A']\n",
      "\t\tToken in Sentence: requirements\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: which\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: give\n",
      "\t\tToken in Sentence: them\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: disadvantage\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: resource\n",
      "\t\tToken in Sentence: competition\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: The estimated levels of IGP, ISP and competitive ability of the interacting species can not fully explain the invasion by the two exotic ladybeetles species.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: The\n",
      "\t\tToken in Sentence: estimated\n",
      "\t\tToken in Sentence: levels\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: competitive\n",
      "\t\tToken in Sentence: ability\n",
      "Token 'ability' Types: []\n",
      "Unit Context of 'ability': [competitive, ability, of, the, interacting, species, can, not, fully, explain, the, invasion, by, the]\n",
      "\t\t+ Points for Trait\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: interacting\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "No Matches Between [] and species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: can\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: fully\n",
      "\t\tToken in Sentence: explain\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: invasion\n",
      "\t\tToken in Sentence: by\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: two\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 2: Match Between 'species' and 'exotic ladybeetles'\n",
      "Method 2: Match Between 'species' and 'exotic ladybeetles'\n",
      "\t\tAlready Seen Species 'exotic' in Sentence\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: _________________\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\t\tToken in Sentence: _\n",
      "\tSentence: Impact of Intraspecific and Intraguild Predation on Predator Invasion and Coexistence Second International Symposium on Biological Control of Arthropods 39 INTRODUCTION\n",
      "\tSentence Cause Tokens: {Impact}\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: Impact\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: Intraspecific\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Intraguild\n",
      "\t\tToken in Sentence: Predation\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: Predator\n",
      "Method 2: Match Between 'species' and 'Predator'\n",
      "No Matches Between [] and Predator\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: Invasion\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Coexistence\n",
      "\t\tToken in Sentence: Second\n",
      "\t\tToken in Sentence: International\n",
      "\t\tToken in Sentence: Symposium\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: Biological\n",
      "\t\tToken in Sentence: Control\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: Arthropods\n",
      "Method 1: Match Between 'arthropods' and 'Arthropods'\n",
      "No Matches Between [Predator] and Arthropods\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: 39\n",
      "\t\tToken in Sentence: INTRODUCTION\n",
      "\tSentence: In recent years the invasive nature of two ladybeetles (Coleoptera: Coccinellidae) has drawn considerable attention in the scientific literature.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: recent\n",
      "\t\tToken in Sentence: years\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: invasive\n",
      "\t\tToken in Sentence: nature\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: two\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "Method 1: Match Between 'ladybeetles' and 'ladybeetles'\n",
      "No Matches Between [] and ladybeetles\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Coleoptera\n",
      "Method 2: Match Between 'species' and 'Coleoptera'\n",
      "Method 2: Match Between 'ladybeetles' and 'Coleoptera'\n",
      "\t\tAlready Seen Species 'Coleoptera' in Sentence\n",
      "\t\tToken in Sentence: :\n",
      "\t\tToken in Sentence: Coccinellidae\n",
      "Method 1: Match Between 'Coccinellidae' and 'Coccinellidae'\n",
      "Method 2: Match Between 'Coleoptera' and 'Coccinellidae'\n",
      "\t\tAlready Seen Species 'Coccinellidae' in Sentence\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: has\n",
      "\t\tToken in Sentence: drawn\n",
      "\t\tToken in Sentence: considerable\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: attention\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: scientific\n",
      "\t\tToken in Sentence: literature\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: The originally Eurasian Coccinella septempunctata L. established and spread through the whole of North-America in the 70s and 80s (Alyokhin and Sewell 2004; Elliott et al. 1996).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: The\n",
      "\t\tToken in Sentence: originally\n",
      "\t\tToken in Sentence: Eurasian\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae]) and Eurasian Coccinella septempunctata L.\n",
      "No Matches Between [] and Eurasian Coccinella septempunctata L.\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: Coccinella\n",
      "\t\tToken in Sentence: septempunctata\n",
      "\t\tToken in Sentence: L.\n",
      "Method 1: Match Between 'Eurasian Coccinella septempunctata L.' and 'Eurasian Coccinella septempunctata L.'\n",
      "Method 1: Match Between 'Eurasian Coccinella septempunctata L.' and 'Eurasian Coccinella septempunctata L.'\n",
      "\t\tAlready Seen Species 'L.' in Sentence\n",
      "\t\tToken in Sentence: established\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: spread\n",
      "\t\tToken in Sentence: through\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: whole\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: North\n",
      "\t\tToken in Sentence: -\n",
      "\t\tToken in Sentence: America\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: 70s\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: 80s\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Alyokhin\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Sewell\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Elliott\n",
      "\t\tToken in Sentence: et\n",
      "\t\tToken in Sentence: al\n",
      "\t\tToken in Sentence: .\n",
      "\t\tToken in Sentence: 1996\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Later, in the mid 90s, the originally Asian Harmonia axyridis (Pallas) became established in various parts of North-America and more recently in some parts of Western Europe as well (Adriaens et al. 2003).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {more}\n",
      "\t\tToken in Sentence: Later\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: mid\n",
      "\t\tToken in Sentence: 90s\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: originally\n",
      "\t\tToken in Sentence: Asian\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L.]) and Asian Harmonia axyridis\n",
      "No Matches Between [] and Asian Harmonia axyridis\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: Harmonia\n",
      "Method 1: Match Between 'Harmonia axyridis' and 'Harmonia axyridis'\n",
      "No Matches Between [Asian Harmonia axyridis] and Harmonia axyridis\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: axyridis\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Pallas\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: became\n",
      "\t\tToken in Sentence: established\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: various\n",
      "\t\tToken in Sentence: parts\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: North\n",
      "\t\tToken in Sentence: -\n",
      "\t\tToken in Sentence: America\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: more\n",
      "\t\tToken in Sentence: recently\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: some\n",
      "\t\tToken in Sentence: parts\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: Western\n",
      "\t\tToken in Sentence: Europe\n",
      "\t\tToken in Sentence: as\n",
      "\t\tToken in Sentence: well\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Adriaens\n",
      "\t\tToken in Sentence: et\n",
      "\t\tToken in Sentence: al\n",
      "\t\tToken in Sentence: .\n",
      "\t\tToken in Sentence: 2003\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Simultaneous with their establishment in new habitats a population decline of native species was observed.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {decline}\n",
      "\t\tToken in Sentence: Simultaneous\n",
      "\t\tToken in Sentence: with\n",
      "\t\tToken in Sentence: their\n",
      "\t\tToken in Sentence: establishment\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: new\n",
      "\t\tToken in Sentence: habitats\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: population\n",
      "\t\tToken in Sentence: decline\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: native\n",
      "Method 3: Match Between 'species' and 'native species'\n",
      "No Matches Between [] and native species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: was\n",
      "\t\tToken in Sentence: observed\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: The establishment of C. septempunctata in arable fields in North America was followed by a dramatic decline of several native ladybeetles (including Adalia bipunctata L.) in these fields (Alyokhin and Sewell 2004; Elliott et al. 1996; Evans 2004; Wheeler and Hoebeke 1995).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {decline}\n",
      "\t\tToken in Sentence: The\n",
      "\t\tToken in Sentence: establishment\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: C.\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis]) and C. septempunctata\n",
      "No Matches Between [] and C. septempunctata\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: septempunctata\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: arable\n",
      "\t\tToken in Sentence: fields\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: North\n",
      "\t\tToken in Sentence: America\n",
      "\t\tToken in Sentence: was\n",
      "\t\tToken in Sentence: followed\n",
      "\t\tToken in Sentence: by\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: dramatic\n",
      "\t\tToken in Sentence: decline\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: several\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata]) and several native ladybeetles\n",
      "No Matches Between [C. septempunctata] and several native ladybeetles\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: native\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: including\n",
      "\t\tToken in Sentence: Adalia\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata, several native ladybeetles]) and Adalia bipunctata L.\n",
      "No Matches Between [C. septempunctata, several native ladybeetles] and Adalia bipunctata L.\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: bipunctata\n",
      "Method 1: Match Between 'Adalia bipunctata L.' and 'Adalia bipunctata L.'\n",
      "Method 1: Match Between 'Adalia bipunctata L.' and 'Adalia bipunctata L.'\n",
      "\t\tAlready Seen Species 'bipunctata' in Sentence\n",
      "\t\tToken in Sentence: L.\n",
      "Method 1: Match Between 'Adalia bipunctata L.' and 'Adalia bipunctata L.'\n",
      "Method 1: Match Between 'Adalia bipunctata L.' and 'Adalia bipunctata L.'\n",
      "\t\tAlready Seen Species 'L.' in Sentence\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: these\n",
      "\t\tToken in Sentence: fields\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Alyokhin\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Sewell\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Elliott\n",
      "\t\tToken in Sentence: et\n",
      "\t\tToken in Sentence: al\n",
      "\t\tToken in Sentence: .\n",
      "\t\tToken in Sentence: 1996\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Evans\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Wheeler\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Hoebeke\n",
      "\t\tToken in Sentence: 1995\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: C. septempunctata also became the dominant ladybeetle species in apple orchards, pushing A. bipunctata to a second position (Brown 2003; Brown and Miller 1998).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: C.\n",
      "Method 1: Match Between 'C. septempunctata' and 'C. septempunctata'\n",
      "No Matches Between [] and C. septempunctata\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: septempunctata\n",
      "Method 1: Match Between 'C. septempunctata' and 'C. septempunctata'\n",
      "Method 1: Match Between 'C. septempunctata' and 'C. septempunctata'\n",
      "\t\tAlready Seen Species 'septempunctata' in Sentence\n",
      "\t\tToken in Sentence: also\n",
      "\t\tToken in Sentence: became\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: dominant\n",
      "Method 2: Match Between 'species' and 'dominant ladybeetle'\n",
      "No Matches Between [C. septempunctata, C. septempunctata] and dominant ladybeetle\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: ladybeetle\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 2: Match Between 'dominant ladybeetle' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: apple\n",
      "\t\tToken in Sentence: orchards\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: pushing\n",
      "\t\tToken in Sentence: A.\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata, several native ladybeetles, Adalia bipunctata L.]) and A.\n",
      "No Matches Between [C. septempunctata, C. septempunctata, dominant ladybeetle, species] and A.\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: bipunctata\n",
      "Method 3: Match Between 'A.' and 'A. bipunctata'\n",
      "Method 3: Match Between 'A.' and 'A. bipunctata'\n",
      "\t\tAlready Seen Species 'bipunctata' in Sentence\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: second\n",
      "\t\tToken in Sentence: position\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Brown\n",
      "\t\tToken in Sentence: 2003\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Brown\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Miller\n",
      "\t\tToken in Sentence: 1998\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: The later establishment of H. axyridis in orchards resulted in a local decline of especially this other exotic C. septempunctata (Brown 2003), but this pattern is not yet apparent in arable fields (Nault and Kennedy 2003).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {decline}\n",
      "\t\tToken in Sentence: The\n",
      "\t\tToken in Sentence: later\n",
      "\t\tToken in Sentence: establishment\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: H.\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata, several native ladybeetles, Adalia bipunctata L., A.]) and H.\n",
      "No Matches Between [] and H.\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: axyridis\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: orchards\n",
      "\t\tToken in Sentence: resulted\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: local\n",
      "\t\tToken in Sentence: decline\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: especially\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: other\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata, several native ladybeetles, Adalia bipunctata L., A., H.]) and other exotic C. septempunctata\n",
      "No Matches Between [H.] and other exotic C. septempunctata\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: exotic\n",
      "\t\tToken in Sentence: C.\n",
      "\t\tToken in Sentence: septempunctata\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Brown\n",
      "\t\tToken in Sentence: 2003\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: but\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: pattern\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: yet\n",
      "\t\tToken in Sentence: apparent\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: arable\n",
      "\t\tToken in Sentence: fields\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Nault\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Kennedy\n",
      "\t\tToken in Sentence: 2003\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: In none of the cases the exotic species has resulted in the exclusion of native species.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: none\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: cases\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 3: Match Between 'species' and 'exotic species'\n",
      "No Matches Between [] and exotic species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: has\n",
      "\t\tToken in Sentence: resulted\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exclusion\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: native\n",
      "Method 3: Match Between 'species' and 'native species'\n",
      "No Matches Between [exotic species] and native species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Resource competition for aphid prey is a possible explanation for the decline in native species following the establishment of the exotic one (Evans 2004).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {decline}\n",
      "\t\tToken in Sentence: Resource\n",
      "\t\tToken in Sentence: competition\n",
      "\t\tToken in Sentence: for\n",
      "\t\tToken in Sentence: aphid\n",
      "\t\tToken in Sentence: prey\n",
      "Method 1: Match Between 'prey' and 'prey'\n",
      "No Matches Between [] and prey\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: a\n",
      "\t\tToken in Sentence: possible\n",
      "\t\tToken in Sentence: explanation\n",
      "\t\tToken in Sentence: for\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: decline\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: native\n",
      "Method 3: Match Between 'species' and 'native species'\n",
      "No Matches Between [prey] and native species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: following\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: establishment\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "\t\tToken in Sentence: one\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Evans\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: However, no evidence is yet provided that the exotic species are better resource competitors than the native ones.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {better}\n",
      "\t\tToken in Sentence: However\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: no\n",
      "\t\tToken in Sentence: evidence\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: yet\n",
      "\t\tToken in Sentence: provided\n",
      "\t\tToken in Sentence: that\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 3: Match Between 'species' and 'exotic species'\n",
      "No Matches Between [] and exotic species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: are\n",
      "\t\tToken in Sentence: better\n",
      "\t\tToken in Sentence: resource\n",
      "\t\tToken in Sentence: competitors\n",
      "\t\tToken in Sentence: than\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: native\n",
      "\t\tToken in Sentence: ones\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Intraguild predation (IGP) between the exotic and native ladybeetles is regarded as the most likely reason for the spread of the exotic species and the subsequent reduction of native or earlier-established species (Yasuda and Ohnuma 1999).\n",
      "\tSentence Cause Tokens: {reduction}\n",
      "\tSentence Change Tokens: {reduction}\n",
      "\t\tToken in Sentence: Intraguild\n",
      "\t\tToken in Sentence: predation\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: between\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: native\n",
      "Method 3: Match Between 'ladybeetles' and 'native ladybeetles'\n",
      "No Matches Between [] and native ladybeetles\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: ladybeetles\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: regarded\n",
      "\t\tToken in Sentence: as\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: most\n",
      "\t\tToken in Sentence: likely\n",
      "\t\tToken in Sentence: reason\n",
      "\t\tToken in Sentence: for\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: spread\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 3: Match Between 'species' and 'exotic species'\n",
      "No Matches Between [native ladybeetles] and exotic species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: subsequent\n",
      "\t\tToken in Sentence: reduction\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: native\n",
      "\t\tToken in Sentence: or\n",
      "\t\tToken in Sentence: earlier\n",
      "\t\tToken in Sentence: -\n",
      "\t\tToken in Sentence: established\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 3: Match Between 'exotic species' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Yasuda\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Ohnuma\n",
      "\t\tToken in Sentence: 1999\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Lab studies indeed show that the IGP by the exotic species on native species is generally bigger than the reverse predation (Snyder et al. 2004; Yasuda et al. 2004), and that IGP between the two exotic species is in favour of H. axyridis (Yasuda and Ohnuma 1999).\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: {bigger}\n",
      "\t\tToken in Sentence: Lab\n",
      "\t\tToken in Sentence: studies\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: indeed\n",
      "\t\tToken in Sentence: show\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: that\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: by\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 3: Match Between 'species' and 'exotic species'\n",
      "No Matches Between [] and exotic species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: native\n",
      "Method 3: Match Between 'species' and 'native species'\n",
      "No Matches Between [exotic species] and native species\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: generally\n",
      "\t\tToken in Sentence: bigger\n",
      "\t\tToken in Sentence: than\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: reverse\n",
      "\t\tToken in Sentence: predation\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Snyder\n",
      "\t\tToken in Sentence: et\n",
      "\t\tToken in Sentence: al\n",
      "\t\tToken in Sentence: .\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: ;\n",
      "\t\tToken in Sentence: Yasuda\n",
      "\t\tToken in Sentence: et\n",
      "\t\tToken in Sentence: al\n",
      "\t\tToken in Sentence: .\n",
      "\t\tToken in Sentence: 2004\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: that\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: between\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: two\n",
      "\t\tToken in Sentence: exotic\n",
      "Method 3: Match Between 'species' and 'exotic species'\n",
      "Method 1: Match Between 'exotic species' and 'exotic species'\n",
      "\t\tAlready Seen Species 'exotic' in Sentence\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: favour\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: H.\n",
      "Method 1: Match Between 'H.' and 'H.'\n",
      "No Matches Between [exotic species, native species, exotic species] and H.\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: axyridis\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: Yasuda\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: Ohnuma\n",
      "\t\tToken in Sentence: 1999\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: A complicating factor is that these predators not only feed on the juveniles of other predator species, but also on those from their own species.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: A\n",
      "\t\tToken in Sentence: complicating\n",
      "\t\tToken in Sentence: factor\n",
      "\t\tToken in Sentence: is\n",
      "\t\tToken in Sentence: that\n",
      "\t\tToken in Sentence: these\n",
      "\t\tToken in Sentence: predators\n",
      "Method 3: Match Between 'Exotic predators' and 'predators'\n",
      "No Matches Between [] and predators\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: not\n",
      "\t\tToken in Sentence: only\n",
      "\t\tToken in Sentence: feed\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: juveniles\n",
      "No Matches Between dict_keys([Exotic predators, related native species, species, native predators, arthropods, stable predator, prey, native lady beetles, Coccinellidae, Harmonia axyridis, Coccinella septempunctata, ladybeetles, larvae, Eurasian Coccinella septempunctata L., Asian Harmonia axyridis, C. septempunctata, several native ladybeetles, Adalia bipunctata L., A., H., other exotic C. septempunctata]) and juveniles\n",
      "No Matches Between [predators] and juveniles\n",
      "\t\t+ Points for Interaction\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: other\n",
      "Method 2: Match Between 'species' and 'other predator'\n",
      "Method 3: Match Between 'predators' and 'other predator'\n",
      "\t\tAlready Seen Species 'other' in Sentence\n",
      "\t\tToken in Sentence: predator\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "Method 2: Match Between 'other predator' and 'species'\n",
      "\t\tAlready Seen Species 'species' in Sentence\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: but\n",
      "\t\tToken in Sentence: also\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: those\n",
      "\t\tToken in Sentence: from\n",
      "\t\tToken in Sentence: their\n",
      "\t\tToken in Sentence: own\n",
      "Method 3: Match Between 'species' and 'own species'\n",
      "Method 3: Match Between 'species' and 'own species'\n",
      "\t\tAlready Seen Species 'own' in Sentence\n",
      "\t\tToken in Sentence: species\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: This cannibalism or Intraspecific Predation (ISP) may partly reduce the effect of IGP on population dominance.\n",
      "\tSentence Cause Tokens: {reduce}\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: This\n",
      "\t\tToken in Sentence: cannibalism\n",
      "\t\tToken in Sentence: or\n",
      "\t\tToken in Sentence: Intraspecific\n",
      "\t\tToken in Sentence: Predation\n",
      "\t\tToken in Sentence: (\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: )\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: partly\n",
      "\t\tToken in Sentence: reduce\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: effect\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: population\n",
      "\t\tToken in Sentence: dominance\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: In this study we therefore start with reviewing the theory on the combined impact of IGP and ISP on population dynamics.\n",
      "\tSentence Cause Tokens: {impact}\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: study\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: therefore\n",
      "\t\tToken in Sentence: start\n",
      "\t\tToken in Sentence: with\n",
      "\t\tToken in Sentence: reviewing\n",
      "\t\t- Points for Experiment\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: theory\n",
      "\t\t- Points for Experiment\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: combined\n",
      "\t\tToken in Sentence: impact\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: IGP\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: ISP\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: population\n",
      "\t\tToken in Sentence: dynamics\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Then we show how the strength of the different interand intraspecific interaction may be calculated, and use these values to derive predictions on invasibility and species coexistence.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: Then\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: show\n",
      "\t\t+ Points for Experiment\n",
      "\t\tToken in Sentence: how\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: strength\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: different\n",
      "\t\tToken in Sentence: interand\n",
      "\t\tToken in Sentence: intraspecific\n",
      "\t\tToken in Sentence: interaction\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: be\n",
      "\t\tToken in Sentence: calculated\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: use\n",
      "\t\tToken in Sentence: these\n",
      "\t\tToken in Sentence: values\n",
      "\t\tToken in Sentence: to\n",
      "\t\tToken in Sentence: derive\n",
      "\t\tToken in Sentence: predictions\n",
      "\t\tToken in Sentence: on\n",
      "\t\tToken in Sentence: invasibility\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: species\n",
      "Method 1: Match Between 'species' and 'species'\n",
      "No Matches Between [] and species\n",
      "\t\t+ Points for Species\n",
      "\t\tToken in Sentence: coexistence\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: In the second part we include resource competition in our theory.\n",
      "\tSentence Cause Tokens: set()\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: In\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: second\n",
      "\t\tToken in Sentence: part\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: include\n",
      "\t\tToken in Sentence: resource\n",
      "\t\tToken in Sentence: competition\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: our\n",
      "\t\tToken in Sentence: theory\n",
      "\t\t- Points for Experiment\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: How will the various coccinelids differ in competitive ability, and how will this alter our conclusions.\n",
      "\tSentence Cause Tokens: {alter}\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: How\n",
      "\t\tToken in Sentence: will\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: various\n",
      "\t\tToken in Sentence: coccinelids\n",
      "\t\tToken in Sentence: differ\n",
      "\t\tToken in Sentence: in\n",
      "\t\tToken in Sentence: competitive\n",
      "\t\tToken in Sentence: ability\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: how\n",
      "\t\tToken in Sentence: will\n",
      "\t\tToken in Sentence: this\n",
      "\t\tToken in Sentence: alter\n",
      "\t\tToken in Sentence: our\n",
      "\t\tToken in Sentence: conclusions\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence: Finally, we will discuss the realism of our simplifying assumptions, indicate how spatial and temporal avoidance, resource partitioning and metapopulation dynamics may affect our conclusions.\n",
      "\tSentence Cause Tokens: {affect}\n",
      "\tSentence Change Tokens: set()\n",
      "\t\tToken in Sentence: Finally\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: we\n",
      "\t\tToken in Sentence: will\n",
      "\t\tToken in Sentence: discuss\n",
      "\t\tToken in Sentence: the\n",
      "\t\tToken in Sentence: realism\n",
      "\t\tToken in Sentence: of\n",
      "\t\tToken in Sentence: our\n",
      "\t\tToken in Sentence: simplifying\n",
      "\t\tToken in Sentence: assumptions\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: indicate\n",
      "\t\tToken in Sentence: how\n",
      "\t\tToken in Sentence: spatial\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: temporal\n",
      "\t\tToken in Sentence: avoidance\n",
      "\t\tToken in Sentence: ,\n",
      "\t\tToken in Sentence: resource\n",
      "\t\tToken in Sentence: partitioning\n",
      "\t\tToken in Sentence: and\n",
      "\t\tToken in Sentence: metapopulation\n",
      "\t\tToken in Sentence: dynamics\n",
      "\t\tToken in Sentence: may\n",
      "\t\tToken in Sentence: affect\n",
      "\t\tToken in Sentence: our\n",
      "\t\tToken in Sentence: conclusions\n",
      "\t\tToken in Sentence: .\n",
      "\tSentence I: Exotic predators are more likely to replace related native species when these species not only compete for similar prey species, but also predate on the offspring of the native predators.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: In several groups of arthropods, however, this intraguild predation (IGP) is not only mutual, but also co-occurs with intraspecific predation (ISP or cannibalism).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: These different processes may have counteracting effects on species invasion and coexistence.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: In this study, we derived simple rules that describe under which combinations of IGP and ISP a predator species is able to invade into a stable predator-prey system, and under which conditions an invasion will results in displacement or in coexistence.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {results, study}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: This theory is then applied to species pairs of exotic and native lady beetles, to test if differences in IGP and ISP may play a role in the establishment of introduced exotic ladybeetles species (Coleoptera: Coccinellidae) such as Harmonia axyridis in Europe and Coccinella septempunctata in North America.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {applied, test, theory}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: {role}\n",
      "\tSentence I Variability Tokens: {differences}\n",
      "Comma - Unit Context of 'differences': [,, to, test, if, differences, in, IGP, and, ISP, may, play, a, role, in, the, establishment, of, introduced, exotic, ladybeetles, species, (, Coleoptera, :, Coccinellidae, ), such, as, Harmonia, axyridis, in, Europe, and, Coccinella, septempunctata, in, North, America, .]\n",
      "\t\tVariability Token 'differences' Traits in Context: {role}\n",
      "\tVariables: [role]\n",
      "\tTrait Variation Points for I: 0.35\n",
      "\tSentence J: This theory is then applied to species pairs of exotic and native lady beetles, to test if differences in IGP and ISP may play a role in the establishment of introduced exotic ladybeetles species (Coleoptera: Coccinellidae) such as Harmonia axyridis in Europe and Coccinella septempunctata in North America.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {Coccinella, species, native, Coleoptera, Harmonia, beetles, exotic, Coccinellidae, species}\n",
      "\tSentence J Trait Tokens: {role}\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: For an accurate estimation of the key processes we cannot rely on specific experimental data only, but take allometric relationships into account as well.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: For ladybeetles, IGP and ISP seem to be determined largely by size differences of the interacting larvae, thereby giving an overall advantage to the larger species.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {larger}\n",
      "\tSentence J Species Tokens: {ladybeetles, larger, larvae}\n",
      "\tSentence J Trait Tokens: {size}\n",
      "\tVariable Types: set()\n",
      "\tTrait Types in Sentence J: set()\n",
      "\tVariable Trait (as Strings): {'role'}\n",
      "\tTrait (as Strings) in Sentence J: {'size'}\n",
      "\tVariable Referenced? False\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 6\n",
      "\tScale for Sentence J Points: 0.9310344827586207\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.5023781212841855\n",
      "\tSentence J: On the other hand, larger species generally have higher food requirements, which may give them a disadvantage in resource competition.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {higher, larger}\n",
      "\tSentence J Species Tokens: {larger}\n",
      "\tSentence J Trait Tokens: {food}\n",
      "\tVariable Types: set()\n",
      "\tTrait Types in Sentence J: {'N/A', 'Food'}\n",
      "\tVariable Trait (as Strings): {'role'}\n",
      "\tTrait (as Strings) in Sentence J: {'food'}\n",
      "\tVariable Referenced? False\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 7\n",
      "\tScale for Sentence J Points: 0.896551724137931\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.49494649227110576\n",
      "\tSentence J: The estimated levels of IGP, ISP and competitive ability of the interacting species can not fully explain the invasion by the two exotic ladybeetles species.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {exotic, species, species}\n",
      "\tSentence J Trait Tokens: {ability}\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: _________________\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: Impact of Intraspecific and Intraguild Predation on Predator Invasion and Coexistence Second International Symposium on Biological Control of Arthropods 39 INTRODUCTION\n",
      "\tSentence J Cause Tokens: {Impact}\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {Predator, Arthropods}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 10\n",
      "\tScale for Sentence J Points: 0.7931034482758621\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.4726516052318668\n",
      "\tSentence J: In recent years the invasive nature of two ladybeetles (Coleoptera: Coccinellidae) has drawn considerable attention in the scientific literature.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {ladybeetles, Coleoptera, Coccinellidae}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: The originally Eurasian Coccinella septempunctata L. established and spread through the whole of North-America in the 70s and 80s (Alyokhin and Sewell 2004; Elliott et al. 1996).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {Eurasian, L.}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: Later, in the mid 90s, the originally Asian Harmonia axyridis (Pallas) became established in various parts of North-America and more recently in some parts of Western Europe as well (Adriaens et al. 2003).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {more}\n",
      "\tSentence J Species Tokens: {Asian, Harmonia}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 13\n",
      "\tScale for Sentence J Points: 0.6896551724137931\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.4503567181926278\n",
      "\tSentence J: Simultaneous with their establishment in new habitats a population decline of native species was observed.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {decline}\n",
      "\tSentence J Species Tokens: {native}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 14\n",
      "\tScale for Sentence J Points: 0.6551724137931034\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.44292508917954815\n",
      "\tSentence J: The establishment of C. septempunctata in arable fields in North America was followed by a dramatic decline of several native ladybeetles (including Adalia bipunctata L.) in these fields (Alyokhin and Sewell 2004; Elliott et al. 1996; Evans 2004; Wheeler and Hoebeke 1995).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {decline}\n",
      "\tSentence J Species Tokens: {Adalia, L., C., several, bipunctata}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 15\n",
      "\tScale for Sentence J Points: 0.6206896551724138\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.43549346016646845\n",
      "\tSentence J: C. septempunctata also became the dominant ladybeetle species in apple orchards, pushing A. bipunctata to a second position (Brown 2003; Brown and Miller 1998).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {septempunctata, bipunctata, C., species, A., dominant}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: The later establishment of H. axyridis in orchards resulted in a local decline of especially this other exotic C. septempunctata (Brown 2003), but this pattern is not yet apparent in arable fields (Nault and Kennedy 2003).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {decline}\n",
      "\tSentence J Species Tokens: {H., other}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 17\n",
      "\tScale for Sentence J Points: 0.5517241379310345\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.4206302021403091\n",
      "\tSentence J: In none of the cases the exotic species has resulted in the exclusion of native species.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {exotic, native}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: Resource competition for aphid prey is a possible explanation for the decline in native species following the establishment of the exotic one (Evans 2004).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {decline}\n",
      "\tSentence J Species Tokens: {native, prey}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 19\n",
      "\tScale for Sentence J Points: 0.48275862068965514\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.4057669441141498\n",
      "\tSentence J: However, no evidence is yet provided that the exotic species are better resource competitors than the native ones.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {better}\n",
      "\tSentence J Species Tokens: {exotic}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 20\n",
      "\tScale for Sentence J Points: 0.4482758620689655\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.3983353151010701\n",
      "\tSentence J: Intraguild predation (IGP) between the exotic and native ladybeetles is regarded as the most likely reason for the spread of the exotic species and the subsequent reduction of native or earlier-established species (Yasuda and Ohnuma 1999).\n",
      "\tSentence J Cause Tokens: {reduction}\n",
      "\tSentence J Change Tokens: {reduction}\n",
      "\tSentence J Species Tokens: {exotic, species, native}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 21\n",
      "\tScale for Sentence J Points: 0.4137931034482759\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.3909036860879904\n",
      "\tSentence J: Lab studies indeed show that the IGP by the exotic species on native species is generally bigger than the reverse predation (Snyder et al. 2004; Yasuda et al. 2004), and that IGP between the two exotic species is in favour of H. axyridis (Yasuda and Ohnuma 1999).\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: {bigger}\n",
      "\tSentence J Species Tokens: {native, exotic, H., exotic}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tTrait Variation Points for J: 0.25\n",
      "\ti: 4\n",
      "\tj: 22\n",
      "\tScale for Sentence J Points: 0.3793103448275862\n",
      "\tScale for Sentence I Points: 0.8620689655172413\n",
      "\tTrait Variation Points: 0.3834720570749108\n",
      "\tSentence J: A complicating factor is that these predators not only feed on the juveniles of other predator species, but also on those from their own species.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {juveniles, own, other, species, predators}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: This cannibalism or Intraspecific Predation (ISP) may partly reduce the effect of IGP on population dominance.\n",
      "\tSentence J Cause Tokens: {reduce}\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: In this study we therefore start with reviewing the theory on the combined impact of IGP and ISP on population dynamics.\n",
      "\tSentence J Cause Tokens: {impact}\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: Then we show how the strength of the different interand intraspecific interaction may be calculated, and use these values to derive predictions on invasibility and species coexistence.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: {species}\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: In the second part we include resource competition in our theory.\n",
      "\tSentence J Cause Tokens: set()\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: How will the various coccinelids differ in competitive ability, and how will this alter our conclusions.\n",
      "\tSentence J Cause Tokens: {alter}\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence J: Finally, we will discuss the realism of our simplifying assumptions, indicate how spatial and temporal avoidance, resource partitioning and metapopulation dynamics may affect our conclusions.\n",
      "\tSentence J Cause Tokens: {affect}\n",
      "\tSentence J Change Tokens: set()\n",
      "\tSentence J Species Tokens: set()\n",
      "\tSentence J Trait Tokens: set()\n",
      "\tUnsatisfied Conditions for Sentence J\n",
      "\tSentence I: For an accurate estimation of the key processes we cannot rely on specific experimental data only, but take allometric relationships into account as well.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {experimental, data}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: For ladybeetles, IGP and ISP seem to be determined largely by size differences of the interacting larvae, thereby giving an overall advantage to the larger species.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: On the other hand, larger species generally have higher food requirements, which may give them a disadvantage in resource competition.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: The estimated levels of IGP, ISP and competitive ability of the interacting species can not fully explain the invasion by the two exotic ladybeetles species.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: _________________\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: Impact of Intraspecific and Intraguild Predation on Predator Invasion and Coexistence Second International Symposium on Biological Control of Arthropods 39 INTRODUCTION\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: In recent years the invasive nature of two ladybeetles (Coleoptera: Coccinellidae) has drawn considerable attention in the scientific literature.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {considerable}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: The originally Eurasian Coccinella septempunctata L. established and spread through the whole of North-America in the 70s and 80s (Alyokhin and Sewell 2004; Elliott et al. 1996).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: Later, in the mid 90s, the originally Asian Harmonia axyridis (Pallas) became established in various parts of North-America and more recently in some parts of Western Europe as well (Adriaens et al. 2003).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: Simultaneous with their establishment in new habitats a population decline of native species was observed.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {observed}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: The establishment of C. septempunctata in arable fields in North America was followed by a dramatic decline of several native ladybeetles (including Adalia bipunctata L.) in these fields (Alyokhin and Sewell 2004; Elliott et al. 1996; Evans 2004; Wheeler and Hoebeke 1995).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: C. septempunctata also became the dominant ladybeetle species in apple orchards, pushing A. bipunctata to a second position (Brown 2003; Brown and Miller 1998).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: The later establishment of H. axyridis in orchards resulted in a local decline of especially this other exotic C. septempunctata (Brown 2003), but this pattern is not yet apparent in arable fields (Nault and Kennedy 2003).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {resulted}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: In none of the cases the exotic species has resulted in the exclusion of native species.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {resulted}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: Resource competition for aphid prey is a possible explanation for the decline in native species following the establishment of the exotic one (Evans 2004).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: However, no evidence is yet provided that the exotic species are better resource competitors than the native ones.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {evidence}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: Intraguild predation (IGP) between the exotic and native ladybeetles is regarded as the most likely reason for the spread of the exotic species and the subsequent reduction of native or earlier-established species (Yasuda and Ohnuma 1999).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: Lab studies indeed show that the IGP by the exotic species on native species is generally bigger than the reverse predation (Snyder et al. 2004; Yasuda et al. 2004), and that IGP between the two exotic species is in favour of H. axyridis (Yasuda and Ohnuma 1999).\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {studies, show}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: A complicating factor is that these predators not only feed on the juveniles of other predator species, but also on those from their own species.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: This cannibalism or Intraspecific Predation (ISP) may partly reduce the effect of IGP on population dominance.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: In this study we therefore start with reviewing the theory on the combined impact of IGP and ISP on population dynamics.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {study, theory}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: Then we show how the strength of the different interand intraspecific interaction may be calculated, and use these values to derive predictions on invasibility and species coexistence.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {show}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: In the second part we include resource competition in our theory.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: {theory}\n",
      "\tTrait Variation Points for I: 0.1\n",
      "\tSentence I Trait Tokens: set()\n",
      "\tNo Trait Tokens in Sentence I\n",
      "\tSentence I: How will the various coccinelids differ in competitive ability, and how will this alter our conclusions.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "\tSentence I: Finally, we will discuss the realism of our simplifying assumptions, indicate how spatial and temporal avoidance, resource partitioning and metapopulation dynamics may affect our conclusions.\n",
      "\tSentence I Test Tokens: set()\n",
      "\tSentence I Experiment Tokens: set()\n",
      "\tNo Experiment or Test Tokens in Sentence I\n",
      "Max Trait Variation Points: 0.5023781212841855\n",
      "Score, Points: 0.34321343638525564, [0.025, 0.24722222222222226, 0.225, 0.3777777777777777, 1.0, 0.5023781212841855]\n",
      "(0.34321343638525564, [0.025, 0.24722222222222226, 0.225, 0.3777777777777777, 1.0, 0.5023781212841855])\n"
     ]
    }
   ],
   "source": [
    "main = Main()\n",
    "main.update_text(str(abstract), verbose=True)\n",
    "print(main.score(verbose=True))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "21a15564-0d3e-4952-baba-40b5dee8a4aa",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "61d1eebc-036a-450f-81b6-a211e902264c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eac2005d-489d-4c1e-8d5c-4f2e856aa2f8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bcd82a79-d4db-43dd-ad4d-f2c217307573",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8807fa3f-9dbb-44a5-95c4-fc77824d9bd9",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d02ef85a-b25a-4987-8a02-5db17414f354",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73367321-7475-40a3-aa76-3f1b35a7ed9f",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2da117a1-ba3e-458c-b55f-d213650e9f22",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d4c3ebb3-bcd5-479d-9fcb-6b945956edf4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c763d50b-a69e-478d-8e62-f1c75412ea54",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
