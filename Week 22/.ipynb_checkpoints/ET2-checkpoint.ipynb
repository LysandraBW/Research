{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "6cd50465-fb8b-45e3-9233-fe5240abd382",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import spacy\n",
    "import itertools"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "4b6d2f9e-131b-45d8-b838-7dd83a002f2c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\lbeln\\anaconda3\\envs\\3.10\\lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "3d2579cf-684c-4c21-a5e3-be4c54ba382d",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Unit:\n",
    "    def __init__(self, sort=None, tokens=None):\n",
    "        self.sort = sort\n",
    "        self.set_tokens(tokens)\n",
    "\n",
    "    def set_tokens(self, tokens):\n",
    "        self.tokens = tokens\n",
    "        self.tokens = sorted(self.tokens, key=lambda token: token.i)\n",
    "        self.l = None if not tokens else tokens[0].i\n",
    "        self.r = None if not tokens else tokens[-1].i"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "67bb71e6-c353-4b80-a23f-d2e35309b0f9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(elements, bool_lambda):\n",
    "    for element in elements:\n",
    "        if bool_lambda(element):\n",
    "            return element\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3126865-e09a-42ae-bd67-71d2f4d09807",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conjunction(token):\n",
    "    return token.lower_ in [\"and\", \"or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "cf5268d2-3d34-4109-9fa1-cdc4833df592",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_units(doc):\n",
    "    units = []\n",
    "\n",
    "    i = 0\n",
    "    buffer = []\n",
    "    while i < len(doc):\n",
    "        if doc[i].text != sep:\n",
    "            buffer.append(doc[i])\n",
    "            i += 1\n",
    "            continue\n",
    "        else:\n",
    "            units.append(Unit(\"I\", buffer))\n",
    "            buffer = []\n",
    "    \n",
    "            if i+1 < len(doc) and is_conjunction(doc[i+1]):\n",
    "                units.append(Unit(\"E\", [doc[i], doc[i+1]]))\n",
    "                i += 2\n",
    "            else:\n",
    "                units.append(Unit(\"B\", [doc[i]]))\n",
    "                i += 1\n",
    "    \n",
    "    if buffer:\n",
    "        units.append(Unit(\"I\", buffer))\n",
    "    \n",
    "    return units"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "00c75714-dbd0-4176-b8e2-6098d327f0fd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find_lists(units):\n",
    "    lists = []\n",
    "\n",
    "    i = 0\n",
    "    buffer = []\n",
    "    while i < len(units):\n",
    "        unit = units[i]\n",
    "        if unit.sort == \"I\":\n",
    "            buffer.append(unit)\n",
    "        if unit.sort == \"E\":\n",
    "            if len(buffer) < 2:\n",
    "                buffer = []\n",
    "            elif i < len(units):\n",
    "                buffer.append(units[i+1])\n",
    "                lists.append(buffer)\n",
    "                buffer = []\n",
    "        i += 1\n",
    "\n",
    "    i = 0\n",
    "    while i < len(buffer):\n",
    "        unit = buffer[i]\n",
    "        simple = len([t for t in unit.tokens if is_conjunction(t)]) == 1\n",
    "        not_seen = bool(i - 1 >= 0 and buffer[i-1].sort != \"E\")\n",
    "        \n",
    "        if (not_seen or not lists) and simple:\n",
    "            lists.append([unit])\n",
    "        \n",
    "        i += 1\n",
    "        \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "26c89994-4529-4271-a5f8-a904512d0631",
   "metadata": {},
   "outputs": [],
   "source": [
    "def fix_lists(lists):\n",
    "    overlaps = []\n",
    "    \n",
    "    i = 0\n",
    "    while i + 1 < len(lists):\n",
    "        a = lists[i]\n",
    "        b = lists[i+1]\n",
    "        \n",
    "        if a[-1] != b[0]:\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if len(a) <= 1 or len(b) <= 1:\n",
    "            a[-1].tokens = [*a[-1].tokens]\n",
    "            b[0].tokens = [*b[0].tokens]\n",
    "            i += 1\n",
    "            continue\n",
    "\n",
    "        if len(a[-1].tokens) == 1:\n",
    "            overlaps.extend([a, b])\n",
    "            i += 2\n",
    "        else:\n",
    "            a[-1] = Unit(\"I\", [a[-1].tokens[0]])\n",
    "            b[0] = Unit(\"I\", [b[0].tokens[-1]])\n",
    "            i += 1\n",
    "\n",
    "    lists = [l for l in lists if l not in overlaps]\n",
    "\n",
    "    i = 0\n",
    "    num_lists = len(lists)\n",
    "    while i < num_lists:\n",
    "        if len(lists[i]) == 1:\n",
    "            i += 1\n",
    "            continue\n",
    "        \n",
    "        for unit in lists[i]:\n",
    "            if len([t for t in unit.tokens if is_conjunction(t)]) == 1:\n",
    "                lists.append([unit])\n",
    "        i += 1\n",
    "    \n",
    "    return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "602b6a78-3ce2-4234-aa4a-035db62c77ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_speech(a, b):\n",
    "    nouns = []\n",
    "    if a.pos_ in nouns and b.pos_ in nouns:\n",
    "        return True\n",
    "    return a.pos_ == b.pos_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "c5d65752-bd1f-47d3-9f88-43d49d245bcb",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_list(lst):\n",
    "    if len(lst) == 1:\n",
    "        i_conj = 0\n",
    "        for i, token in enumerate(lst[0].tokens):\n",
    "            if is_conjunction(token):\n",
    "                i_conj = i\n",
    "                break\n",
    "\n",
    "        a = Unit(\"I\", lst[0].tokens[:i_conj])\n",
    "        b = Unit(\"I\", lst[0].tokens[i_conj+1:])\n",
    "\n",
    "        print(a.tokens)\n",
    "        print(b.tokens)\n",
    "\n",
    "        ignore = [\"ADV\", \"ADJ\", \"ADP\", \"DET\", \"SYM\"]\n",
    "\n",
    "        l_bound = b.tokens[0].pos_\n",
    "        if l_bound in ignore:\n",
    "            bi = 0\n",
    "            while bi < len(b.tokens) and b.tokens[bi] in ignore:\n",
    "                l_bound = b.tokens[bi].pos_\n",
    "                bi += 1\n",
    "            l_bound = [*ignore, l_bound]\n",
    "        else:\n",
    "            l_bound = [l_bound]\n",
    "\n",
    "        r_bound = a.tokens[-1].pos_\n",
    "        if r_bound in ignore:\n",
    "            ai = len(a.tokens) - 1\n",
    "            while ai >= 0 and a.tokens[ai] in ignore:\n",
    "                r_bound = a.tokens[ai].pos_\n",
    "                ai -= 1\n",
    "            r_bound = [*ignore, r_bound]\n",
    "        else:\n",
    "            r_bound = [r_bound]\n",
    "        \n",
    "        print(l_bound)\n",
    "        print(r_bound)\n",
    "        \n",
    "        i = len(a.tokens) - 1\n",
    "        while i >= 0 and a.tokens[i].pos_ not in l_bound:\n",
    "            i -= 1\n",
    "\n",
    "        if i < 0:\n",
    "            return None\n",
    "        \n",
    "        a.tokens = [*a.tokens[i:]]\n",
    "        \n",
    "        j = 0\n",
    "        while j < len(b.tokens) and b.tokens[j].pos_ not in r_bound:\n",
    "            j += 1\n",
    "        \n",
    "        if j > len(b.tokens):\n",
    "            return None\n",
    "            \n",
    "        b.tokens = [*b.tokens[:j+1]]\n",
    "        \n",
    "        return [a, b]\n",
    "    else:\n",
    "        l_bound = [unit.tokens[0].pos_ for unit in lst[-2:]]\n",
    "        l_bound.sort()\n",
    "        if l_bound[0] != l_bound[-1]:\n",
    "            return None\n",
    "        \n",
    "        print(f\"Left Bound: {l_bound}\")\n",
    "        l_bound = l_bound[0]\n",
    "\n",
    "        b_lst = [*lst[-2:]]\n",
    "        for i in range(len(lst) - 3, 0, -1):\n",
    "            unit = lst[i]\n",
    "            match = find(unit.tokens, lambda token: token.pos_ == l_bound)\n",
    "            print(f\"...{match}\")\n",
    "            if match:\n",
    "                b_lst.insert(0, unit)\n",
    "            else:\n",
    "                break\n",
    "\n",
    "        i = 0\n",
    "        while i >= 0 and b_lst[0].tokens[i].pos != l_bound:\n",
    "            i -= 1\n",
    "\n",
    "        b_lst[0].tokens = [*b_lst[0].tokens[i:]] \n",
    "        \n",
    "        r_bound = [unit.tokens[-1].pos_ for unit in b_lst[:-1]]\n",
    "        print(f\"Right Bound: {r_bound}\")\n",
    "        \n",
    "        r_bound.sort()\n",
    "        \n",
    "        if r_bound[0] != r_bound[-1]:\n",
    "            return None\n",
    "        \n",
    "        r_bound = r_bound[0]\n",
    "        \n",
    "        j = 0\n",
    "        while j < len(b_lst[-1].tokens) and b_lst[-1].tokens[j].pos != r_bound:\n",
    "            j += 1\n",
    "\n",
    "        b_lst[-1].tokens = [*b_lst[-1].tokens[:j+1]] \n",
    "        return b_lst"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "b12b6202-99a9-473d-a62c-64aca6481cc0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(I) 'Last week'\n",
      "(B) ','\n",
      "(I) 'Mr. Macron said his government would recognize a Palestinian state'\n",
      "(B) ','\n",
      "(I) 'setting France apart from the United States and most of its close allies'\n",
      "(E) ', and'\n",
      "(I) 'risking friction with Mr. Trump .'\n",
      "List: ['Last week', 'Mr. Macron said his government would recognize a Palestinian state', 'setting France apart from the United States and most of its close allies', 'risking friction with Mr. Trump .']\n",
      "List: ['Last week', 'Mr. Macron said his government would recognize a Palestinian state', 'setting France apart from the United States and most of its close allies', 'risking friction with Mr. Trump .']\n",
      "List: ['setting France apart from the United States and most of its close allies']\n",
      "Bound List: ['state', 'setting France apart from the United States and most of its close allies', 'risking friction with Mr. Trump .']\n",
      "[setting, France, apart, from, the, United, States]\n",
      "[most, of, its, close, allies]\n",
      "['ADV', 'ADJ', 'ADP', 'DET', 'SYM', 'ADJ']\n",
      "['PROPN']\n",
      "Bound List: ['the United States', 'most of its close allies']\n"
     ]
    }
   ],
   "source": [
    "doc = nlp(\"Last week, Mr. Macron said his government would recognize a Palestinian state, setting France apart from the United States and most of its close allies, and risking friction with Mr. Trump.\")\n",
    "sep = \";\" if find(doc, lambda token: token.text == \";\" and (token.nbor() and token.nbor().lower_ in [\"and\", \"or\"])) else \",\"\n",
    "\n",
    "units = find_units(doc)\n",
    "for unit in units:\n",
    "    print(f\"({unit.sort}) \\'{' '.join([token.text for token in unit.tokens])}\\'\")\n",
    "\n",
    "lists = find_lists(units)\n",
    "for l in lists:\n",
    "    print(f\"List: {[' '.join([token.text for token in unit.tokens]) for unit in l]}\")\n",
    "\n",
    "f_lists = fix_lists(lists)\n",
    "for l in f_lists:\n",
    "    print(f\"List: {[' '.join([token.text for token in unit.tokens]) for unit in l]}\")\n",
    "\n",
    "f_lists = fix_lists(lists)\n",
    "for l in f_lists:\n",
    "    b_l = bound_list(l)\n",
    "    print(f\"Bound List: {[' '.join([token.text for token in unit.tokens]) for unit in b_l]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "de8ed2b6-9d5e-4fb2-beaf-073a8dcaa04d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "825c3895-0599-4772-bd67-a54043ac9d49",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "631a0c08-e0fb-418e-9a88-385f8399c77b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e720828-0e8c-4759-89bd-eea7c36479d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "ed3d088b-9686-4edf-8e46-be25e60cd315",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Last ADJ\n",
      "week NOUN\n",
      ", PUNCT\n",
      "Mr. PROPN\n",
      "Macron PROPN\n",
      "said VERB\n",
      "his PRON\n",
      "government NOUN\n",
      "would AUX\n",
      "recognize VERB\n",
      "a DET\n",
      "Palestinian ADJ\n",
      "state NOUN\n",
      ", PUNCT\n",
      "setting VERB\n",
      "France PROPN\n",
      "apart ADV\n",
      "from ADP\n",
      "the DET\n",
      "United PROPN\n",
      "States PROPN\n",
      "and CCONJ\n",
      "most ADJ\n",
      "of ADP\n",
      "its PRON\n",
      "close ADJ\n",
      "allies NOUN\n",
      ", PUNCT\n",
      "and CCONJ\n",
      "risking VERB\n",
      "friction NOUN\n",
      "with ADP\n",
      "Mr. PROPN\n",
      "Trump PROPN\n",
      ". PUNCT\n"
     ]
    }
   ],
   "source": [
    "for token in doc:\n",
    "    print(token, token.pos_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d0a57bf5-1c64-446f-850d-b181d46a6719",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
