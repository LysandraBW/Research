{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b95284-9556-4813-a4c8-cc182e276f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc5b30-b2c0-4243-babb-0fbf075093ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")\n",
    "# nlp.add_pipe(\"merge_entities\")\n",
    "# nlp.add_pipe(\"merge_noun_chunks\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "975d591c-640c-4f06-b173-7e46a3c7e40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def flatten(arr):\n",
    "    flat_arr = []\n",
    "\n",
    "    if not isinstance(arr, list):\n",
    "        return [arr]\n",
    "\n",
    "    for element in arr:\n",
    "        flat_arr.extend(flatten(element))\n",
    "\n",
    "    return flat_arr"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dc263-2066-4189-a0e4-0c184242050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(l, f):\n",
    "    for _ in l:\n",
    "        if f(_):\n",
    "            return _\n",
    "    return None\n",
    "\n",
    "def find_all(l, f):\n",
    "    a = []\n",
    "    for _ in l:\n",
    "        if f(_):\n",
    "            a.append(_)\n",
    "    return a\n",
    "\n",
    "def find_separator(tokens):\n",
    "    if find(tokens, lambda t: t.text == \";\"):\n",
    "        return \";\"\n",
    "    return \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4a528ff4-fb0b-437b-851d-f7e7a4b8b970",
   "metadata": {},
   "outputs": [],
   "source": [
    "def index(l, f):\n",
    "    for i, _ in enumerate(l):\n",
    "        if f(_):\n",
    "            return i\n",
    "    return -1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11407981-899f-43e3-be24-c7ef607e9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conjunction(t):\n",
    "    return t.lower_ in [\"and\", \"or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a307064-2701-4be7-9948-111999329efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(tokens):\n",
    "    accept = [\"PROPN\", \"NOUN\", \"PRON\"]\n",
    "    ignore = [*accept, \"PART\", \"NUM\", \"ADJ\", \"CCONJ\", \"DET\"]\n",
    "\n",
    "    found = False\n",
    "    for token in tokens:\n",
    "        found = found or token in accept\n",
    "        if token not in ignore:\n",
    "            return False\n",
    "    \n",
    "    return found\n",
    "\n",
    "def is_verb(tokens):\n",
    "    accept = [\"VERB\"]\n",
    "    ignore = [*accept, \"AUX\", \"ADV\", \"ADP\", \"NOUN\", \"PRON\", \"PROPN\", \"CCONJ\", \"PART\", \"NUM\"]\n",
    "\n",
    "    found = False\n",
    "    for token in tokens:\n",
    "        found = found or token in accept\n",
    "        if token not in ignore:\n",
    "            return False\n",
    "\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448649b6-d3fc-4a04-9e2a-bc13ec4589ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_by_noun(tokens, noun_chunks):\n",
    "    number_tokens = len(tokens)\n",
    "    if not number_tokens:\n",
    "        return None\n",
    "    \n",
    "    l = number_tokens\n",
    "    while l > 0 and tokens[l].pos_ not in [\"PROPN\", \"NOUN\", \"PRON\"]:\n",
    "        l -= 1\n",
    "\n",
    "    for chunk in noun_chunks:\n",
    "        chunk_l = chunk.start\n",
    "        chunk_r = chunk.end\n",
    "        \n",
    "        if chunk_l <= tokens[l].i < chunk_r:\n",
    "            while l > 0 and tokens[l].i != chunk_l:\n",
    "                l -= 1\n",
    "            break\n",
    "\n",
    "    r = 0\n",
    "    number_tokens = len(tokens)\n",
    "    while r < number_tokens and tokens[r].pos_ not in [\"PROPN\", \"NOUN\", \"PRON\"]:\n",
    "        r += 1\n",
    "\n",
    "    for chunk in noun_chunks:\n",
    "        chunk_l = chunk.start\n",
    "        chunk_r = chunk.end\n",
    "\n",
    "        if chunk_l <= tokens[r].i < chunk_r:\n",
    "            while r < number_tokens and tokens[r].i != chunk_r - 1:\n",
    "                r += 1\n",
    "            break\n",
    "\n",
    "    return (l, r)\n",
    "\n",
    "def bound_by_verb(tokens):\n",
    "    number_tokens = len(tokens)\n",
    "    if not number_tokens:\n",
    "        return None\n",
    "\n",
    "    l = number_tokens\n",
    "    while l > 0 and tokens[l].pos_ not in [\"VERB\"]:\n",
    "        l -= 1\n",
    "\n",
    "    r = 0\n",
    "    number_tokens = len(tokens)\n",
    "    while r < number_tokens and tokens[r].pos_ not in [\"VERB\"]:\n",
    "        r += 1\n",
    "\n",
    "    return (l, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cc7a7939-a002-4f48-b98a-b7d3237cf9db",
   "metadata": {},
   "outputs": [],
   "source": [
    "def same_speech(speech_1, speech_2):\n",
    "    nouns = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "    if speech_1 in nouns and speech_2 in nouns:\n",
    "        return True\n",
    "    return speech_1 == speech_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "81b5b4ab-1b3c-4ecf-a973-92a3d9bb952c",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Entity:\n",
    "    LIST = 1\n",
    "    QUOTE = 2\n",
    "    CLAUSE = 3\n",
    "    BRACKET = 4\n",
    "    BREAK = 5\n",
    "    ITEM = 6\n",
    "    AND_OR_END = 7\n",
    "    COLON = 8\n",
    "    END = 9\n",
    "    COLON_BREAK = 10\n",
    "\n",
    "    def __init__(self, doc, label=None, l=None, r=None, children=None):\n",
    "        self.doc = doc\n",
    "        self.label = label\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "        self.children = children or []\n",
    "\n",
    "    def length(self):\n",
    "        return self.r - self.l + 1\n",
    "\n",
    "    def tokens(self):\n",
    "        return self.doc[self.l:self.r+1]\n",
    "\n",
    "    def text(self):\n",
    "        return self.doc[self.l:self.r+1].text\n",
    "        \n",
    "    def lower(self):\n",
    "        return self.doc[self.l:self.r+1].text.lower()\n",
    "\n",
    "    def first(self):\n",
    "        return self.doc[self.l]\n",
    "    \n",
    "    def start(self):\n",
    "        return self.doc[self.l]\n",
    "\n",
    "    def end(self):\n",
    "        return self.doc[self.r]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b4c1eaa-10df-4e68-bfc4-0656673edf93",
   "metadata": {},
   "outputs": [],
   "source": [
    "def to_tokens(*, ent=None, ents=None):\n",
    "    if ents:\n",
    "        tokens = flatten([list(e.tokens()) for e in ents])\n",
    "        tokens = sorted(tokens, key=lambda token: token.i)\n",
    "        return tokens\n",
    "    if ent:\n",
    "        return list(ent.tokens())\n",
    "    return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "280d9b53-4f23-4fb2-8d21-813bb23033a1",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Quotes:\n",
    "    def __init__(self, entities):\n",
    "        self.entities = entities\n",
    "\n",
    "    def is_quote(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower() == \"\\\"\"\n",
    "    \n",
    "    def identify(self):\n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            if not self.is_quote(i):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            self.entities[i].label = Entity.QUOTE\n",
    "            \n",
    "            while not self.is_quote(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            if self.is_quote(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f2d77b2c-2fe9-4ea8-814b-1ea1c6a9f62a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Brackets:\n",
    "    MATCHES = {\n",
    "        \"[\": \"]\", \n",
    "        \"(\": \")\",\n",
    "        \"—\": \"—\",\n",
    "    }\n",
    "\n",
    "    OPENING = MATCHES.keys()\n",
    "    CLOSING = MATCHES.values()\n",
    "\n",
    "    def __init__(self, entities):\n",
    "        self.stack = []\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def is_opening(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower() in Brackets.OPENING\n",
    "\n",
    "    def is_closing(self, i):\n",
    "        return i < len(self.entities) and self.entities[i].lower()[0] in Brackets.CLOSING\n",
    "\n",
    "    def closes(self, i):\n",
    "        opener = self.entities[self.stack[-1]].lower()[0]\n",
    "        closer = self.entities[i].lower()[0]\n",
    "        \n",
    "        return bool(\n",
    "            i < len(self.entities) and \n",
    "            Brackets.MATCHES[opener] == closer\n",
    "        )\n",
    "    \n",
    "    def identify(self):\n",
    "        self.stack = []\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(self.entities):\n",
    "            if self.is_closing(i) and self.stack:\n",
    "                j = None\n",
    "\n",
    "                if self.closes(i):\n",
    "                    j = self.stack.pop()\n",
    "\n",
    "                if not self.stack and j is not None:\n",
    "                    self.entities[j].r += 1\n",
    "                    self.entities.pop(i)\n",
    "                else:\n",
    "                    i += 1\n",
    "\n",
    "            elif self.is_opening(i):\n",
    "                if not self.stack:\n",
    "                    self.entities[i].label = Entity.BRACKET\n",
    "                self.stack.append(i)\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            else:\n",
    "                if self.stack:\n",
    "                    self.entities[self.stack[0]].r += 1\n",
    "                    self.entities.pop(i)\n",
    "                else:\n",
    "                    i += 1\n",
    "        \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f08c93d-7d0c-46c1-80d8-d0d32725aec8",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Separators:\n",
    "    def __init__(self, entities):\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def is_break(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return False\n",
    "        if self.entities[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "        if bool(\n",
    "            i + 1 < len(self.entities) and \n",
    "            self.entities[i+1].length() == 1 and \n",
    "            self.entities[i+1].tokens()[0].pos_ in [\"CCONJ\"]\n",
    "        ):\n",
    "            return False\n",
    "        return True\n",
    "\n",
    "    def is_end(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return False\n",
    "        if self.entities[i].lower() not in [\";\", \",\"]:\n",
    "            return False\n",
    "        return not self.is_break(i)\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.entities):\n",
    "            if self.is_break(i):\n",
    "                self.entities[i].label = Entity.BREAK\n",
    "                i += 1\n",
    "            elif self.is_end(i):\n",
    "                conjunction = self.entities[i+1].tokens()[0]\n",
    "                if conjunction.lower_ in [\"and\", \"or\"]:\n",
    "                    self.entities[i].label = Entity.AND_OR_END\n",
    "                else:\n",
    "                    self.entities[i].label = Entity.END\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "            else:\n",
    "                i += 1\n",
    "                \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8c828165-8eeb-4b5b-a6c0-d86de79992cd",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Colons:\n",
    "    def __init__(self, entities):\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def identify(self):\n",
    "        i = 0\n",
    "\n",
    "        while i < len(self.entities):\n",
    "            if self.entities[i].lower()[-1] != \":\":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if not self.entities[i].label:\n",
    "                self.entities[i].label = Entity.COLON_BREAK\n",
    "            \n",
    "            self.entities[i+1].label = Entity.COLON\n",
    "            self.entities[i+1].r = self.entities[-1].r\n",
    "            self.entities = self.entities[:i+2]\n",
    "\n",
    "            break\n",
    "\n",
    "        return self.entities        "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3d272298-aa7d-466a-be94-322d940d2fc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Independent_Clauses:\n",
    "    def __init__(self, entities):\n",
    "        self.entities = [*entities]\n",
    "        self.allowed = []\n",
    "\n",
    "    def end(self, i):    \n",
    "        if i >= len(self.entities):\n",
    "            return True\n",
    "        if i + 1 < len(self.entities) and self.entities[i+1].label in [Entity.CLAUSE, Entity.COLON]:\n",
    "            return True\n",
    "        if self.entities[i].label in self.allowed:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def identify(self, allowed):\n",
    "        self.allowed = allowed\n",
    "        \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            if self.entities[i].label not in self.allowed:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if self.entities[i].label == Entity.CLAUSE:\n",
    "                i = entities[i].r + 1\n",
    "                continue\n",
    "            \n",
    "            self.entities[i].label = Entity.CLAUSE\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "            \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b6f0456c-9c8b-4ff5-9d74-fe1345b37a32",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Dependent_Clauses:\n",
    "    RELATIVE_NOUNS = [\n",
    "        \"who\",\n",
    "        \"whom\",\n",
    "        \"which\",\n",
    "        \"what\",\n",
    "        \"that\",\n",
    "        \"whose\",\n",
    "        \"whomever\",\n",
    "        \"whoever\",\n",
    "        \"whichever\",\n",
    "        \"whatever\"\n",
    "    ]\n",
    "    \n",
    "    def __init__(self, entities):\n",
    "        self.entities = entities\n",
    "        self.separator = None\n",
    "\n",
    "    def end(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return True\n",
    "        if i + 1 < len(self.entities) and self.entities[i+1].label in [Entity.COLON, Entity.CLAUSE]:\n",
    "            return True\n",
    "        if self.entities[i].lower()[0] == self.separator:\n",
    "            return True\n",
    "        if self.entities[i].lower() in Dependent_Clauses.RELATIVE_NOUNS:\n",
    "            return True\n",
    "        if self.entities[i].first().pos_ in [\"SCONJ\"]:\n",
    "            return True\n",
    "        return False\n",
    "\n",
    "    def identify(self, separator):\n",
    "        self.separator = separator\n",
    "        \n",
    "        i = 0\n",
    "        while i < len(self.entities):\n",
    "            if self.entities[i].label in [Entity.COLON, Entity.CLAUSE]:\n",
    "                i = self.entities[i].r + 1\n",
    "                continue\n",
    "\n",
    "            rel = self.entities[i].lower() in Dependent_Clauses.RELATIVE_NOUNS\n",
    "            sub = self.entities[i].first().pos_ == \"SCONJ\"\n",
    "            \n",
    "            if not sub and not rel:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            self.entities[i].label = Entity.CLAUSE\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        return self.entities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf870805-562c-4d58-91b7-8271ddc50fb0",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Prepositional_Clauses:\n",
    "    NOUN_SPEECH = [\"NOUN\", \"PROPN\", \"PRON\"]\n",
    "\n",
    "    def __init__(self, entities):\n",
    "        self.entities = [*entities]\n",
    "\n",
    "    def last_noun(self, i):\n",
    "        if i >= len(self.entities):\n",
    "            return False\n",
    "            \n",
    "        if self.entities[i].first().pos_ in Prepositional_Clauses.NOUN_SPEECH:\n",
    "            if bool(\n",
    "                i + 1 > len(self.entities) - 1 or \n",
    "                (\n",
    "                    self.entities[i+1].length() == 1 and \n",
    "                    self.entities[i+1].first().pos_ not in [*Prepositional_Clauses.NOUN_SPEECH, \"PART\"]\n",
    "                )\n",
    "            ):\n",
    "                return True\n",
    "            \n",
    "        return False\n",
    "\n",
    "    def end(self, i):\n",
    "        if i + 1 >= len(self.entities):\n",
    "            return True\n",
    "        if self.entities[i+1].label in [Entity.COLON, Entity.CLAUSE]:\n",
    "            return True\n",
    "        return self.last_noun(i)\n",
    "\n",
    "    def identify(self):    \n",
    "        i = 0\n",
    "        \n",
    "        while i < len(self.entities):\n",
    "            if self.entities[i].length() != 1:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if self.entities[i].first().pos_ != \"ADP\":\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            self.entities[i].label = Entity.CLAUSE\n",
    "            while not self.end(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "\n",
    "            if self.last_noun(i+1):\n",
    "                self.entities[i].r += 1\n",
    "                self.entities.pop(i+1)\n",
    "            \n",
    "            i += 1\n",
    "        \n",
    "        return self.entities   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "49e98285-f9b5-41a7-8cd0-a3e858ce3331",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Lists:\n",
    "    NOUNS = [\"NOUN\", \"PRON\", \"PROPN\"]\n",
    "    \n",
    "    def __init__(self, entities):\n",
    "        self.entities = [*entities]\n",
    "        self.separator = None\n",
    "\n",
    "    def is_stop(self, entity):\n",
    "        is_break = entity.label == Entity.BREAK and entity.lower()[0] == self.separator\n",
    "        is_clause = entity.label in [Entity.CLAUSE, Entity.COLON, Entity.COLON_BREAK]\n",
    "        return is_break or is_clause\n",
    "\n",
    "    def find_lists(self, sep):\n",
    "        self.separator = sep\n",
    "        \n",
    "        lists = [\n",
    "            [\n",
    "                [None, None]\n",
    "            ]\n",
    "        ]\n",
    "\n",
    "        i = 0\n",
    "        while i < len(self.entities):\n",
    "            print(lists)\n",
    "            entity = self.entities[i]\n",
    "\n",
    "            opened = lists[-1][0] != [None, None]\n",
    "\n",
    "            kill_list = entity.label in [Entity.COLON, Entity.COLON_BREAK]\n",
    "            close_list = entity.label in [Entity.AND_OR_END] and entity.lower()[0] == sep\n",
    "            close_item = entity.label in [Entity.BREAK] and entity.lower() == sep\n",
    "\n",
    "            print(f\"\\tOpened: {opened}\")\n",
    "            print(f\"\\tKill List: {kill_list}\")\n",
    "            print(f\"\\tClose List: {close_list}\")\n",
    "            print(f\"\\tClose Item: {close_item}\")\n",
    "            \n",
    "            # Close List, Open List\n",
    "            if opened and close_list:\n",
    "                # Invalid List\n",
    "                if len(lists[-1]) < 2:\n",
    "                    lists.pop()\n",
    "                \n",
    "                # Add Last Item\n",
    "                else: \n",
    "                    last_item_l = i + 1\n",
    "                    last_item_r = last_item_l\n",
    "                    \n",
    "                    length = index(self.entities[last_item_l:], lambda e: self.is_stop(e))\n",
    "                    \n",
    "                    if length > 0:\n",
    "                        last_item_r += length - 1\n",
    "                    elif length == -1:\n",
    "                        last_item_r = len(self.entities) - 1\n",
    "\n",
    "                    print(f\"ADDING LAST ITEM: {[last_item_l, last_item_r]}\")\n",
    "                    lists[-1].append([last_item_l, last_item_r])\n",
    "\n",
    "                # Close List, Open List\n",
    "                lists.append([[None, None]])\n",
    "                i += 1\n",
    "\n",
    "            # Close Item, Open Item\n",
    "            elif opened and close_item:\n",
    "                lists[-1].append([i + 1, i])\n",
    "                i += 1\n",
    "                \n",
    "            # Kill List, Open List\n",
    "            elif opened and kill_list:\n",
    "                lists.pop()\n",
    "                lists.append([[None, None]])\n",
    "                i += 1\n",
    "\n",
    "            # Restart List\n",
    "            # elif not opened and kill_list and entity.label in [Entity.CLAUSE]:\n",
    "            #     lists[-1][0] = [i, i]\n",
    "            #     i += 1\n",
    "            \n",
    "            # Increment Item\n",
    "            else:\n",
    "                if not opened:\n",
    "                    lists[-1][0] = [i, i]\n",
    "                else:\n",
    "                    lists[-1][-1][1] += 1\n",
    "                i += 1\n",
    "\n",
    "        print(lists)\n",
    "        print(\"ENDDDD\")\n",
    "\n",
    "        # In case list hasn't closed\n",
    "        if len(lists[-1]) < 3:\n",
    "            lists.pop()\n",
    "        \n",
    "        # Looking for Two-Item Lists\n",
    "        num_lists = len(lists)\n",
    "        for list_i, list_ in enumerate(lists):\n",
    "            if list_i >= num_lists:\n",
    "                break\n",
    "            \n",
    "            for l, r in list_:\n",
    "                tokens = flatten([list(e.tokens()) for e in self.entities[l:r+1]])\n",
    "                num_conj = len(find_all(tokens, lambda t: is_conjunction(t)))\n",
    "                if num_conj == 1:\n",
    "                    lists.append([[l, r]])\n",
    "\n",
    "        # Removing Duplicates\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            if lists[i] in lists[i+1:]:\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "\n",
    "        # Removing Non-Lists\n",
    "        i = 0\n",
    "        while i < len(lists):\n",
    "            if len(lists[i]) == 1 and lists[i][0][0] == lists[i][0][1]:\n",
    "                lists.pop(i)\n",
    "            else:\n",
    "                i += 1\n",
    "         \n",
    "        return lists\n",
    "\n",
    "    def clean_lists(self, lists):\n",
    "        print(\"clean_lists\")\n",
    "        print(lists)\n",
    "        \n",
    "        overlaps = []\n",
    "\n",
    "        i = 0\n",
    "        while i + 1 < len(lists):\n",
    "            a = lists[i]\n",
    "            b = lists[i+1]\n",
    "                  \n",
    "            if a[-1] != b[0]:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            if len(a) <= 1 or len(b) <= 1:\n",
    "                i += 1\n",
    "                continue\n",
    "\n",
    "            # No Way to Split\n",
    "            if a[-1][1] - a[-1][0] <= 1:\n",
    "                overlaps.extend([i, i + 1])\n",
    "                i += 2\n",
    "            else:\n",
    "                a[-1][1] = a[-1][0]\n",
    "                b[0][0] = b[0][1]\n",
    "                i += 2\n",
    "        \n",
    "        lists = [l for i, l in enumerate(lists) if i not in overlaps]\n",
    "\n",
    "        print(lists)\n",
    "        \n",
    "        return lists\n",
    "\n",
    "    def bound_list_(self, lst):\n",
    "        # Left Bound\n",
    "        l_bound_text = to_tokens(ent=self.entities[lst[-2][0]])[0].lower_\n",
    "\n",
    "        # Right Bound\n",
    "        b_tokens = to_tokens(ents=self.entities[lst[-2][0]:lst[-2][1]+1])\n",
    "        num_b_tokens = len(b_tokens)\n",
    "        \n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\", \"NUM\"]\n",
    "        \n",
    "        r_bound = None\n",
    "        for i in range(num_b_tokens - 1, -1, -1):\n",
    "            if b_tokens[i].pos_ in speech:\n",
    "                r_bound = b_tokens[i]\n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # Check Inner Items for Left Bound\n",
    "        inner_items = lst[1:-2]\n",
    "\n",
    "        print(\"Bound Inner Items\")\n",
    "        print(inner_items)\n",
    "        \n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            tokens = to_tokens(ents=self.entities[l:r+1])\n",
    "            \n",
    "            if tokens[0].lower_ != l_bound_text:\n",
    "                if len(inner_items) - i - 1 > 1:\n",
    "                    return self.bound_list_(lst[i+2:])\n",
    "                return None\n",
    "            \n",
    "        # Shift Starting Item\n",
    "        start_tokens = to_tokens(ents=self.entities[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        print(start_tokens, start_l)\n",
    "\n",
    "        while start_l >= 0 and start_tokens[start_l] != l_bound_text:\n",
    "            start_l -= 1\n",
    "\n",
    "        if start_l < 0:\n",
    "            if len(inner_items) >= 2:\n",
    "                return self.bound_list(lst[1:])\n",
    "            return None\n",
    "\n",
    "        # Adjust Starting Item\n",
    "        if l_bound.pos_ in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if start_tokens[start_l].i in tokens_i:\n",
    "                    while start_l >= 0 and start_tokens[start_l].i in tokens_i:\n",
    "                        start_l -= 1\n",
    "                    start_l += 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if start_tokens[start_l].i in tokens_i:\n",
    "                    while start_l >= 0 and start_tokens[start_l].i in tokens_i:\n",
    "                        start_l -= 1\n",
    "                    start_l += 1\n",
    "                break\n",
    "\n",
    "        print(f\"start_l: {start_l}\")\n",
    "        print(f\"Starting Item: {start_tokens[start_l:]}\")\n",
    "        \n",
    "        # Shift Ending Item\n",
    "        end_tokens = to_tokens(ents=self.entities[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "\n",
    "        \n",
    "        while end_r < num_end_tokens and end_tokens[end_r].pos_ not in SPEECH:\n",
    "            end_r += 1\n",
    "\n",
    "        if end_r >= num_end_tokens:\n",
    "            return None\n",
    "\n",
    "        # Adjust Ending Item\n",
    "        if end_tokens[end_r].pos_ in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if end_tokens[end_r].i in tokens_i:\n",
    "                    while end_r < num_tokens and end_tokens[end_r].i in tokens_i:\n",
    "                        end_r += 1\n",
    "                    end_r -= 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if end_tokens[end_r].i in tokens_i:\n",
    "                    while end_r < num_tokens and end_tokens[end_r].i in tokens_i:\n",
    "                        end_r += 1\n",
    "                    end_r -= 1\n",
    "                break\n",
    "\n",
    "        print(f\"end_r: {end_r}\")\n",
    "        print(f\"Ending Item: {end_tokens[:end_r+1]}\")\n",
    "        \n",
    "        doc = self.entities[0].doc\n",
    "        entity_list = Entity(doc, label=Entity.LIST, l=start_tokens[start_l].i, r=end_tokens[end_r].i)\n",
    "        \n",
    "        entity_start_item = Entity(doc, label=Entity.ITEM, l=start_tokens[start_l].i, r=start_tokens[-1].i)\n",
    "        entity_list.children.append(entity_start_item)\n",
    "        \n",
    "        entity_end_item = Entity(doc, label=Entity.ITEM, l=end_tokens[0].i, r=end_tokens[end_r].i)\n",
    "        entity_list.children.append(entity_end_item)\n",
    "\n",
    "        for item in lst[1:-1]:\n",
    "            tokens = to_tokens(ents=self.entities[item[0]:item[1]+1])\n",
    "            entity_item = Entity(doc, label=Entity.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            entity_list.children.append(entity_item)\n",
    "\n",
    "        return entity_list\n",
    "            \n",
    "    def bound_list(self, lst):\n",
    "        print(\"Bound List\")\n",
    "        print(lst)\n",
    "\n",
    "        tokens = to_tokens(ents=self.entities[lst[0][0]:lst[-1][-1]])\n",
    "        print(tokens)\n",
    "\n",
    "        # Base\n",
    "        b_l = lst[-2][0]\n",
    "        b_r = lst[-2][1]\n",
    "        \n",
    "        b_tokens = to_tokens(ents=self.entities[b_l:b_r+1])\n",
    "        b_speech = [token.pos_ for token in b_tokens]\n",
    "        \n",
    "        num_b_tokens = len(b_tokens)\n",
    "        \n",
    "        # Bound\n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\", \"NUM\"]\n",
    "\n",
    "        # L-Bound\n",
    "        l_bound = None\n",
    "        for i in range(0, num_b_tokens):\n",
    "            if b_tokens[i].pos_ in speech:\n",
    "                l_bound = b_tokens[i]\n",
    "                break\n",
    "\n",
    "        if not l_bound:\n",
    "            return None\n",
    "        \n",
    "        # R-Bound\n",
    "        r_bound = None\n",
    "        for i in range(num_b_tokens - 1, -1, -1):\n",
    "            if b_tokens[i].pos_ in speech:\n",
    "                r_bound = b_tokens[i]\n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # Bound Inner Items\n",
    "        inner_items = lst[1:-2]\n",
    "\n",
    "        print(\"Bound Inner Items\")\n",
    "        print(inner_items)\n",
    "        \n",
    "        for i, item in enumerate(inner_items):\n",
    "            l = item[0]\n",
    "            r = item[1]\n",
    "            \n",
    "            tokens = to_tokens(ents=self.entities[l:r+1])\n",
    "            item_speech = [token.pos_ for token in tokens]\n",
    "\n",
    "            if l_bound.pos_ not in item_speech:\n",
    "                if len(inner_items) - i - 1 > 1:\n",
    "                    return self.bound_list(lst[i+2:])\n",
    "                return None\n",
    "        \n",
    "        # Shift Starting Item\n",
    "        start_tokens = to_tokens(ents=self.entities[lst[0][0]:lst[0][1]+1])\n",
    "        start_l = len(start_tokens) - 1\n",
    "        print(start_tokens, start_l)\n",
    "\n",
    "        while start_l >= 0 and not same_speech(start_tokens[start_l].pos_, l_bound.pos_):\n",
    "            start_l -= 1\n",
    "\n",
    "            if start_l < 0:\n",
    "                if len(inner_items) >= 2:\n",
    "                    return self.bound_list(lst[1:])\n",
    "                return None\n",
    "\n",
    "        # Adjust Starting Item\n",
    "        if l_bound.pos_ in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if start_tokens[start_l].i in tokens_i:\n",
    "                    while start_l >= 0 and start_tokens[start_l].i in tokens_i:\n",
    "                        start_l -= 1\n",
    "                    start_l += 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if start_tokens[start_l].i in tokens_i:\n",
    "                    while start_l >= 0 and start_tokens[start_l].i in tokens_i:\n",
    "                        start_l -= 1\n",
    "                    start_l += 1\n",
    "                break\n",
    "\n",
    "        print(f\"start_l: {start_l}\")\n",
    "        print(f\"Starting Item: {start_tokens[start_l:]}\")\n",
    "        \n",
    "        # Shift Ending Item\n",
    "        end_tokens = to_tokens(ents=self.entities[lst[-1][0]:lst[-1][1]+1])\n",
    "        end_r = 0\n",
    "        num_end_tokens = len(end_tokens)\n",
    "\n",
    "        \n",
    "        while end_r < num_end_tokens and not same_speech(end_tokens[end_r].pos_, l_bound.pos_):\n",
    "            end_r += 1\n",
    "\n",
    "            if end_r >= num_end_tokens:\n",
    "                return None\n",
    "\n",
    "        # Adjust Ending Item\n",
    "        if r_bound.pos_ in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if end_tokens[end_r].i in tokens_i:\n",
    "                    while end_r < num_tokens and end_tokens[end_r].i in tokens_i:\n",
    "                        end_r += 1\n",
    "                    end_r -= 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if end_tokens[end_r].i in tokens_i:\n",
    "                    while end_r < num_tokens and end_tokens[end_r].i in tokens_i:\n",
    "                        end_r += 1\n",
    "                    end_r -= 1\n",
    "                break\n",
    "\n",
    "        print(f\"end_r: {end_r}\")\n",
    "        print(f\"Ending Item: {end_tokens[:end_r+1]}\")\n",
    "        \n",
    "        doc = self.entities[0].doc\n",
    "        entity_list = Entity(doc, label=Entity.LIST, l=start_tokens[start_l].i, r=end_tokens[end_r].i)\n",
    "        \n",
    "        entity_start_item = Entity(doc, label=Entity.ITEM, l=start_tokens[start_l].i, r=start_tokens[-1].i)\n",
    "        entity_list.children.append(entity_start_item)\n",
    "        \n",
    "        entity_end_item = Entity(doc, label=Entity.ITEM, l=end_tokens[0].i, r=end_tokens[end_r].i)\n",
    "        entity_list.children.append(entity_end_item)\n",
    "\n",
    "        for item in lst[1:-1]:\n",
    "            tokens = to_tokens(ents=self.entities[item[0]:item[1]+1])\n",
    "            entity_item = Entity(doc, label=Entity.ITEM, l=tokens[0].i, r=tokens[-1].i)\n",
    "            entity_list.children.append(entity_item)\n",
    "\n",
    "        return entity_list\n",
    "\n",
    "    def bound_pair_by_chars(self, pair):\n",
    "        print(\"Bound Pair\")\n",
    "        print(pair)\n",
    "        \n",
    "        tokens = flatten([list(e.tokens()) for e in self.entities[pair[0][0]:pair[0][1]+1]])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        print(tokens)\n",
    "        \n",
    "        m = index(tokens, lambda t: is_conjunction(t))\n",
    "        l = m - 1\n",
    "        r = m + 1\n",
    "\n",
    "        print(l, m, r)\n",
    "\n",
    "        # Bound Left by Right Characters\n",
    "        i = m - 1\n",
    "        while i >= 0 and tokens[i].lower_ != tokens[m + 1].lower_:\n",
    "            i -= 1\n",
    "\n",
    "        if i < 0:\n",
    "            return None\n",
    "\n",
    "        # Bound Right by Left Token Speech\n",
    "        j =  m + 1\n",
    "        while j < num_tokens and not same speech(tokens[m-1].pos_, tokens[j].pos_):\n",
    "            j += 1\n",
    "\n",
    "        if j >= num_tokens:\n",
    "            return None\n",
    "\n",
    "        doc = self.entities[0].doc\n",
    "        \n",
    "        item_l = Entity(doc, label=Entity.ITEM, l=i, r=m-1)\n",
    "        item_r = Entity(doc, label=Entity.ITEM, l=m+1, r=j)\n",
    "        list_ = Entity(doc, label=Entity.LIST, l=i, r=j, children=[item_l, item_r])\n",
    "        \n",
    "        return list_\n",
    "    \n",
    "    def bound_pair(self, pair):\n",
    "        print(\"Bound Pair\")\n",
    "        print(pair)\n",
    "        \n",
    "        tokens = flatten([list(e.tokens()) for e in self.entities[pair[0][0]:pair[0][1]+1]])\n",
    "        tokens = sorted(tokens, key=lambda t: t.i)\n",
    "        num_tokens = len(tokens)\n",
    "        \n",
    "        print(tokens)\n",
    "        \n",
    "        m = index(tokens, lambda t: is_conjunction(t))\n",
    "        l = m - 1\n",
    "        r = m + 1\n",
    "\n",
    "        print(l, m, r)\n",
    "        \n",
    "        speech = [\"NOUN\", \"PROPN\", \"PRON\", \"VERB\", \"NUM\"]\n",
    "\n",
    "        # Find L Bound\n",
    "        l_bound = None\n",
    "        l_bound_i = None\n",
    "        for i in range(m + 1, num_tokens):\n",
    "            if tokens[i].pos_ in speech:\n",
    "                l_bound = tokens[i].pos_\n",
    "                l_bound_i = tokens[i].i\n",
    "                break\n",
    "\n",
    "        if not l_bound:\n",
    "            return None\n",
    "\n",
    "        # Find R Bound\n",
    "        r_bound = None\n",
    "        r_bound_i = None\n",
    "        for i in range(m - 1, -1, -1):\n",
    "            if tokens[i].pos_ in speech:\n",
    "                r_bound = tokens[i].pos_\n",
    "                r_bound_i = tokens[i].i\n",
    "                break\n",
    "\n",
    "        if not r_bound:\n",
    "            return None\n",
    "\n",
    "        # Shift L\n",
    "        while l >= 0 and not same_speech(tokens[l].pos_, l_bound):\n",
    "            l -= 1\n",
    "            if l < 0:\n",
    "                return None\n",
    "\n",
    "        # Adjust L if Noun\n",
    "        if l_bound in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if tokens[l].i in tokens_i:\n",
    "                    while l >= 0 and tokens[l].i in tokens_i:\n",
    "                        l -= 1\n",
    "                    l += 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if tokens[l].i in tokens_i:\n",
    "                    while l >= 0 and tokens[l].i in tokens_i:\n",
    "                        l -= 1\n",
    "                    l += 1\n",
    "                break\n",
    "            \n",
    "        # Shift R\n",
    "        while r < num_tokens and not same_speech(tokens[r].pos_, r_bound):\n",
    "            r += 1\n",
    "            if r >= num_tokens:\n",
    "                return None\n",
    "\n",
    "        # Adjust R if Noun\n",
    "        if r_bound in Lists.NOUNS:\n",
    "            for c in self.entities[0].doc.noun_chunks:\n",
    "                tokens_i = [t.i for t in c]\n",
    "                if tokens[r].i in tokens_i:\n",
    "                    while r < num_tokens and tokens[r].i in tokens_i:\n",
    "                        r += 1\n",
    "                    r -= 1\n",
    "                break\n",
    "\n",
    "            for e in self.entities[0].doc.ents:\n",
    "                tokens_i = [t.i for t in e]\n",
    "                if tokens[r].i in tokens_i:\n",
    "                    while r < num_tokens and tokens[r].i in tokens_i:\n",
    "                        r += 1\n",
    "                    r -= 1\n",
    "                break\n",
    "\n",
    "        doc = self.entities[0].doc\n",
    "        \n",
    "        entity_list = Entity(doc, label=Entity.LIST, l=l, r=r)\n",
    "        \n",
    "        entity_start_item = Entity(doc, label=Entity.ITEM, l=l, r=r_bound_i)\n",
    "        entity_list.children.append(entity_start_item)\n",
    "\n",
    "        entity_end_item = Entity(doc, label=Entity.ITEM, l=l_bound_i, r=r)\n",
    "        entity_list.children.append(entity_end_item)\n",
    "        \n",
    "        return entity_list\n",
    "\n",
    "    def bound_lists(self, lists):\n",
    "        print(f\"bound_lists\")\n",
    "        print(lists)\n",
    "        bound_lists = []\n",
    "        \n",
    "        for lst in lists:\n",
    "            bound = None \n",
    "            \n",
    "            if len(lst) == 1:\n",
    "                print(f\"Pair: {lst}\")\n",
    "                bound = self.bound_pair_(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_pair(lst)\n",
    "                print(f\"---\")\n",
    "                print(f\"List: {bound.tokens()}\")\n",
    "                for item in bound.children:\n",
    "                    print(f\"\\tItem: {item.tokens()}\")\n",
    "            \n",
    "            else:\n",
    "                print(f\"List: {lst}\")\n",
    "                bound = self.bound_list_(lst)\n",
    "                if not bound:\n",
    "                    bound = self.bound_list(lst)\n",
    "                print(f\"---\")\n",
    "                print(f\"List: {bound.tokens()}\")\n",
    "                for item in bound.children:\n",
    "                    print(f\"\\tItem: {item.tokens()}\")\n",
    "            \n",
    "            if bound:\n",
    "                bound_lists.append(bound)\n",
    "\n",
    "        # Map (L, R) to Entity List\n",
    "        mapped_bounds = {}\n",
    "        for lst in bound_lists:\n",
    "            mapped_bounds[(lst.l, lst.r)] = lst\n",
    "\n",
    "        bounds = list(mapped_bounds.keys())\n",
    "        print(f\"Bounds: {bounds}\")\n",
    "\n",
    "        max_coverage = []\n",
    "        \n",
    "        for bound in bounds:\n",
    "            overlap = False\n",
    "            for i, max_bound in enumerate(max_coverage):\n",
    "                contains = max_bound[0] <= bound[0] <= max_bound[1] or max_bound[0] <= bound[1] <= max_bound[1]\n",
    "                surround = bound[0] <= max_bound[0] <= bound[1] or bound[0] <= max_bound[1] <= bound[1]\n",
    "                \n",
    "                print(f\"{bound} v. {max_bound}\")\n",
    "                print(f\"Contains: {contains}\")\n",
    "                print(f\"Surround: {surround}\")\n",
    "                \n",
    "                if contains or surround:\n",
    "                    overlap = True\n",
    "                \n",
    "                    if bound[1] - bound[0] > max_bound[1] - max_bound[0]:\n",
    "                        max_coverage[i] = bound\n",
    "            \n",
    "            if not overlap:\n",
    "                max_coverage.append(bound)\n",
    "\n",
    "        print(\"Max Coverage\")\n",
    "        print(max_coverage)\n",
    "\n",
    "        # Integrate Lists\n",
    "        # Case 1: No Overlap w/ 'Composite' Entities\n",
    "        # Add Entity List, Remove Old Entities\n",
    "        # Case 2: Overlap w/ Entities\n",
    "        # Split Overlapped Entity to Make Space for List\n",
    "        # Note: Store L and R Overlaps, Analyze Both Directions at Once\n",
    "        for bound in max_coverage:\n",
    "            l_overlap = None\n",
    "            r_overlap = None\n",
    "            \n",
    "            l_overlap_i = None\n",
    "            r_overlap_i = None\n",
    "            \n",
    "            i = 0\n",
    "            while i < len(self.entities):\n",
    "                entity = self.entities[i]\n",
    "                \n",
    "                # Overlap w/ Left\n",
    "                if not l_overlap and entity.l <= bound[0] <= entity.r:\n",
    "                    l_overlap = entity\n",
    "                    l_overlap_i = i\n",
    "    \n",
    "                # Overlap w/ Right\n",
    "                if not r_overlap and entity.l <= bound[1] <= entity.r:\n",
    "                    r_overlap = entity\n",
    "                    r_overlap_i = i\n",
    "\n",
    "                if l_overlap and r_overlap:\n",
    "                    break\n",
    "\n",
    "                i += 1\n",
    "\n",
    "            if l_overlap.label == Entity.CLAUSE:\n",
    "                print(\"A\", l_overlap.l, mapped_bounds[bound].l)\n",
    "                if l_overlap.l == mapped_bounds[bound].l:\n",
    "                    print(\"B\")\n",
    "                    self.entities.pop(0)\n",
    "                    self.entities.insert(0, mapped_bounds[bound])\n",
    "                else:\n",
    "                    print(\"C\")\n",
    "                    l_overlap.r = mapped_bounds[bound].l - 1\n",
    "                    self.entities = self.entities[:l_overlap_i+1] + self.entities[r_overlap_i+1:]\n",
    "                    self.entities.insert(l_overlap_i + 1, mapped_bounds[bound])\n",
    "            else:\n",
    "                self.entities = self.entities[:l_overlap_i] + self.entities[r_overlap_i+1:]\n",
    "                self.entities.insert(l_overlap_i, mapped_bounds[bound])\n",
    "        \n",
    "        return self.entities\n",
    "        \n",
    "    def identify(self, sep):\n",
    "        lists = self.find_lists(sep)\n",
    "        lists = self.clean_lists(lists)\n",
    "        lists = self.bound_lists(lists)   \n",
    "        return lists"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdc4eb-4007-44f8-b007-aba9ca15510a",
   "metadata": {},
   "outputs": [],
   "source": [
    "class Sentence:\n",
    "    def __init__(self, doc):\n",
    "        self.doc = doc\n",
    "        self.root = Entity(self.doc)\n",
    "\n",
    "    def update(self, tokens):\n",
    "        entities = []\n",
    "        for token in tokens:\n",
    "            entity = Entity(\n",
    "                self.doc, \n",
    "                l=token.i, \n",
    "                r=token.i\n",
    "            )\n",
    "            entities.append(entity)\n",
    "\n",
    "        entities = Quotes(entities).identify()\n",
    "        entities = Brackets(entities).identify()\n",
    "        entities = Separators(entities).identify()\n",
    "        \n",
    "        sep = \",\"\n",
    "        for entity in entities:\n",
    "            if \";\" == entity.lower()[0]:\n",
    "                sep = \";\"\n",
    "                break\n",
    "        print(f\"Separator: '{sep}'\")\n",
    "        \n",
    "        entities = Colons(entities).identify()\n",
    "        entities = Dependent_Clauses(entities).identify(sep)\n",
    "        entities = Independent_Clauses(entities).identify([Entity.END])\n",
    "        entities = Prepositional_Clauses(entities).identify()\n",
    "        entities = Lists(entities).identify(sep)\n",
    "        \n",
    "        return entities\n",
    "\n",
    "doc = nlp(\"By causing Nucella to consume fewer barnacles, crab predation risk allowed fucoids that had settled on or between barnacles to remain in the community.\")\n",
    "snt = Sentence(doc)\n",
    "\n",
    "entities = snt.update(snt.doc)\n",
    "for entity in entities:\n",
    "    print(f\"({entity.label}) '{doc[entity.l:entity.r+1]}'\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bfd3a4-1f6b-4877-8d9e-c3df21cb1bf0",
   "metadata": {},
   "outputs": [],
   "source": [
    "for nc in doc.noun_chunks:\n",
    "    print(nc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a587950a-d9af-4239-82d1-b5f8e4b1c957",
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"By causing Nucella to consume fewer barnacles, crab predation risk allowed fucoids that had settled on or between barnacles to remain in the community. \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "993c93a7-3a91-43bc-bd88-795f844beafe",
   "metadata": {},
   "outputs": [],
   "source": [
    "for token in doc:\n",
    "    print(token)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b82a72eb-7032-4a5d-93ed-51ac7f6f0831",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb3a36ad-d1f0-4017-80f2-6cfc24a05318",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
