{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19b95284-9556-4813-a4c8-cc182e276f58",
   "metadata": {},
   "outputs": [],
   "source": [
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "72dc5b30-b2c0-4243-babb-0fbf075093ad",
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load(\"en_core_web_lg\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0c7dc263-2066-4189-a0e4-0c184242050f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def find(l, f):\n",
    "    for _ in l:\n",
    "        if f(_):\n",
    "            return _\n",
    "    return None\n",
    "\n",
    "def find_all(l, f):\n",
    "    a = []\n",
    "    for _ in l:\n",
    "        if f(_):\n",
    "            a.append(_)\n",
    "    return a\n",
    "\n",
    "def find_separator(tokens):\n",
    "    if find(tokens, lambda t: t.text == \";\")\n",
    "        return \";\"\n",
    "    return \",\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "11407981-899f-43e3-be24-c7ef607e9fe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_conjunction(t):\n",
    "    return t.lower_ in [\"and\", \"or\"]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3a307064-2701-4be7-9948-111999329efd",
   "metadata": {},
   "outputs": [],
   "source": [
    "def is_noun(tokens):\n",
    "    accept = [\"PROPN\", \"NOUN\", \"PRON\"]\n",
    "    ignore = [*accept, \"PART\", \"NUM\", \"ADJ\", \"CCONJ\", \"DET\"]\n",
    "\n",
    "    found = False\n",
    "    for token in tokens:\n",
    "        found = found or token in accept\n",
    "        if token not in ignore:\n",
    "            return False\n",
    "    \n",
    "    return found\n",
    "\n",
    "def is_verb(tokens):\n",
    "    accept = [\"VERB\"]\n",
    "    ignore = [*accept, \"AUX\", \"ADV\", \"ADP\", \"NOUN\", \"PRON\", \"PROPN\", \"CCONJ\", \"PART\", \"NUM\"]\n",
    "\n",
    "    found = False\n",
    "    for token in tokens:\n",
    "        found = found or token in accept\n",
    "        if token not in ignore:\n",
    "            return False\n",
    "\n",
    "    return found"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "448649b6-d3fc-4a04-9e2a-bc13ec4589ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "def bound_by_noun(tokens, noun_chunks):\n",
    "    number_tokens = len(tokens)\n",
    "    if not number_tokens:\n",
    "        return None\n",
    "    \n",
    "    l = number_tokens\n",
    "    while l > 0 and tokens[l].pos_ not in [\"PROPN\", \"NOUN\", \"PRON\"]:\n",
    "        l -= 1\n",
    "\n",
    "    for chunk in noun_chunks:\n",
    "        chunk_l = chunk.start\n",
    "        chunk_r = chunk.end\n",
    "        \n",
    "        if chunk_l <= tokens[l].i < chunk_r:\n",
    "            while l > 0 and tokens[l].i != chunk_l:\n",
    "                l -= 1\n",
    "            break\n",
    "\n",
    "    r = 0\n",
    "    number_tokens = len(tokens)\n",
    "    while r < number_tokens and tokens[r].pos_ not in [\"PROPN\", \"NOUN\", \"PRON\"]:\n",
    "        r += 1\n",
    "\n",
    "    for chunk in noun_chunks:\n",
    "        chunk_l = chunk.start\n",
    "        chunk_r = chunk.end\n",
    "\n",
    "        if chunk_l <= tokens[r].i < chunk_r:\n",
    "            while r < number_tokens and tokens[r].i != chunk_r - 1:\n",
    "                r += 1\n",
    "            break\n",
    "\n",
    "    return (l, r)\n",
    "\n",
    "def bound_by_verb(tokens):\n",
    "    number_tokens = len(tokens)\n",
    "    if not number_tokens:\n",
    "        return None\n",
    "\n",
    "    l = number_tokens\n",
    "    while l > 0 and tokens[l].pos_ not in [\"VERB\"]:\n",
    "        l -= 1\n",
    "\n",
    "    r = 0\n",
    "    number_tokens = len(tokens)\n",
    "    while r < number_tokens and tokens[r].pos_ not in [\"VERB\"]:\n",
    "        r += 1\n",
    "\n",
    "    return (l, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "81b5b4ab-1b3c-4ecf-a973-92a3d9bb952c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Quote Bounds: [(0, 5)]\n",
      "0 5\n",
      "6 6\n",
      "7 7\n",
      "8 13\n",
      "14 22\n",
      "23 23\n",
      "24 24\n"
     ]
    }
   ],
   "source": [
    "class Entity:\n",
    "    LIST = 1\n",
    "    QUOTE = 2\n",
    "    CLAUSE = 3\n",
    "    BRACKET = 4\n",
    "    END = 5\n",
    "    ITEM = 6\n",
    "    SEPARATOR = 7\n",
    "    COLON = 8\n",
    "\n",
    "    def __init__(self, doc, label=None, l=None, r=None, children=None):\n",
    "        self.doc = doc\n",
    "        self.label = label\n",
    "        self.l = l\n",
    "        self.r = r\n",
    "        self.children = children\n",
    "\n",
    "    def length(self):\n",
    "        return self.r - self.l\n",
    "\n",
    "    def tokens(self):\n",
    "        return self.doc[self.l:self.r+1]\n",
    "\n",
    "class Sentence:\n",
    "    def __init__(self, doc):\n",
    "        self.doc = doc\n",
    "        self.root = Entity(self.doc)\n",
    "\n",
    "    def find_quotes(self, entities):\n",
    "        bounds = []\n",
    "        \n",
    "        i = 0\n",
    "        l = 0\n",
    "        found = False\n",
    "        \n",
    "        while i < len(tokens):\n",
    "            token = self.doc[i]\n",
    "            \n",
    "            if not found:\n",
    "                if token.text == \"\\\"\":\n",
    "                    found = True\n",
    "                    l = token.i\n",
    "            else:\n",
    "                if token.text == \"\\\"\":\n",
    "                    found = False\n",
    "                    bounds.append((l, token.i))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        print(f\"Quote Bounds: {bounds}\")\n",
    "        \n",
    "        if bool(\n",
    "            len(bounds) == 1 and \n",
    "            bounds[0][0] == tokens[0].i and \n",
    "            bounds[0][-1] == tokens[-1].i\n",
    "        ):\n",
    "            return []\n",
    "        return bounds\n",
    "\n",
    "    def identify_quotes(self, entities):\n",
    "        i = 0\n",
    "\n",
    "        is_quote = lambda i: i < len(entities) and entities[i].tokens().lower_ == \"\\\"\"\n",
    "        \n",
    "        while i < len(entities):\n",
    "            if not is_quote(i):\n",
    "                i += 1\n",
    "                continue\n",
    "            \n",
    "            entities[i].label = Entity.QUOTE\n",
    "            \n",
    "            while not is_quote(i+1):\n",
    "                entities[i].r += 1\n",
    "                entities.pop(i+1)\n",
    "\n",
    "            if is_quote(i+1):\n",
    "                entities[i].r += 1\n",
    "                entities.pop(i + 1)\n",
    "\n",
    "        return entities\n",
    "\n",
    "    def identify_brackets(self, entities):\n",
    "        i = 0\n",
    "\n",
    "        pairs = {\n",
    "            \"[\": \"]\", \n",
    "            \"(\": \")\",\n",
    "            \"窶能": \"窶能",\n",
    "            \",\": \",\",\n",
    "        }\n",
    "        \n",
    "        opening = pairs.keys()\n",
    "        is_opening = lambda i: i < len(entities) and entities[i].tokens().lower_ in opening\n",
    "\n",
    "        closing = pairs.values()\n",
    "        is_closing = lambda i: i < len(entities) and entities[i].tokens().lower_ in closing\n",
    "\n",
    "        closes = lambda i: bool(\n",
    "            i < len(entities) and \n",
    "            opening[entities[stack[-1]].tokens().lower_] == entities[i].tokens().lower_\n",
    "        )\n",
    "\n",
    "        stack = []\n",
    "        while i < len(entities):\n",
    "            if is_opening(i):\n",
    "                if not stack:\n",
    "                    entities[i].label = Entity.BRACKET\n",
    "                stack.append(i)\n",
    "                i += 1\n",
    "                continue\n",
    "                \n",
    "            if is_closing(i) and stack:\n",
    "                if closes(i):\n",
    "                    stack.pop()\n",
    "\n",
    "                if not stack:\n",
    "                    entities[stack[0]].r += 1\n",
    "                    entities.pop(i)\n",
    "                \n",
    "            if stack:\n",
    "                entities[stack[0]].r += 1\n",
    "                entities.pop(i)\n",
    "\n",
    "            i += 1\n",
    "        \n",
    "        return entities\n",
    "\n",
    "    def find_brackets(self, tokens):\n",
    "        bounds = []\n",
    "        \n",
    "        i = 0\n",
    "        stack = []\n",
    "        found = False\n",
    "\n",
    "        bracket = {\n",
    "            \"[\": \"]\", \n",
    "            \"(\": \")\",\n",
    "            \"窶能": \"窶能",\n",
    "            \",\": \",\", \n",
    "        }\n",
    "        opening = bracket.keys()\n",
    "        closing = bracket.values()\n",
    "        \n",
    "        while i < len(tokens):\n",
    "            token = tokens[i]\n",
    "\n",
    "            if token.text in opening:\n",
    "                stack.append(token)\n",
    "            \n",
    "            if token.text in closing and stack:\n",
    "                start = None\n",
    "                \n",
    "                if bracket[stack[-1].text] == token.text:\n",
    "                    start = stack.pop()\n",
    "\n",
    "                if not stack and start:\n",
    "                    bounds.append((start.i, token.i))\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        if bool(\n",
    "            len(bounds) == 1 and \n",
    "            bounds[0][0] == tokens[0].i and \n",
    "            bounds[0][-1] == tokens[-1].i\n",
    "        ):\n",
    "            return []\n",
    "        return bounds\n",
    "\n",
    "    def merge(self, entities, bound):\n",
    "        i = 0\n",
    "        while i < len(entities):\n",
    "            past_l = entities[i].l < bound[0]\n",
    "            past_r = entities[i].r > bound[1]\n",
    "\n",
    "            if not past_l and not past_r:\n",
    "                break\n",
    "\n",
    "            i += 1\n",
    "\n",
    "        while i+1 < len(entities) and entities[i+1].r <= bound[1]:\n",
    "            entities.pop(i+1)\n",
    "            entities[i].r += 1\n",
    "\n",
    "        return entities\n",
    "\n",
    "    def find_separators(self, entities, sep):\n",
    "        i = 0\n",
    "        while i < len(entities):\n",
    "            \n",
    "        \n",
    "    def update(self, tokens):\n",
    "        entities = []\n",
    "        for token in tokens:\n",
    "            entity = Entity(\n",
    "                self.doc, \n",
    "                l=token.i, \n",
    "                r=token.i\n",
    "            )\n",
    "            entities.append(entity)\n",
    "\n",
    "        self.identify_quotes(entities)\n",
    "        self.identify_brackets(entities)\n",
    "        \n",
    "        return entities\n",
    "\n",
    "doc = nlp(\"\\\"My name is Bob\\\", he (the friend of Gary) (not the friend of Joe) replied.\")\n",
    "snt = Sentence(doc)\n",
    "bnd = snt.update(snt.doc)\n",
    "for b in bnd:\n",
    "    print(b.l, b.r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "37fdc4eb-4007-44f8-b007-aba9ca15510a",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
